<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>与小陈同学的打卡计划1💘|0418-0424规划</title>
      <link href="/2022/04/17/0418-0424%E8%A7%84%E5%88%92/"/>
      <url>/2022/04/17/0418-0424%E8%A7%84%E5%88%92/</url>
      
        <content type="html"><![CDATA[<p><strong>数学建模</strong> (🚩🚩🚩🚩)<br>距离五一数学建模大赛还有13天</p><blockquote><p>规划概要：<br>针对数学建模题型学习两个模型对应的算法，学习原理的过程中整理笔记，在MATLAB上验证算法并更换数据集分析结果。</p></blockquote><ul><li>层次分析法<ul><li><input disabled="" type="checkbox"> 基于熵权法对Topsis模型的修正——解析原理和代码(对应课程：番外篇)</li></ul></li><li>预测模型<ul><li><input disabled="" type="checkbox"> 灰色预测算法——原理+代码(对应课程：基础篇&#x2F;第12讲)</li><li><input disabled="" type="checkbox"> 神经网络预测算法——原理+代码(对应课程：基础篇&#x2F;第12讲)</li></ul></li><li>数模作图与写作<ul><li><input disabled="" type="checkbox"> 学习用Excel绘制统计图(对应课程：更新篇&#x2F;更新1)</li><li><input disabled="" type="checkbox"> 写一篇完整的数学建模论文<blockquote><p>找一道题目，运用本周学习的其中一道算法(神经网络预测算法)完成论文写作练习。<br>时间安排：</p><ol><li>本周的某三个晚上学习算法，时间自定</li><li>下午整理算法的原理笔记</li><li>双休日的某一天完成论文写作</li></ol></blockquote></li></ul></li></ul><hr><p><strong>计算机视觉</strong>(🚩🚩🚩)</p><ul><li>Yolov5-v6.1学习<ul><li><input disabled="" type="checkbox"> Yolov5的深入学习<blockquote><p>针对Yolov5算法中的Backbone部分的每个模块深入理解，<br>基于新发现的网站：<a href="https://poloclub.github.io/cnn-explainer/">卷积神经网络可视化</a>联合学习</p></blockquote></li><li><input disabled="" type="checkbox"> Yolov5-ship模型检测与评价<blockquote><p>用上周训练的Yolov5权重文件在已有的数据集上进行验证，并分析评价训练效果和输出各种曲线</p></blockquote></li></ul></li><li>Vision Transform算法学习<ul><li><input disabled="" type="checkbox"> 算法框架和原理学习  <blockquote><p>继续学习Vision Tranform的网络架构和原理，并整理笔记</p></blockquote></li></ul></li></ul><hr><p><strong>神经网络论文</strong>(课程作业)(🚩🚩)</p><ul><li>看文献<ul><li><input disabled="" type="checkbox"> Graph Wavelet Neural Network</li><li><input disabled="" type="checkbox"> Multi-level Wavelet Convolutional Neural Networks<blockquote><p>目标要求：</p><ol><li>对应源码学习</li><li>看懂原理</li><li>验证原论文数据集并更换数据集验证</li></ol></blockquote></li></ul></li><li><ul><li><input disabled="" type="checkbox"> 写作业大论文大论文框架</li></ul></li></ul><hr><p><strong>支线任务</strong>(🚩)</p><ul><li><p>嵌入式应用技术备课</p><blockquote><p>第9周开始新一章节的课程，周日完成备课</p></blockquote></li><li><p>研电赛相关</p><blockquote><p>实验+技术报告写作</p></blockquote></li><li><p>深度学习课程与作业</p><blockquote><p>周一上完课后，晚上带电脑回寝室完成</p></blockquote></li><li><p>本科生毕设</p><blockquote><ol><li>24VDC伺服电机驱动器系统设计</li><li>智慧物流小车设计</li></ol></blockquote></li></ul><hr><p><strong>规划评价</strong></p><blockquote><p>将一周划分为6个上午、6个下午、7个晚上。<br>每周二上午需要备课，每周有两次核酸检测，有1天不早起，有一天或半天自由休息，可能会有规划之外的事情干扰(实验室吐槽大会、导师奇葩安排、学院莫名其妙任务活动)，可能自己的状态不佳能力不够导致效率低下任务周期变长。 </p></blockquote><p>基于以上情况：任务完成80%以上在接受范围内</p><p>上午8:00从宿舍出发，吃完早饭到达实验室预计8:30<br>下午第一节有课时不午睡，无课时2:00从宿舍出发<br>晚上6:30开始学习，22:00~22:30回寝室</p>]]></content>
      
      
      <categories>
          
          <category> 学习计划 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vision Transform学习笔记2|Self-Attention</title>
      <link href="/2022/04/13/ViT%E6%94%AF%E7%BA%BF-Self-Attention/"/>
      <url>/2022/04/13/ViT%E6%94%AF%E7%BA%BF-Self-Attention/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是Attention-注意力机制"><a href="#什么是Attention-注意力机制" class="headerlink" title="什么是Attention(注意力机制)"></a>什么是Attention(注意力机制)</h1><p>在认知科学中，由于信息处理的瓶颈，人类会选择性地关注所有信息的一部分，同时忽略其他可见的信息。通俗点来说就是，我们在认知事物时，有着明显的主观色彩和测重，比如「我喜欢踢足球，但我更喜欢打篮球」，对于人类显然知道这个人更喜欢打篮球，但对于深度学习或计算机来说，它没办法领会到「更」的含义，因此没有办法知道这个结果。所以我们在训练模型的时候，会大家「更」字的权重，让它在句子中的重要性获得更大的占比。</p><p>综上，注意力机制主要有两个方面：<strong>决定需要关注输入的哪部分</strong>；<strong>分配有限的信息处理资源给重要的部分</strong>。</p><h1 id="什么是Self-Attention"><a href="#什么是Self-Attention" class="headerlink" title="什么是Self-Attention"></a>什么是Self-Attention</h1><p>在知道了attention在机器学习中的含义之后（下文都称之为注意力机制）。人为设计的注意力机制，是非常主观的，而且没有一个准则来评定，这个权重设置为多少才好。所以，如何让模型自己对变量的权重进行<strong>自赋值</strong>成了一个问题，这个<strong>权重自赋值</strong>的过程也就是self-attention。</p><h1 id="Self-Attention原理"><a href="#Self-Attention原理" class="headerlink" title="Self-Attention原理"></a>Self-Attention原理</h1><p>$$<br>Attention(Q,K,V)&#x3D;softmax(\frac{QK^T}{\sqrt{d_k}})V<br>$$</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220413150524.png"></p><h2 id="Softmax操作"><a href="#Softmax操作" class="headerlink" title="Softmax操作"></a>Softmax操作</h2><p>抛开Q,K,V三个矩阵不谈，self-attention最原始的形态是$Softmax(XX^T)X$</p><p>这个公式表示什么意思呢？</p><p>&#x3D;&#x3D;Q1：$XX^T$代表什么？&#x3D;&#x3D;</p><p>一个矩阵乘以它自己的转置，会得到什么结果，有什么意义？</p><p>我们知道，矩阵可以看作由一些向量组成，一个矩阵乘以它自己转置的运算，其实可以看成这些向量分别与其他向量计算内积。（此时脑海里想起矩阵乘法的口诀，第一行乘以第一列、第一行乘以第二列……嗯哼，矩阵转置以后第一行不就是第一列吗？这是在计算<strong>第一个行向量与自己</strong>的内积，第一行乘以第二列是计算<strong>第一个行向量与第二个行向量的内积</strong>第一行乘以第三列是计算<strong>第一个行向量与第三个行向量的内积</strong>…..）</p><p>回想我们文章开头提出的问题，向量的内积，其几何意义是什么？</p><p><strong>A1：表征两个向量的夹角，表征一个向量在另一个向量上的投影</strong></p><p>实例：我们假设$X&#x3D;[x^T_1;x^T_2;x^T_3]$，其中X为一个二维矩阵，$X^T_i$为一个行向量，下图中模拟运算了$XX^T$：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220413153154.png"></p><p>首先，行向量$X^T_i$分别与自己和其他两个向量做内积，得到了一个新的向量。</p><p>&#x3D;&#x3D;Q2：新的向量有什么意义？表征什么？&#x3D;&#x3D;</p><p><strong>A2：投影的值大，说明两个向量相关度高。</strong></p><p>更进一步，这个向量是词向量，是词在高维空间的数值映射。词向量之间相关度高表示什么？是不是<strong>在一定程度上</strong>（不是完全）表示，在关注词A的时候，应当给予词B更多的关注？</p><p>&#x3D;&#x3D;Q3：$XX^T$的意义是什么？&#x3D;&#x3D;</p><p><strong>A3：矩阵</strong>$XX^T$<strong>是一个方阵，我们以行向量的角度理解，里面保存了每个向量与自己和其他向量进行内积运算的结果。</strong></p><p>&#x3D;&#x3D;Q4：Softmax操作的意义是什么？&#x3D;&#x3D;</p><p>回到Softmax的公式：$Softmax(z_i)&#x3D;\frac{e^{z_i}}{\sum^C_{c&#x3D;1}e^{z_c}}$</p><p><strong>A4：归一化。</strong></p><p>也就是说通过Softmax操作后，这些数字的和为1了。</p><p>&#x3D;&#x3D;Q5：那么Attention机制的核心是什么呢？&#x3D;&#x3D;</p><p><strong>A5：加权求和。</strong></p><h2 id="Q-K-V矩阵"><a href="#Q-K-V矩阵" class="headerlink" title="Q,K,V矩阵"></a>Q,K,V矩阵</h2><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220413155750.png"></p><p>在很多文章中提到的Q,K,V矩阵、查询矩阵之类的字眼，本质上都是<strong>X矩阵的线性变换</strong>，其来源是X与某个矩阵的乘积。</p><p>&#x3D;&#x3D;Q6：为什么不直接使用X而要对其进行线性变换呢？&#x3D;&#x3D;</p><p><strong>A6：当然是为了提升模型的拟合能力，矩阵W都是可以训练的，起到一个缓冲的作用。</strong></p><h2 id="sqrt-d-k-的意义"><a href="#sqrt-d-k-的意义" class="headerlink" title="$\sqrt{d_k}$的意义"></a>$\sqrt{d_k}$的意义</h2><p>假设Q,K里的元素全为0，方差为1，那么$A^T&#x3D;Q^TK$中元素的均值为0，方差为d。当d变得很大时，A中的元素的方差也会变得很大，如果A中的元素方差很大，那么Softmax(A)的分布会趋于陡峭(分布的方差大，分布集中在绝对值大的区域)。</p><p><strong>总结</strong>：Softmax(A)的分布会和d有关。因此A中每一个元素除以$\sqrt{d_k}$后，方差又变为1。这使得Softmax(A)的分布陡峭程度与d解耦，从而使得训练过程中梯度保持稳定。</p><p><strong>对self-attention来说，它跟每一个input vector都做attention，所以没有考虑到input sequence的顺序</strong>。</p><h1 id="Self-Attention的优点"><a href="#Self-Attention的优点" class="headerlink" title="Self-Attention的优点"></a>Self-Attention的优点</h1><p>与RNN相比，RNN的一个最大的问题是：前面的变量在经过多次RNN计算后，已经失去了原有的特征。越到后面，最前面的变量占比就越小，这是一个很反人类的设计。而self-attention在每次计算中都能保证每个输入变量a a<em>a</em>的初始占比是一样的，这样才能保证经过self-attention layer计算后他的注意力系数是可信的。</p><p>总结下来，它的优点是：</p><ul><li>需要学习的参数量更少</li><li>可以并行计算</li><li>能够保证每个变量初始化占比是一样的</li></ul><h1 id="Multi-head-Self-Attention"><a href="#Multi-head-Self-Attention" class="headerlink" title="Multi-head Self-Attention"></a>Multi-head Self-Attention</h1><p>这里继续讲解multi-head self-attention，所谓head也就是指一个a a<em>a</em>衍生出几个q , k , v 。上述所讲解的self-attention是基于single-head的。以2 head为例：</p><p>首先，$a^i$先生成$q^1$，$ k^1$，$ v^1$。然后，接下来就和single-head不一样了，$q^i$生成 $q^{i,1}$,$q^{i,2}$，生成的方式有两种：</p><ol><li>$q^i$乘上一个$W^{q,1}$得到 $q^{i,1}$，乘上 $W^{q,2}$得到$q^{i,2}$这个和single-head的生成是差不多的；</li><li>$q^i$**直接从通道维，平均拆分成两个，得到$ q^{i,1}$,$q^{i,2}$；</li></ol><p>这两种方式，在最后结果上都差不多。至于为啥，后面会讲一下原因。</p><p>那么这里的图解使用第1个方式，先得到$q^{i,1}$ $k^{i,1}$ $v^{i,1}$。对 $a^j$做同样的操作得到 $q^{j,1}$**, $k^{j,1}$,$ v^{j,1}$。这边需要注意的一点，$q^{i,1}$是要和$k^{j,1}$做矩阵乘法，而非$k^{j,2}$，一一对应。后面计算就和single-head一样了，最后得到$b^{i,1}$。</p><h1 id="Position-Encoding"><a href="#Position-Encoding" class="headerlink" title="Position Encoding"></a>Position Encoding</h1>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> Vision Transform </tag>
            
            <tag> Self-Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数学建模综述</title>
      <link href="/2022/04/12/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BB%BC%E8%BF%B0/"/>
      <url>/2022/04/12/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="数学建模基本题型"><a href="#数学建模基本题型" class="headerlink" title="数学建模基本题型"></a>数学建模基本题型</h1><h2 id="预测类"><a href="#预测类" class="headerlink" title="预测类"></a>预测类</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>指的是通过分析已有的数据或者现象，找出其内在发展规律，然后对未来情形做出预测的过程。<br>根据已知条件和求解目的，往往将预测类问题分为：</p><ul><li>小样本内部预测</li><li>大样本内部预测</li><li>小样本未来预测</li><li>大样本随机因素或周期特征的未来预测</li><li>大样本的未来预测</li></ul><h3 id="例题——2021年第十一届MathorCup高校数学建模挑战赛B题"><a href="#例题——2021年第十一届MathorCup高校数学建模挑战赛B题" class="headerlink" title="例题——2021年第十一届MathorCup高校数学建模挑战赛B题"></a>例题——2021年第十一届MathorCup高校数学建模挑战赛B题</h3><blockquote><p><strong>B题 三维团簇的能量预测</strong><br>团簇，也称超细小簇，属纳米材料的尺度概念。团簇是由几个乃至上<br>千个原子、分子或离子通过物理或化学结合力组成的相对稳定的微观或亚<br>微观聚集体，其物理和化学性质随所含的原子数目而变化。</p><p>团簇是材料尺度纳米材料的一个概念。团簇的空间尺度是几埃至几百埃的范围，用无机分子来描述显得太小，用小块固体描述又显得太大，许多性质既不同于单个原子分子，又不同于固体和液体，也不能用两者性质的简单线性外延或内插得到。因此，人们把团簇看成是介于原子、分子与宏观固体物质之间的物质结构的新层次。团簇科学是凝聚态物理领域中非常重要的研究方向。</p><p>团簇可以分为金属团簇和非金属团簇，由于金属团簇具有良好的催化性能，因此备受关注。但由于团簇的势能面过于复杂，同时有时候还需要考虑相对论效应等，所以搜索团簇的全局最优结构（即能量最低）显得尤为困难。其中，传统的理论计算方法需要数值迭代求解薛定谔方程，并且随原子数增加，高精度的理论计算时间呈现指数增长，非常耗时。因此，目前需要对这种方法加以改进，例如：考虑全局优化算法，结合机器学习等方法，训练团簇结构和能量的关系，从而预测新型团簇的全局最优结构，有利于发现新型团簇材料的结构和性能。请建立三维团簇能量预测的数学模型，并使用附件中的坐标和能量数据，解决下列问题。</p><p>备注：附件中数据集格式为xyz，第一行是原子数，第二行是能量，后面是原子的三维坐标。可用文本阅读器打开，并用VMD 等软件进行可视化。<br><strong>问题1</strong>：针对金属团簇，附件给出了1000 个金团簇$Au_{20}$的结构，请你们建立金团簇能量预测的数学模型，并预测金团簇$Au_{20}$ 的全局最优结构，<br>描述形状；<br><strong>问题2</strong>：在问题1 的基础上，请你们设计算法，产生金团簇不同结构的异构体，自动搜索和预测金团簇$Au_{32}$的全局最优结构，并描述其几何形<br>状，分析稳定性；<br><strong>问题3</strong>：针对非金属团簇，附件给出了3751 个硼团簇$B_{45}$的结构，请你们建立硼团簇能量预测的数学模型，并预测硼团簇B45的全局最优结构，描述形状；<br><strong>问题4</strong>：在问题3 的基础上，请你们设计算法，产生硼团簇不同结构的异构体，自动搜索和预测硼团簇$B_{40}$的全局最优结构，并描述其几何形状，分析稳定性。</p></blockquote><p><strong>注：预测问题主要是以某个小问的形式出现，很少有整个赛题所有小问全是预测要求的</strong></p><h2 id="评价类"><a href="#评价类" class="headerlink" title="评价类"></a>评价类</h2><p>指的是按照一定的标准对事物的发展或者现状进行划分的过程在数学建模中题点可体现在对生态环境，社会建设，方案策略等进行评价。评价类赛题往往没有明确的指标体系和评价标准，往往是需要查阅各类资料进行构建的，因此评价类赛题也没有明确的答案。</p><p><strong>注：解决评价类赛题的关键是指标体系的构建，构建完评价体系后在选择合适的评价方法即可，体系建立应秉承全面，准确，独立的三要素</strong></p><h2 id="机理分析类赛题"><a href="#机理分析类赛题" class="headerlink" title="机理分析类赛题"></a>机理分析类赛题</h2><p>机理分析是根据对现实对象特性的认识，分析其因果关系，找出反映内部机理的规律。在求解机理分析类问题时首先需要探寻与问题相关的物理，化学，经济等相关的知识，然后通过对已知数据或现象的分析对事物的内在规律做出必要的假设，最后通过构建合适的方程或关系式对其内在规律进行数值表达。</p><p><strong>注：机理分析立足于建立事物内部的规律，相对于其他类型的赛题均有章可循，机理分析类赛题往往需要结合众多关联知识才可以进行求解，如空气动力学，流体力学，热力学等</strong></p><h2 id="优化类"><a href="#优化类" class="headerlink" title="优化类"></a>优化类</h2><p>指在现有现有条件固定的情况下，如何使目标效果达到最佳。如在一座城市公交车公司拥有的公交车数量是固定的，问如何安排线路能够使盈利达到最高。优化类问题往往需要分析三个关键因素：目标函数，决策变量和约束条件，三者往往缺一不可。</p><p><strong>注：解决优化类赛题必须知道优化的目的，约束的条件和所求解的关键变量，需要有较强的编程能力和赛题分析挖掘能力</strong></p><h1 id="数学建模算法"><a href="#数学建模算法" class="headerlink" title="数学建模算法"></a>数学建模算法</h1><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB.png"></p>]]></content>
      
      
      <categories>
          
          <category> 数学建模 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学建模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数学建模学习笔记2|综合评价类模型</title>
      <link href="/2022/04/11/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/"/>
      <url>/2022/04/11/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>topsis综合评价法即根据有限个评价对象与理想化目标的接近程度进行排序的方法，是在现有的对象中进行相对优劣的评价，是一种逼近于理想解的排序法。</p><blockquote><p>基本过程为先将原始数据矩阵统一指标类型（一般正向化处理）得到正向化的矩阵，再对正向化的矩阵进行标准化处理以消除各指标量纲的影响，并找到有限方案中的最优方案和最劣方案，然后分别计算各评价对象与最优方案和最劣方案间的距离，获得各评价对象与最优方案的相对接近程度，以此作为评价优劣的依据。该方法对数据分布及样本含量没有严格限制，数据计算简单易行。</p></blockquote><p><strong>适用于：</strong>决策层中指标的数据是已知的，利用这些数据使得评价的更加准确。</p><h1 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h1><h2 id="统一指标类型"><a href="#统一指标类型" class="headerlink" title="统一指标类型"></a>统一指标类型</h2><p>将所有的指标转化为极大型称为<strong>指标正向化</strong>(最常用)</p><h2 id="第一步：将原始矩阵正向化"><a href="#第一步：将原始矩阵正向化" class="headerlink" title="第一步：将原始矩阵正向化"></a>第一步：将原始矩阵正向化</h2><p>常见的四种指标：</p><table><thead><tr><th align="center">指标名称</th><th align="center">指标特点</th><th align="center">例子</th></tr></thead><tbody><tr><td align="center">极大型(效益型)指标</td><td align="center">越大(多)越好</td><td align="center">成绩、GDP增速、企业利润</td></tr><tr><td align="center">极小型(成本型)指标</td><td align="center">越小(少)越好</td><td align="center">费用、坏品率、污染程度</td></tr><tr><td align="center">中间型指标</td><td align="center">越接近某个值越好</td><td align="center">水质量评估时的PH值</td></tr><tr><td align="center">区间型指标</td><td align="center">落在某个区间最好</td><td align="center">体温、水中植物性营养物量</td></tr></tbody></table><p><em>注：将原始矩阵正向化，就是要将所有的指标类型统一转化为极大型指标</em><br><strong>转换的函数形式可以不唯一</strong></p><h3 id="各种类型指标的转换"><a href="#各种类型指标的转换" class="headerlink" title="各种类型指标的转换"></a>各种类型指标的转换</h3><ul><li><p>极小型指标→极大型指标</p><ul><li><p>公式：$max-x$</p></li><li><p><strong>补充</strong>：如果所有元素均为正数，那么也可以使用1&#x2F;x</p></li></ul></li><li><p>中间型指标→极大型指标</p><ul><li><p>中间型指标：指标值既不要太大也不要太小，取某特定值最好(如水质量评估PH值)。</p></li><li><p>公式：$M&#x3D;max{|X_i-X_{best}|}$,$\widetilde{X_i}&#x3D;1-\frac{|X_i-X_{best}|}{M}$，其中{X<del>i</del>}是一组中间型指标序列，且最佳的数值为X<del>best</del>。</p></li></ul></li><li><p>区间型指标→极大型指标</p><ul><li><p>区间型指标：指标值落在某个区间内最好，例如人的体温在36°～37°这个区间比较好。</p></li><li><p>公式：$M&#x3D;max[{a-min({x_i}),max(x_i)-b}]$， $\widetilde{X_i}&#x3D;\begin{cases}{ 1-\frac{a-x_i}{M},x_i&lt;a} \ 1 ,     a\le x_i \le b\ 1-\frac{x_i-b}{M}, x_i &gt; b \end{cases}$</p><p>其中$x_i$是一组区间型指标序列，且最佳的区间为[a,b]</p></li></ul></li></ul><h2 id="第二步：正向化矩阵标准化"><a href="#第二步：正向化矩阵标准化" class="headerlink" title="第二步：正向化矩阵标准化"></a>第二步：正向化矩阵标准化</h2><p><strong>标准化的目的是消除不同指标量纲的影响</strong></p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220412222627.png"></p><h2 id="第三步：计算得分并归一化"><a href="#第三步：计算得分并归一化" class="headerlink" title="第三步：计算得分并归一化"></a>第三步：计算得分并归一化</h2><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220412222728.png"></p><h1 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h1><blockquote><p>题目：评价下表中20条河流的水质情况。<br>注：含氧量越高越好；PH值越接近7越好；细菌总数越少越好；植物性营养物量介于10‐20之间最佳，超过20或低于10均不好。<br><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220412222931.png"></p></blockquote><h1 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h1><h2 id="第一步：把数据复制到工作区，并将矩阵命名为X"><a href="#第一步：把数据复制到工作区，并将矩阵命名为X" class="headerlink" title="第一步：把数据复制到工作区，并将矩阵命名为X"></a>第一步：把数据复制到工作区，并将矩阵命名为X</h2><p>（1）在工作区右键，点击新建（Ctrl+N)，输入变量名称为X<br>（2）在Excel中复制数据，再回到Excel中右键，点击粘贴Excel数据（Ctrl+Shift+V）<br>（3）关掉这个窗口，点击X变量，右键另存为，保存为mat文件<br>注意：代码和数据要放在同一个目录下，且Matlab的当前文件夹也要是这个目录。</p><p>&#x3D;&#x3D;导入数据代码：&#x3D;&#x3D;</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load XX.mat</span><br></pre></td></tr></table></figure><h2 id="第二步：判断是否需要正向化"><a href="#第二步：判断是否需要正向化" class="headerlink" title="第二步：判断是否需要正向化"></a>第二步：判断是否需要正向化</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[n,m] = <span class="built_in">size</span>(X); <span class="comment">%将表格数据转换为矩阵</span></span><br></pre></td></tr></table></figure><p>&#x3D;&#x3D;正向化代码：&#x3D;&#x3D;</p><ul><li><p>极小型→极大型</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[posit_x]</span> = <span class="title">Min2Max</span><span class="params">(x)</span></span></span><br><span class="line">    posit_x = <span class="built_in">max</span>(x) - x;</span><br><span class="line">     <span class="comment">%posit_x = 1 ./ x;    %如果x全部都大于0，也可以这样正向化</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></li><li><p>中间型→极大型</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[posit_x]</span> = <span class="title">Mid2Max</span><span class="params">(x,best)</span></span></span><br><span class="line">    M = <span class="built_in">max</span>(<span class="built_in">abs</span>(x-best));</span><br><span class="line">    posit_x = <span class="number">1</span> - <span class="built_in">abs</span>(x-best) / M;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></li><li><p>区间型→极大型</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[posit_x]</span> = <span class="title">Inter2Max</span><span class="params">(x,a,b)</span></span></span><br><span class="line">    r_x = <span class="built_in">size</span>(x,<span class="number">1</span>);  <span class="comment">% row of x </span></span><br><span class="line">    M = <span class="built_in">max</span>([a-<span class="built_in">min</span>(x),<span class="built_in">max</span>(x)-b]);</span><br><span class="line">    posit_x = <span class="built_in">zeros</span>(r_x,<span class="number">1</span>);   <span class="comment">%zeros函数用法: zeros(3)  zeros(3,1)  ones(3)</span></span><br><span class="line">    <span class="comment">% 初始化posit_x全为0  初始化的目的是节省处理时间</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>: r_x</span><br><span class="line">        <span class="keyword">if</span> x(<span class="built_in">i</span>) &lt; a</span><br><span class="line">           posit_x(<span class="built_in">i</span>) = <span class="number">1</span>-(a-x(<span class="built_in">i</span>))/M;</span><br><span class="line">        <span class="keyword">elseif</span> x(<span class="built_in">i</span>) &gt; b</span><br><span class="line">           posit_x(<span class="built_in">i</span>) = <span class="number">1</span>-(x(<span class="built_in">i</span>)-b)/M;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">           posit_x(<span class="built_in">i</span>) = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="第三步：对正向化后的矩阵进行标准化"><a href="#第三步：对正向化后的矩阵进行标准化" class="headerlink" title="第三步：对正向化后的矩阵进行标准化"></a>第三步：对正向化后的矩阵进行标准化</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Z = X ./ <span class="built_in">repmat</span>(sum(X.*X) .^ <span class="number">0.5</span>, n, <span class="number">1</span>);</span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;标准化矩阵 Z = &#x27;</span>)</span><br><span class="line"><span class="built_in">disp</span>(Z)</span><br></pre></td></tr></table></figure><h2 id="第四步：计算与最大值的距离和最小值的距离，并算出得分"><a href="#第四步：计算与最大值的距离和最小值的距离，并算出得分" class="headerlink" title="第四步：计算与最大值的距离和最小值的距离，并算出得分"></a>第四步：计算与最大值的距离和最小值的距离，并算出得分</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">D_P = sum([(Z - <span class="built_in">repmat</span>(<span class="built_in">max</span>(Z),n,<span class="number">1</span>)) .^ <span class="number">2</span> ],<span class="number">2</span>) .^ <span class="number">0.5</span>;   <span class="comment">% D+ 与最大值的距离向量</span></span><br><span class="line">D_N = sum([(Z - <span class="built_in">repmat</span>(<span class="built_in">min</span>(Z),n,<span class="number">1</span>)) .^ <span class="number">2</span> ],<span class="number">2</span>) .^ <span class="number">0.5</span>;   <span class="comment">% D- 与最小值的距离向量</span></span><br><span class="line">S = D_N ./ (D_P+D_N);    <span class="comment">% 未归一化的得分</span></span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;最后的得分为：&#x27;</span>)</span><br><span class="line">stand_S = S / sum(S)</span><br><span class="line">[sorted_S,index] = <span class="built_in">sort</span>(stand_S ,<span class="string">&#x27;descend&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="补充——幻方矩阵"><a href="#补充——幻方矩阵" class="headerlink" title="补充——幻方矩阵"></a>补充——幻方矩阵</h2><p>A &#x3D; magic(5)  % 幻方矩阵<br>M &#x3D; magic(n)返回由1到n^2的整数构成并且总行数和总列数相等的n×n矩阵。阶次n必须为大于或等于3的标量。<br>sort(A)若A是向量不管是列还是行向量，默认都是对A进行升序排列。sort(A)是默认的升序，而sort(A,’descend’)是降序排序。<br>sort(A)若A是矩阵，默认对A的各列进行升序排列<br>sort(A,dim)<br>dim&#x3D;1时等效sort(A)<br>dim&#x3D;2时表示对A中的各行元素升序排列<br>A &#x3D; [2,1,3,8]<br>Matlab中给一维向量排序是使用sort函数：sort（A），排序是按升序进行的，其中A为待排序的向量；<br>若欲保留排列前的索引，则可用 [sA,index] &#x3D; sort(A,’descend’) ，排序后，sA是排序好的向量，index是向量sA中对A的索引。<br>sA  &#x3D;  8     3     2     1<br>index &#x3D;  4     3     1     2</p>]]></content>
      
      
      <categories>
          
          <category> 数学建模 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>碎碎念1</title>
      <link href="/2022/04/09/%E7%A2%8E%E7%A2%8E%E5%BF%B51/"/>
      <url>/2022/04/09/%E7%A2%8E%E7%A2%8E%E5%BF%B51/</url>
      
        <content type="html"><![CDATA[<p>所以你读了几篇论文？<br>写了几段代码？<br>真正思考过什么东西？<br>你真的没有在努力。</p><p>只要我还在一直读书，我就能够一直理解自己的痛苦。<br>一直与自己的无知、狭隘、偏见、阴暗见招拆招。<br>很多人说：“和自己握手言和”，<br>我不要做这样的人，我要拿着石头打磨我这块石头。<br>会一直读书，一直痛苦，一直爱着从痛苦荒芜里生出来的喜悦。<br>乘兴而来，尽兴而归，在一生中，这是很难得很难得的一件事情。</p><p>再后来我知道阅读只是理解世界的一种方式，<br>如果你有其他的方式与世界产生沟通，进行理解，<br>被世界在风雨雷电中触动，那甚至不读书也行，<br>不是必须要走的路，也不是那条路比另一条路高级，<br>你需要做的甚至也不是阅读，是与世界产生对话，理解自己所在的时代。</p><p>你知道你最大的问题是什么么？<br>误认为自己有无限的时间和无限的可能，又不知道自己需要努力的方向在哪里。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 务虚笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mAP值解析</title>
      <link href="/2022/04/06/Yolov5%E6%94%AF%E7%BA%BF%E5%AD%A6%E4%B9%A0%E4%B9%8BmAP%E5%80%BC/"/>
      <url>/2022/04/06/Yolov5%E6%94%AF%E7%BA%BF%E5%AD%A6%E4%B9%A0%E4%B9%8BmAP%E5%80%BC/</url>
      
        <content type="html"><![CDATA[<h1 id="目标检测算法评价指标——mAP值"><a href="#目标检测算法评价指标——mAP值" class="headerlink" title="目标检测算法评价指标——mAP值"></a>目标检测算法评价指标——mAP值</h1><blockquote><p>mAP值即为平均精度，是衡量目标检测算法优劣的常用指标。<br>AP（平均精度）是衡量目标检测算法好坏的常用指标，在Faster R-CNN，SSD等算法中作为评估指标。<br>AP等于recall值取0-1时，precision值的平均值。</p></blockquote><h2 id="Precision-amp-Recall-查准率和查全率"><a href="#Precision-amp-Recall-查准率和查全率" class="headerlink" title="Precision &amp; Recall(查准率和查全率)"></a>Precision &amp; Recall(查准率和查全率)</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p> <strong>Precision</strong>：衡量你的模型预测准确度。即预测的数目中正确的百分比。</p><blockquote><p>例：你预测100个图片是苹果，其中80个真的是苹果，那么你的Precision为0.8</p></blockquote><p><strong>recall</strong>：召回表示预测正确的目标数量。</p><blockquote><p>例：总共有100张苹果图片，你成功找到其中50张，那么你的recall为0.5</p></blockquote><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>以二分类结果为例：</p><p>对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为<strong>真正例(true positive)<strong>、</strong>假正例(false positive)<strong>、</strong>真反例(true negative)<strong>、</strong>假反例(false negative)<strong>四种情形，令</strong>TP</strong>、<strong>FP</strong>、<strong>TN</strong>、<strong>FN</strong>分别表示其对应的样例数，则显然有<strong>TP+FP+TN+FN&#x3D;样例总数</strong>。分类结果的“混淆矩阵”(confusion matrix)如表所示：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220409165719.png"></p><p>查准率P和查全率R分别定义为：</p><p>$ P &#x3D; \frac{TP}{TP+FP}$        $R &#x3D; \frac{TP}{TP+FN}$</p><p>一般来说查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。</p><p><strong>平衡点(BER):查准率&#x3D;查全率时的取值,用来比较模型好坏.</strong> </p><h2 id="交并比-IoU"><a href="#交并比-IoU" class="headerlink" title="交并比(IoU)"></a>交并比(IoU)</h2><p>IoU是预测框与ground truth的交集和并集的比值。</p><p>为了计算precision和recall，与所有机器学习问题一样，我们必须鉴别出<strong>True Positives</strong>（真正例）、<strong>False Positives</strong>（假正例）、<strong>True Negatives</strong>（真负例）和 <strong>False Negatives</strong>（假负例）。</p><p>假设边界框对应的IoU大于某个阈值（一般来说，比较常用的IoU阈值是0.5），我们就可以说这个预测的边界框是对的，或者说可以被划分为TP中。反之如果IoU小于阈值，那么这个预测的边界框就是错的，或者说是一个FP。如果对于图像中某个物体来说，我们的模型没有预测出对应的边界框，那么这种情况就可以被记为一次FN。</p><ul><li><strong>True Positive (TP)</strong>: IOU&gt;&#x3D;阈值的检测框</li><li><strong>False Positive (FP)</strong>: IOU&lt;阈值的检测框</li><li><strong>False Negative (FN)</strong>: 未被检测到的GT</li><li><strong>True Negative (TN)</strong>: 忽略不计</li></ul><p>对于每一个图片，ground truth数据会给出该图片中各个类别的实际物体数量。我们可以计算每个Positive预测框与ground truth的IoU值，并取最大的IoU值，认为该预测框检测到了那个IoU最大的ground truth。然后根据IoU阈值，我们可以计算出一张图片中各个类别的正确检测值（True Positives, TP）数量以及错误检测值数量（False Positives, FP）。</p><p>既然我们已经得到了正确的预测值数量（True Positives），也很容易计算出漏检的物体数（False Negatives, FN）。</p><h2 id="AP值"><a href="#AP值" class="headerlink" title="AP值"></a>AP值</h2><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><p><strong>PR曲线下面积的近似，是一个0~1之间的数值，也可用来衡量模型的performance</strong>。</p><ul><li>PR曲线比较直观，但由于曲线的上下震荡，不方便比较不同模型的PR曲线</li><li>AP是一个数字，模型的AP大，则模型更好，方便比较不同模型</li></ul><h3 id="计算方法"><a href="#计算方法" class="headerlink" title="计算方法"></a>计算方法</h3><p>计算AP值，一般有两种方法：</p><ol><li><p>11点插值法：</p><p>选取当Recall &gt;&#x3D; 0, 0.1, 0.2, …, 1共11个点时的Precision最大值，AP是这11个Precision的平均值，此时只由11个点去近似PR曲线下面积。<br>$$<br>AP &#x3D; \frac{1}{11}\sum_{r\in(0,0,,1…1)}\rho_{interp(r)}<br>$$</p><p>$$<br>\rho_{interp(r)} &#x3D; max_{\widetilde{r}:\widetilde{r}\geq{r}}\rho(\widetilde{r})<br>$$</p></li><li><p>所有点插值法：</p><p>针对每一个不同的Recall值（包括0和1），选取其大于等于这些Recall值时的Precision最大值，然后计算PR曲线下面积作为AP值：<br>$$<br>\sum_{r&#x3D;0}^{1}(r_{n+1}-r_n)\rho_{interp}(r_{n+1})<br>$$</p><p>$$<br>\rho_{interp(r)} &#x3D; max_{\widetilde{r}:\widetilde{r}\geq{r}}\rho(\widetilde{r})<br>$$</p><p>由于此方法用了所有点去近似PR曲线下面积，计算的AP比11点插值法更准确。</p></li></ol><h2 id="mAP-mean-Average-Precision-即各类别AP的平均值"><a href="#mAP-mean-Average-Precision-即各类别AP的平均值" class="headerlink" title="mAP(mean Average Precision, 即各类别AP的平均值)"></a>mAP(mean Average Precision, 即各类别AP的平均值)</h2><p>对于各个类别，分别按照上述方式计算AP，取所有类别的AP平均值就是mAP。这就是在目标检测问题中mAP的计算方法。可能有时会发生些许变化，如COCO数据集采用的计算方式更严格，其计算了不同IoU阈值和物体大小下的AP.</p><p><strong>在评测时，COCO评估了在不同的交并比(IoU)[0.5:0.05:0.95]共10个IoU下的AP，并且在最后以这些阈值下的AP平均作为结果，记为mAP@[.5, .95]。</strong></p><p>而在Pascal VOC中，检测结果只评测了IOU在0.5这个阈值下的AP值。因此相比VOC而言，COCO数据集的评测会更加全面：不仅评估到物体检测模型的分类能力，同时也能体现出检测模型的定位能力。因此在IoU较大如0.8时，预测框必须和真实的框具有很大的重叠比才能被视为正确。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Deep_Learning学习笔记2|优化模型</title>
      <link href="/2022/04/05/Deep_Learning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/"/>
      <url>/2022/04/05/Deep_Learning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/</url>
      
        <content type="html"><![CDATA[<h1 id="Deep-Learning学习笔记2"><a href="#Deep-Learning学习笔记2" class="headerlink" title="Deep_Learning学习笔记2"></a>Deep_Learning学习笔记2</h1><h2 id="极简手写数字识别模型"><a href="#极简手写数字识别模型" class="headerlink" title="极简手写数字识别模型"></a>极简手写数字识别模型</h2><h3 id="基础模型：神经网络"><a href="#基础模型：神经网络" class="headerlink" title="基础模型：神经网络"></a>基础模型：神经网络</h3><ul><li>套用房价预测的模型</li><li>输入：由28*28改为784&#x2F;每个像素值</li><li>输出：1，预测的数据值</li></ul><h3 id="以类的方式组建网络"><a href="#以类的方式组建网络" class="headerlink" title="以类的方式组建网络"></a>以类的方式组建网络</h3><ul><li>初始化函数：定义每层的函数</li><li>Forward函数：层之间的串联方式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义mnist数据识别网络结构，同房价预测网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MNIST</span>(fluid.dygraph.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name_scope</span>):</span><br><span class="line">        <span class="built_in">super</span>(MNIST, self).__init__(name_scope)</span><br><span class="line">        name_scope = self.full_name()</span><br><span class="line">        <span class="comment"># 定义一层全连接层，输出维度是1,激活函数为None，即不使用激活函数</span></span><br><span class="line">        self.fc = Linear(input_dim=<span class="number">784</span>, output_dim=<span class="number">1</span>, act=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义网络结构的前向计算过程</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = self.fc(inputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><blockquote><p>input_dim设置为784,即输入为784</p><p>output_dim为1，即网络层数为1</p><p>act为None，即不使用激活函数</p><p>在init()中申明网络结构，在forward()函数中把这些结构串联，</p></blockquote><h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><ul><li><p>代码几乎与房价预测任务一致</p></li><li><p>包含四个部分：</p><ul><li>生成模型实例，设为“训练”状态</li><li>配置优化器，SGD Optimizer</li><li>两层循环的训练过程</li><li>保存模型参数，便于后续使用</li></ul></li><li><p>仅在向模型灌入数据的代码不同</p><ul><li>先转变成np.array格式</li><li>再转换成框架内置格式 to variable</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过with语句创建一个dygraph运行的context</span></span><br><span class="line"><span class="comment"># 动态图下的一些操作需要在guard下进行</span></span><br><span class="line"><span class="keyword">with</span> fluid.dygraph.guard():</span><br><span class="line">    model = MNIST(<span class="string">&quot;mnist&quot;</span>)</span><br><span class="line">    <span class="comment"># 启动训练模式</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment"># 加载训练集 batch_size 设为 16</span></span><br><span class="line">    train_loader = paddle.batch(paddle.dataset.mnist.train(), batch_size=<span class="number">16</span>)</span><br><span class="line">    <span class="comment"># 定义优化器，使用随机梯度下降SGD优化器，学习率设置为0.001</span></span><br><span class="line">    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=<span class="number">0.001</span>,parameter_list=model.parameters())</span><br><span class="line">    EPOCH_NUM = <span class="number">10</span></span><br><span class="line">    <span class="keyword">for</span> epoch_id <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH_NUM):</span><br><span class="line">        <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">            <span class="comment"># 准备数据并转化成符合框架要求的格式</span></span><br><span class="line">            image_data = np.array([x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> data]). astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">            label_data = np.array([x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> data]). astype(<span class="string">&#x27;float32&#x27;</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 将格式转为飞桨动态图格式</span></span><br><span class="line">            image = fluid.dygraph.to_variable(image_data)</span><br><span class="line">            label = fluid.dygraph.to_variable(label_data)</span><br><span class="line">            <span class="comment"># 前向计算的过程</span></span><br><span class="line">            predict = model(image)</span><br><span class="line">            <span class="comment"># 计算损失</span></span><br><span class="line">            loss = fluid.layers.square_error_cost(predict, label)</span><br><span class="line">            avg_loss = fluid.layers.mean(loss)</span><br><span class="line">            <span class="comment"># 每训练了1000批次的数据，打印下当前Loss的情况</span></span><br><span class="line">            <span class="keyword">if</span> batch_id != <span class="number">0</span> <span class="keyword">and</span> batch_id % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;epoch_id: &#123;&#125;, batch_id: &#123;&#125;, loss is: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch_id, batch_id, avg_loss.numpy()))</span><br><span class="line">            <span class="comment"># 后向传播，更新参数的过程</span></span><br><span class="line">            avg_loss.backward()</span><br><span class="line">            optimizer.minimize(avg_loss)</span><br><span class="line">            model.clear_gradients()</span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">fluid.save_dygraph(model.state_dict(),<span class="string">&#x27;mnist1&#x27;</span>)</span><br></pre></td></tr></table></figure><p>每训练1000批次打印的Loss数据如下:</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220331155448.png"></p><p>可以看出训练的效果并不好</p><ul><li>Loss的值并没有在1以下，甚至有的还超过3</li><li>从epoch0到epoch9，Loss值总体上下降趋势并不明显</li></ul><h3 id="测试效果"><a href="#测试效果" class="headerlink" title="测试效果"></a>测试效果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试效果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">img_path</span>):</span><br><span class="line">    im = Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">    <span class="comment"># print(np.array(im))</span></span><br><span class="line">    im = im.resize((<span class="number">28</span>, <span class="number">28</span>), Image.ANTIALIAS)</span><br><span class="line">    im = np.array(im).reshape(<span class="number">1</span>, -<span class="number">1</span>).astype(np.float32)</span><br><span class="line">    im = <span class="number">2</span> - im / <span class="number">127.5</span></span><br><span class="line">    <span class="keyword">return</span> im</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义预测过程</span></span><br><span class="line"><span class="keyword">with</span> fluid.dygraph.guard():</span><br><span class="line">    model = MNIST(<span class="string">&quot;mnist&quot;</span>)</span><br><span class="line">    params_file_path = <span class="string">&#x27;mnist3&#x27;</span></span><br><span class="line">    img_path = <span class="string">&#x27;./work/example_0.jpg&#x27;</span></span><br><span class="line">    <span class="comment"># 加载数据模型</span></span><br><span class="line">    model_dict, _ = fluid.load_dygraph(<span class="string">&quot;mnist3&quot;</span>)</span><br><span class="line">    model.load_dict(model_dict)</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    tensor_img = load_image(img_path)</span><br><span class="line">    result = model(fluid.dygraph.to_variable(tensor_img))</span><br><span class="line">    <span class="comment"># 预测输出取整，即为预测的数字</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;本次预测的数字是:&quot;</span>,result.numpy().astype(<span class="string">&#x27;int32&#x27;</span>))</span><br></pre></td></tr></table></figure><p>预测的结果如下图所示:</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220331161622.png"></p><p>显然是不准确的</p><h2 id="优化版手写数字识别模型"><a href="#优化版手写数字识别模型" class="headerlink" title="优化版手写数字识别模型"></a>优化版手写数字识别模型</h2><h3 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h3><h4 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h4><ul><li><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义多层全连接神经网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MNIST</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MNIST, self).__init__()</span><br><span class="line">        <span class="comment"># 定义两层全连接隐含层，输出维度是10，当前设定隐含节点数为10，可根据任务调整</span></span><br><span class="line">        self.fc1 = Linear(in_features=<span class="number">784</span>, out_features=<span class="number">10</span>)</span><br><span class="line">        self.fc2 = Linear(in_features=<span class="number">10</span>, out_features=<span class="number">10</span>)</span><br><span class="line">        <span class="comment"># 定义一层全连接输出层，输出维度是1</span></span><br><span class="line">        self.fc3 = Linear(in_features=<span class="number">10</span>, out_features=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 定义网络的前向计算，隐含层激活函数为sigmoid，输出层不使用激活函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        <span class="comment"># inputs = paddle.reshape(inputs, [inputs.shape[0], 784])</span></span><br><span class="line">        outputs1 = self.fc1(inputs)</span><br><span class="line">        outputs1 = F.sigmoid(outputs1)</span><br><span class="line">        outputs2 = self.fc2(outputs1)</span><br><span class="line">        outputs2 = F.sigmoid(outputs2)</span><br><span class="line">        outputs_final = self.fc3(outputs2)</span><br><span class="line">        <span class="keyword">return</span> outputs_final</span><br></pre></td></tr></table></figure><blockquote><ul><li>输入层的尺度为28×28，但批次计算的时候会统一加1个维度（大小为batch size）。</li><li>中间的两个隐含层为10×10的结构，激活函数使用常见的Sigmoid函数。</li><li>与房价预测模型一样，模型的输出是回归一个数字，输出层的尺寸设置成1。</li></ul></blockquote></li><li><p>训练效果</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220331200615.png"></p></li></ul><h4 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h4><ul><li><p>代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多层卷积神经网络实现</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MNIST</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MNIST, self).__init__()</span><br><span class="line">        <span class="comment"># 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2</span></span><br><span class="line">        self.conv1 = Conv2D(in_channels=<span class="number">1</span>, out_channels=<span class="number">20</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 定义池化层，池化核的大小kernel_size为2，池化步长为2</span></span><br><span class="line">        self.max_pool1 = MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2</span></span><br><span class="line">        self.conv2 = Conv2D(in_channels=<span class="number">20</span>, out_channels=<span class="number">20</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 定义池化层，池化核的大小kernel_size为2，池化步长为2</span></span><br><span class="line">        self.max_pool2 = MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 定义一层全连接层，输出维度是1</span></span><br><span class="line">        self.fc = Linear(input_dim=<span class="number">980</span>, output_dim=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出</span></span><br><span class="line">    <span class="comment"># 卷积层激活函数使用Relu，全连接层不使用激活函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        x = self.conv1(inputs)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.max_pool1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.max_pool2(x)</span><br><span class="line">        x = paddle.reshape(x, [x.shape[<span class="number">0</span>], -<span class="number">1</span>])</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></li><li><p>训练结果如下</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220331201203.png"></p><p><strong>比较经典全连接神经网络和卷积神经网络的损失变化，可以发现卷积神经网络的损失值下降更快，且最终的损失值更小。</strong></p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><h4 id="均方误差"><a href="#均方误差" class="headerlink" title="均方误差"></a>均方误差</h4><p>上述卷积神经网络的模型的损失函数用的即为均方误差。</p><h4 id="交叉熵——sigmoid"><a href="#交叉熵——sigmoid" class="headerlink" title="交叉熵——sigmoid()"></a>交叉熵——sigmoid()</h4><p>修改计算损失的函数:</p><ul><li>从：<code>loss = paddle.nn.functional.square_error_cost(predict, label)</code></li><li>到：<code>loss = paddle.nn.functional.cross_entropy(predict, label)</code></li></ul><p>训练结果如下：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220331210432.png"></p><h3 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h3><p>在深度学习神经网络模型中，通常使用标准的随机梯度下降算法更新参数，学习率代表参数更新幅度的大小，即步长。当学习率最优时，模型的有效容量最大，最终能达到的效果最好。学习率和深度学习任务类型有关，合适的学习率往往需要大量的实验和调参经验。探索学习率最优值时需要注意如下两点：</p><ul><li><strong>学习率不是越小越好</strong>。学习率越小，损失函数的变化速度越慢，意味着我们需要花费更长的时间进行收敛，如 <strong>图2</strong> 左图所示。</li><li><strong>学习率不是越大越好</strong>。只根据总样本集中的一个批次计算梯度，抽样误差会导致计算出的梯度不是全局最优的方向，且存在波动。在接近最优解时，过大的学习率会导致参数在最优解附近震荡，损失难以收敛，如 <strong>图2</strong> 右图所示。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220331210808.png"></p><h4 id="设置学习率"><a href="#设置学习率" class="headerlink" title="设置学习率"></a>设置学习率</h4><p>在训练前，我们往往不清楚一个特定问题设置成怎样的学习率是合理的，因此在训练时可以尝试调小或调大，通过观察Loss下降的情况判断合理的学习率，设置学习率的代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置不同初始学习率</span></span><br><span class="line">opt = paddle.optimizer.SGD(learning_rate=<span class="number">0.001</span>, parameters=model.parameters())</span><br><span class="line"><span class="comment"># opt = paddle.optimizer.SGD(learning_rate=0.0001, parameters=model.parameters())</span></span><br><span class="line"><span class="comment"># opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())</span></span><br></pre></td></tr></table></figure><h4 id="学习率的主流优化算法"><a href="#学习率的主流优化算法" class="headerlink" title="学习率的主流优化算法"></a>学习率的主流优化算法</h4><p>学习率是优化器的一个参数，调整学习率看似是一件非常麻烦的事情，需要不断的调整步长，观察训练时间和Loss的变化。经过研究员的不断的实验，当前已经形成了四种比较成熟的优化算法：SGD、Momentum、AdaGrad和Adam，效果如下图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220331211905.png"></p><ul><li><strong>SGD</strong>： 随机梯度下降算法，每次训练少量数据，抽样偏差导致的参数收敛过程中震荡。</li><li><strong>Momentum</strong>： 引入物理“动量”的概念，累积速度，减少震荡，使参数更新的方向更稳定。</li></ul><blockquote><p>每个批次的数据含有抽样误差，导致梯度更新的方向波动较大。如果我们引入物理动量的概念，给梯度下降的过程加入一定的“惯性”累积，就可以减少更新路径上的震荡，即每次更新的梯度由“历史多次梯度的累积方向”和“当次梯度”加权相加得到。历史多次梯度的累积方向往往是从全局视角更正确的方向，这与“惯性”的物理概念很像，也是为何其起名为“Momentum”的原因。类似不同品牌和材质的篮球有一定的重量差别，街头篮球队中的投手（擅长中远距离投篮）喜欢稍重篮球的比例较高。一个很重要的原因是，重的篮球惯性大，更不容易受到手势的小幅变形或风吹的影响。</p></blockquote><ul><li><strong>AdaGrad</strong>： 根据不同参数距离最优解的远近，动态调整学习率。学习率逐渐下降，依据各参数变化大小调整学习率。</li></ul><blockquote><p>通过调整学习率的实验可以发现：当某个参数的现值距离最优解较远时（表现为梯度的绝对值较大），我们期望参数更新的步长大一些，以便更快收敛到最优解。当某个参数的现值距离最优解较近时（表现为梯度的绝对值较小），我们期望参数的更新步长小一些，以便更精细的逼近最优解。类似于打高尔夫球，专业运动员第一杆开球时，通常会大力打一个远球，让球尽量落在洞口附近。当第二杆面对离洞口较近的球时，他会更轻柔而细致的推杆，避免将球打飞。与此类似，参数更新的步长应该随着优化过程逐渐减少，减少的程度与当前梯度的大小有关。根据这个思想编写的优化算法称为“AdaGrad”，Ada是Adaptive的缩写，表示“适应环境而变化”的意思。RMSProp是在AdaGrad基础上的改进，学习率随着梯度变化而适应，解决AdaGrad学习率急剧下降的问题。</p></blockquote><ul><li><strong>Adam</strong>： 由于动量和自适应学习率两个优化思路是正交的，因此可以将两个思路结合起来，这就是当前广泛应用的算法。</li></ul><h4 id="利用不同的优化算法训练模型"><a href="#利用不同的优化算法训练模型" class="headerlink" title="利用不同的优化算法训练模型"></a>利用不同的优化算法训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#四种优化算法的设置方案，可以逐一尝试效果</span></span><br><span class="line">    opt = paddle.optimizer.SGD(learning_rate=<span class="number">0.01</span>, parameters=model.parameters())</span><br><span class="line">    <span class="comment"># opt = paddle.optimizer.Momentum(learning_rate=0.01, momentum=0.9, parameters=model.parameters())</span></span><br><span class="line">    <span class="comment"># opt = paddle.optimizer.Adagrad(learning_rate=0.01, parameters=model.parameters())</span></span><br><span class="line">    <span class="comment"># opt = paddle.optimizer.Adam(learning_rate=0.01, parameters=model.parameters())</span></span><br></pre></td></tr></table></figure><h3 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h3><p>在深度学习中，超参数有很多，比如学习率α、使用momentum或Adam优化算法的参数（β1，β2，ε）、层数layers、不同层隐藏单元数hidden units、学习率衰退、mini&#x3D;batch的大小等。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> deep_learning </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文献阅读3|EfficientNet</title>
      <link href="/2022/04/04/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB3/"/>
      <url>/2022/04/04/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB3/</url>
      
        <content type="html"><![CDATA[<h1 id="文献阅读3-EfficientNet-Rethinking-Model-Scaling-for-Convolutional-Neural-Networks"><a href="#文献阅读3-EfficientNet-Rethinking-Model-Scaling-for-Convolutional-Neural-Networks" class="headerlink" title="文献阅读3|EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"></a>文献阅读3|EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h1><h2 id="Intrudoction"><a href="#Intrudoction" class="headerlink" title="Intrudoction"></a>Intrudoction</h2><p>在论文中，作者介绍了<strong>放大卷积神经网络</strong>是一种常见的提高模型准确率的方法。但是在传统的方法中，通常只是在某单一维度上进行放大（<strong>宽度width</strong>，<strong>深度depth</strong>，<strong>图片分辨率resolution</strong>），宽度就是网络中的过滤器的数量，因为增加了过滤器的数量，该层的输出的通道数就相应变大了，深度可以理解为整个网络结构的长度，即网络中layer的数量。那么为什么在这几个维度上进行放大可以提高准确率？因为增加了图片的分辨率或则增加了网络的宽度，网络就能够捕获到更过细节的特征，而增加网络的深度能够捕获到更丰富和更复杂的特征。<br>虽然也可以任意的放大两个或三个维度，但是因为维度变多，设计空间也随之变大，因此随意的放大多个维度需要耗费较大的人力来调整，并且也通常会一个次优的精度和效率。因此作者通过研究实验提出了一种新的缩放方法——复合缩放方法(compound scaling method)。</p><p>在一些手工设计网络中(如AlexNET、VGG、ResNet等)，我们常常会有这样的疑问：为什么输入图像分辨率要固定为224，为什么卷积的个数要设置为这个值？为什么网络的深度设为这么深？这些问题你要问设计作者的话，估计回复就四个字——工程经验。<br>这篇论文使用NAS(Neural Architecture Search)技术来搜索网络的图像输入分辨率r，网络的深度depth，以及channel的宽度width三个参数的合理化配置。<br>        EfficientNetB0到B7与其他网络的对比如下图所示:</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220402161317.png"></p><p>为什么在这几个维度上进行放大可以提高准确率呢？因为增加了图片的分辨率或则增加了网络的宽度，网络就能够捕获到更过细节的特征，而增加网络的深度能够捕获到更丰富和更复杂的特征。</p><p>虽然也可以任意的放大两个或三个维度，但是因为维度变多，设计空间也随之变大，因此随意的放大多个维度需要耗费较大的人力来调整，并且也通常会有一个次优的精度和效率。因此作者通过研究实验提出了一种新的缩放方法——**复合缩放方法(compound scaling method)**。<br>下图所展示的便是放大神经网络的几种方法：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220402162025.png"></p><p>在之前的论文中，有的会通过增加网络的<strong>width</strong>即增加卷积核的个数(增加特征矩阵的<strong>channels</strong>)来提升网络的性能(上图b)，有的会通过增加网络的<strong>深度</strong>即<strong>使用更多的层结构</strong>来提升网络的性能(上图c)，有的会通过增加输入网络的分辨率来提升网络的性能(上图d)。而在本篇论文中会同时增加网络的<strong>width</strong>、网络的<strong>深度</strong>以及输入网络的<strong>分辨率</strong>来提升网络的性能(上图e)</p><p>但是因为网络结构的缩放并不会改变具体某一层的卷积操作，所以一个良好的基线网络是必须的，作者在论文中也提出了一种新的基线网络结构——<strong>EfficientNet</strong>。</p><h2 id="compound-scaling-method"><a href="#compound-scaling-method" class="headerlink" title="compound scaling method"></a>compound scaling method</h2><h3 id="论文思想"><a href="#论文思想" class="headerlink" title="论文思想"></a>论文思想</h3><ul><li><p><strong>Depth（d）</strong>：缩放网络深度是许多卷积网络中最常用的方法。<em>更深的卷积网络能够捕获到更丰富和复杂的特征，但是更深的网络由于存在<strong>梯度消失</strong>的问题而难以训练。</em>尽管有一些方法可以解决梯度消失（例如 跨层连接skip connections和批量归一化 batch normalization），但是对于非常深的网络所获得的准确率的增益会减弱。例如ResNet-1000和ResNet-101有着相近的准确率尽管depth相差很大。<em>下图的中间的曲线图表示用不同的深度系数d缩放模型的准确率曲线，并且表明了对于非常深的网络，准确率的增益会减弱。</em></p><blockquote><p>The intuition is that deeper ConvNet can capture richer and more complex features, and generalize well on new tasks. However, deeper networks are also more difficult to train due to the vanishing gradient problem</p></blockquote></li><li><p><strong>Width（w）</strong>：缩放网络宽度对于小规模的网络也是很常用的一种方式。<em>更宽的网络更能够捕捉到更多细节的特征，也更容易训练。</em>很宽但很浅的网络结构很难捕捉到更高层次的特征。<em>下图中左边的曲线图则是作者的不同宽度系数实验结果曲线，当w不断增大的时候，准确率很快就饱和了。</em></p><blockquote><p>wider networks tend to be able to capture more fine-grained features and are easier to train. However, extremely wide but shallow networks tend to have difficulties in capturing higher level features.</p></blockquote></li><li><p><strong>Resolution（r）</strong>：使用更高分辨率的图像，网络能够捕获到更细粒度的特模式。增加输入网络的图像分辨率能够潜在得获得更高细粒度的特征模板，但对于非常高的输入分辨率，<em>准确率的增益也会减小，并且大分辨率图像会增加计算量</em>。<em>下图中右边的曲线图则是作者的不同分辨率系数实验结果曲线，对于非常高分辨率的图像，准确率的增益会减弱。（r&#x3D;1.0表示224x224，r&#x3D;2.5表示560x560）。</em></p><blockquote><p>With higher resolution input images, ConvNets can potentially capture more fine-grained patterns. but the accuracy gain diminishes for very high resolutions.</p></blockquote></li></ul><p>下图展示了在基准<strong>EfficientNetB-0</strong>上分别增加<strong>width</strong>、<strong>depth</strong>以及<strong>resolution</strong>后得到的统计结果。通过下图可以看出大概在Accuracy达到80%时就趋于饱和了。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220402203414.png"></p><p>通过以上实验得出<strong>结论1：对网络深度、宽度和分辨率中的任一维度进行缩放都可以提高精度，但是当模型非常大时，这种放大的增益都会减弱</strong>。</p><p>接着作者又做了一个实验，采用不同的d , r 组合，然后不断改变网络的width就得到了如下图所示的4条曲线，通过分析可以发现在相同的FLOPs下，同时增加d和r的效果最好。</p><h3 id="复合缩放Compound-Scaling"><a href="#复合缩放Compound-Scaling" class="headerlink" title="复合缩放Compound Scaling"></a>复合缩放<strong>Compound Scaling</strong></h3><blockquote><p>作者通过实验发现缩放的各个维度并不是独立的。直观上来讲，对于分辨率更高的图像，我们应该增加网络深度，因为需要更大的感受野来帮助捕获更多像素点的类似特征。为了证明这种猜测，作者做了一下相关实验：比较宽度缩放在不同深度和分辨率之下对准确率的影响。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220402204530.png"></p><p><em>通过上图的结果我们可以看到d&#x3D;2.0，r&#x3D;1.3时宽度缩放在相同flops下有着更高的准确率。</em><br>得到<strong>结论2：为了达到更好的准确率和效率，在缩放时平衡网络所有维度至关重要。</strong></p><p>为了方便后续理解，我们先看下论文中通过<strong>NAS</strong>(<strong>Neural Architecture Search</strong>)技术搜索得到的EfficientNetB0的结构，如下图所示，整个网络框架由一系列Stage，$\widehat{Fi}$表示对应stage的运算操作，$\widehat{Li}$表示在该stage中重复$\widehat{Fi}$的次数：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220402210952.png"></p><p>作者在论文中对整个网络的运算进行抽象：$N(d,\omega,r) &#x3D; ^{\bigodot}<em>{i&#x3D;1…s}F_i^{L_i}(X</em>{<H_iW_iC_i>})$</p><p>其中：</p><ul><li>$ ^{\bigodot}_{i&#x3D;1…s}$表示连乘运算</li><li>$F_i$表示一个运算操作(如上图中的<strong>operator</strong>)，那么$F_i^{L_i}$表示在Stage_i中$F_i$运算被重复执行$L_i$次。</li><li>X表示输入Stage_i的特征矩阵(<strong>input tensor</strong>)</li><li>$&lt;H_i,W_i,C_i&gt;$表示X的高度，宽度以及<strong>Channels</strong>(<strong>shape</strong>)。</li></ul><p>为了探究d,r,w这三个因子对最终准确率的影响，作者将d,r,w加到公式中，我们可以得到抽象化后的优化问题(在指定资源限制下)，其中s.t.代表限制条件：</p><blockquote><p>Our target is to maximize the model accuracy for any given resource constraints, which can be formulated as an optimization problem:</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220403140239.png"></p><p>其中：</p><ul><li>d用来缩放深度$\widehat{Li}$</li><li>r用来缩放分辨率即影响$\widehat{Hi}$和$\widehat{Wi}$</li><li>$\omega$用来缩放特征矩阵的channel即$\widehat{Ci}$</li><li>target_memory为memory限制</li><li>target_flops为FlOPs限制</li></ul><p>然后，作者又提出了一种新的复合缩放方法使用了一个复合系数<strong>ϕ</strong> ，通过这个系数按照以下原则来统一的缩放<strong>网络深度</strong>、<strong>宽度</strong>和<strong>分辨率</strong>：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220402204755.png"></p><p>这里：</p><ul><li>FLOPs(理论计算量)与depth的关系是：当depth翻倍，FLOPs也翻倍。</li><li>FLOPs与width的关系是：当width翻倍(即channel翻倍)，FLOPs会翻4倍，因为卷积层的FLOPs约等于$feature_\omega \times feature_h \times feature_c \times kernel_\omega \times kernel_h \times kernel_{number}$(假设输入输出特征矩阵的高宽不变)，当width翻倍，输入特征矩阵的channels($feature_c$)和输出特征矩阵的channel或卷积核的个数($kernel_{number}$)都会翻倍，所以FLOPs会翻4倍。</li><li>FLOPs与resolution的关系是：当resolution翻倍，FLOPs也会翻4倍，和上面类似因为特征矩阵的宽度$feature_\omega$和特征矩阵的高度$feature_h$都会翻倍。</li></ul><p>所以总的FLOPs倍率可以近似用($({\alpha \cdot \beta^2 \cdot \gamma^2})^\phi$)来表示，当限制${\alpha \cdot \beta^2 \cdot \gamma^2} \approx 2$，对于任意一个$\phi$而言FLOPs想当增加了$2^\phi$倍</p><p>接下来作者在基准网络EfficientNetB-0上使用NAS来搜索$\alpha,\beta,\gamma$这三个参数。</p><ol><li>首先固定$\phi &#x3D; 1$，并基于上面给出的公式(2)和(3)进行搜索，作者发现对于EfficientNetB-0最佳参数为</li><li>接着固定$\alpha&#x3D;1.2,\beta&#x3D;1.1,\gamma&#x3D;1.15$，在EfficientNetB-0的基础上使用不同的$\phi$分别得到EfficientNetB-1至EfficientNetB-7。</li></ol><p>需要注意的是，对于不同的基准网络搜索出的α , β , γ 也不一定相同。还需要注意的是，在原论文中，作者也说了，如果直接在大模型上去搜索α , β , γ 可能获得更好的结果，但是在较大的模型中搜索成本太大，所以这篇文章就在比较小的EfficientNetB-0模型上进行搜索的。</p><blockquote><p>Notably, it is possible to achieve even better performance by searching for α, β, γ directly around a large model, but the search cost becomes prohibitively more expensive on larger models. Our method solves this issue by only doing search once on the small baseline network (step 1), and then use the same scaling coefficients for all other models (step 2).</p></blockquote><h2 id="网络详细结构"><a href="#网络详细结构" class="headerlink" title="网络详细结构"></a>网络详细结构</h2><p>下表为EfficientNet-B0的网络框架（B1-B7就是在B0的基础上修改<strong>Resolution</strong>，<strong>Channels</strong>以及<strong>Layers</strong>），可以看出网络总共分成了9个<strong>Stage</strong>，第一个Stage就是一个卷积核大小为3x3步距为2的普通卷积层（包含BN和激活函数<strong>Swish</strong>），<strong>Stage2～Stage8</strong>都是在重复堆叠<strong>MBConv</strong>结构（最后一列的<strong>Layers</strong>表示该<strong>Stage</strong>重复<strong>MBConv</strong>结构多少次），而<strong>Stage9</strong>由一个普通的1x1的卷积层（包含BN和激活函数<strong>Swish</strong>）一个平均池化层和一个全连接层组成。表格中每个<strong>MBConv</strong>后会跟一个数字1或6，这里的1或6就是倍率因子n即<strong>MBConv</strong>中第一个1x1的卷积层会将输入特征矩阵的<strong>channels</strong>扩充为n倍，其中k3x3或k5x5表示<strong>MBConv</strong>中<strong>Depthwise Conv</strong>所采用的卷积核大小。<strong>Channels</strong>表示通过该<strong>Stage</strong>后输出特征矩阵的Channels。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220403144813.png"></p><h3 id="MBConv"><a href="#MBConv" class="headerlink" title="MBConv"></a>MBConv</h3><p>MBConv其实就是MobileNetV3网络中的InvertedResidualBlock，但也有些许区别。一个是采用的激活函数不一样(EfficientNet的MBConv中使用的都是Swish激活函数)，另一个是在每个MBConv中都加入了SE(Squeeze-and-Excitation)模块。</p><p>以下结构图为B站UP主<a href="https://space.bilibili.com/18161609">霹雳吧啦Wz</a>绘制的MBConv结构。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220403145314.png"></p><p>如图所示，<strong>MBConv</strong>结构主要由一个1x1的普通卷积（升维作用，包含<strong>BN</strong>和<strong>Swish</strong>），一个<strong>kxk</strong>的<strong>Depthwise Conv</strong>卷积（包含<strong>BN</strong>和<strong>Swish</strong>）<strong>k</strong>的具体值可看<strong>EfficientNet-B0</strong>的网络框架主要有3x3和5x5两种情况，一个SE模块，一个1x1的普通卷积（降维作用，包含BN），一个<strong>Droupout</strong>层构成。搭建过程中还需要注意几点：</p><ul><li>第一个升维的<strong>1x1</strong>卷积层，它的卷积核个数是输入特征矩阵<strong>channel</strong>的n倍， $n \in \left{1, 6\right}$(n∈{1,6})。</li><li>当n &#x3D; 1时，不要第一个升维的1x1卷积层，即<strong>Stage2</strong>中的<strong>MBConv</strong>结构都没有第一个升维的1x1卷积层（这和<strong>MobileNetV3</strong>网络类似）。</li><li>关于<strong>shortcut</strong>连接，仅当输入<strong>MBConv</strong>结构的特征矩阵与输出的特征矩阵<strong>shape</strong>相同时才存在（代码中可通过$stride&#x3D;&#x3D;1 and inputc_channels&#x3D;&#x3D;output_channels$条件来判断）。</li><li>SE模块如下所示，由&#x3D;&#x3D;一个全局平均池化&#x3D;&#x3D;，&#x3D;&#x3D;两个全连接层&#x3D;&#x3D;组成。第一个全连接层的节点个数是输入该MBConv特征矩阵channels的$\frac{1}{4}$ 且使用Swish激活函数。第二个全连接层的节点个数等于Depthwise Conv层输出的特征矩阵channels，且使用Sigmoid激活函数。</li><li>Dropout层的dropout_rate在tensorflow的keras源码中对应的是drop_connect_rate后面会细讲（注意，在源码实现中只有使用shortcut的时候才有Dropout层）。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220403153958.png"></p><h3 id="EfficientNet-B0-B7-参数"><a href="#EfficientNet-B0-B7-参数" class="headerlink" title="EfficientNet(B0-B7)参数"></a>EfficientNet(B0-B7)参数</h3><table><thead><tr><th align="center">Model</th><th align="center">input_size</th><th align="center">width_coefficient</th><th align="center">depth_coefficient</th><th align="center">drop_connect_rate</th><th align="center">dropout_rate</th></tr></thead><tbody><tr><td align="center">EfficientNetB0</td><td align="center">224x224</td><td align="center">1.0</td><td align="center">1.0</td><td align="center">0.2</td><td align="center">0.2</td></tr><tr><td align="center">EfficientNetB1</td><td align="center">240×240</td><td align="center">1.0</td><td align="center">1.1</td><td align="center">0.2</td><td align="center">0.2</td></tr><tr><td align="center">EfficientNetB2</td><td align="center">260x260</td><td align="center">1.1</td><td align="center">1.2</td><td align="center">0.2</td><td align="center">0.3</td></tr><tr><td align="center">EfficientNetB3</td><td align="center">300x300</td><td align="center">1.2</td><td align="center">1.4</td><td align="center">0.2</td><td align="center">0.3</td></tr><tr><td align="center">EfficientNetB4</td><td align="center">380x380</td><td align="center">1.4</td><td align="center">1.8</td><td align="center">0.2</td><td align="center">0.4</td></tr><tr><td align="center">EfficientNetB5</td><td align="center">456x456</td><td align="center">1.6</td><td align="center">2.2</td><td align="center">0.2</td><td align="center">0.4</td></tr><tr><td align="center">EfficientNetB6</td><td align="center">528x528</td><td align="center">1.8</td><td align="center">2.6</td><td align="center">0.2</td><td align="center">0.5</td></tr><tr><td align="center">EfficientNetB7</td><td align="center">600x600</td><td align="center">2.0</td><td align="center">3.1</td><td align="center">0.2</td><td align="center">0.5</td></tr></tbody></table><ul><li><strong>input_size</strong>代表训练网络时输入网络的图像大小</li><li><strong>width_coefficient</strong>代表<strong>channel</strong>维度上的倍率因子，比如在 <strong>EfficientNetB0</strong>中<strong>Stage1</strong>的3x3卷积层所使用的卷积核个数是32，那么在B6中就是32 × 1.8 &#x3D; 57.6 32 \times 1.8&#x3D;57.632×1.8&#x3D;57.6接着取整到离它最近的8的整数倍即56，其它<strong>Stage</strong>同理。</li><li><strong>depth_coefficient</strong>代表depth维度上的倍率因子（仅针对<strong>Stage2</strong>到<strong>Stage8</strong>），比如在<strong>EfficientNetB0</strong>中<strong>Stage7</strong>的 $\widehat L_i&#x3D;4$，那么在B6中就是4 × 2.6 &#x3D; 10.4 4 \times 2.6&#x3D;10.44×2.6&#x3D;10.4接着向上取整即11。</li><li><strong>drop_connect_rate</strong>是在<strong>MBConv</strong>结构中<strong>dropout</strong>层使用的<strong>drop_rate</strong>，在官方keras模块的实现中<strong>MBConv</strong>结构的<strong>drop_rate</strong>是从0递增到<strong>drop_connect_rate</strong>的（具体实现可以看下官方源码，注意，在源码实现中只有使用<strong>shortcut</strong>的时候才有<strong>Dropout</strong>层）。还需要注意的是，这里的<strong>Dropout</strong>层是<strong>Stochastic Depth</strong>，即会随机丢掉整个<strong>block</strong>的主分支（只剩捷径分支，相当于直接跳过了这个<strong>block</strong>）也可以理解为减少了网络的深度。</li><li><strong>dropout_rate</strong>是最后一个全连接层前的<strong>dropout</strong>层（在<strong>stage9</strong>的Pooling与FC之间）的<strong>dropout_rate</strong>。</li></ul><p>最后是原论文中关于EfficientNet与当时主流网络的性能参数对比:</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220403155412.png"></p>]]></content>
      
      
      <categories>
          
          <category> 文献阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> EfficientNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文件夹指定软件打开</title>
      <link href="/2022/04/03/%E6%96%87%E4%BB%B6%E5%A4%B9%E6%8C%87%E5%AE%9A%E8%BD%AF%E4%BB%B6%E6%89%93%E5%BC%80/"/>
      <url>/2022/04/03/%E6%96%87%E4%BB%B6%E5%A4%B9%E6%8C%87%E5%AE%9A%E8%BD%AF%E4%BB%B6%E6%89%93%E5%BC%80/</url>
      
        <content type="html"><![CDATA[<h1 id="鼠标右键属性相关"><a href="#鼠标右键属性相关" class="headerlink" title="鼠标右键属性相关"></a>鼠标右键属性相关</h1><h2 id="右键文件夹指定软件打开"><a href="#右键文件夹指定软件打开" class="headerlink" title="右键文件夹指定软件打开"></a>右键文件夹指定软件打开</h2><p>GitHub上下载的代码通常需要对应的编译器打开项目文件，比如我们通常要指定用pycharm或webcharm打开相关文件夹。</p><p>教程如下：</p><ol><li>win+R，输入regedit打开注册表编辑器。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220408145825.png"></p><p>2.在路径HKEY_CURRENT_USER\SOFTWARE\Classes\Directory\shell下新建项，命名为Open Folder as XXX Project。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220408150134.png"></p><ol start="3"><li>在此文件夹右击新建字符串值Icon,属性为 软件的本地安装路径\xxx.exe</li></ol><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220408150400.png"></p><ol start="4"><li><p>在Open Folder as XXX Project文件夹下新建项Command,其值修改为 “软件的本地安装路径\xxx.exe” “%1”</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220408150617.png"></p></li><li><p>设置完成，选项即可出现在您右击文件夹之后！</p></li></ol><h2 id="删除不需要的鼠标右键属性"><a href="#删除不需要的鼠标右键属性" class="headerlink" title="删除不需要的鼠标右键属性"></a>删除不需要的鼠标右键属性</h2><ol><li><p>打开注册表</p><p>win+R -&gt; input “regedit”</p></li><li><p>在地址栏输入“HKEY_CLASSES_ROOT\Directory\shell”，并回车进入</p></li><li><p>进入ContextMenuHandlers项后，可以根据个人的需求，把鼠标右键菜单中不需要项目删掉，或者保留new项，其他的全部删掉即可删除鼠标右键菜单选项。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220408151748.png"></p>]]></content>
      
      
      <categories>
          
          <category> 使用技巧 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>远处的拉莫</title>
      <link href="/2022/04/03/%E8%BF%9C%E5%A4%84%E7%9A%84%E6%8B%89%E8%8E%AB/"/>
      <url>/2022/04/03/%E8%BF%9C%E5%A4%84%E7%9A%84%E6%8B%89%E8%8E%AB/</url>
      
        <content type="html"><![CDATA[<p><strong>“远处的拉莫在看着你，那是你的神。</strong></p><p><strong>你存在的每一秒，被痛苦占据的每一秒，他都在看着你。</strong></p><p><strong>有时候你可以感觉到他，但一生只有那么几个瞬间。”</strong></p><h1 id="2022-4-3"><a href="#2022-4-3" class="headerlink" title="2022.4.3"></a>2022.4.3</h1><p>P54<br>重要的是，我知道痛苦其他的样貌，它们像是白色的羽毛，像是水面上的烟火，像是雪山的幽灵，它们是一切不可诉说的、静默在永恒里的、被掩埋着的枯萎、灰败和消亡。</p><p>P62<br>很久之前，我就告诉自己不能被任何所击垮，只要有一瞬间的崩塌，便会迅速瓦解。</p><p>P68<br>人就是这样，要有比他们自身更糟的东西在上方控制着他们，才能不处于濒死的状态。</p><p>P69<br>有一种叫作塌陷的感受，几乎每次入睡时都会溢出来，最开始是胸腔，然后是腹部、膝盖，向上抵达脊椎，向下抵达生殖器，最后是四肢的末端，全部塌陷，然后进入睡眠。</p><p>P74<br>那些聪明人，从古至今追求着智慧的人，他们令文明得到进化，逐利使文明扩张，扩张代表着侵蚀、封锁、屠杀，然而仍有奔向智慧的人，一切糟糕的结果由他们而起，他们进化着文明的同时，让更野蛮的力量得以无限扩张。这从来都不是双刃剑，一直都是通向此刻的必然。</p><p>P79<br>上一代人总是会不遗余力地压制下一代，这与进化的意志相反。在我吃这橘子的那个夜晚，我的朋友说。他的女朋友坐在一侧，腿放在他手腕上。<br>你被压制什么了？我说<br>我被不剥夺了很多，也对抗不了，他们扣押了我所有的版权。就像现在，我把这些称作邪恶，但可能二十年后，我也会这么干。我剥夺年轻人，压制他们，利用他们，可能只是因为他们拥有的东西令我心烦。他揉着那个女人的脚，我能看出这中间有种色情的意味，情侣喜欢在公开场合以不起眼的方式调情，这种色情使他们有乐趣。如果没有旁观者，充斥在这里的只剩下乏味。<br>我能理解你，就你所说的这种邪恶，人们会在不同的年龄以不同的方式发作出来。我说。<br>童年时是什么？他说。<br>杀戮。<br>杀戮？他的女朋友抽回了脚。<br>我总觉得，虽然所有阶段都会产生杀戮，但杀戮始于童年，你身边更为强大的个体告诉你杀戮是可怕的。某个儿童敲死一片蚂蚁，这被认为是不好的，但这个不好，只是因为你屈服于周围的强大，毕竟那段日子，你没有选择任何事物的权利。<br>所以呢？朋友说。<br>所以杀戮被掩埋住，在一些年代以别的方式发泄出来。像你所说的，在一些年代你被剥夺了，在另一些年代以直接的杀戮呈现。<br>哈哈，那青年呢？女人问。<br>侵占。<br>我没觉得自己在侵占什么啊。朋友说。<br>让自己覆盖更多的事物，侵占所有可以看得到的。我仔细想想，我觉得这个民族的自负跟这个有关系。这个民族，还停留在青年人的阶段，也就是一个侵占的时期，必然会认为自己无所不能。<br>那中年呢？<br>我还不知道，但我观察到，中年已经开始向毁灭过渡了，不计任何后果地令世界丑陋下去。<br>你这样看待周遭，因此活得糟糕透顶。朋友说。<br>我无论怎么看待，这都是注定的。你能想象十几年之后的样子吗？我们还能坐在这里，你递给我两个橘子，你虚伪地跟我说起这漫长的友谊，你讲起我们的过去那看起来好玩的事情。但到了某些情况下，即便是很脆弱的情况，我认为所有人也会毫不犹豫地获得那个强大的本能。<br>十几年后，我们已经结婚很多年，有了两个孩子，会告诫他们不能变成你这样。女人笑着说。<br>他们的狗过来咬着我的拖鞋。</p><p>P83<br>愚笨是因为安逸。</p><p>P84<br>“我们无法触碰，亦不可调和”</p><p>P85<br>我们，与什么事物调和过呢？我抬起自己的手，看着那条渐变如山脊的伤痕，上面沾满了尘土，我与自身的伤口都无法调和。</p><p>P92<br>“其实听别人的故事，不会让你感受到什么。”</p><h1 id="2022-4-9"><a href="#2022-4-9" class="headerlink" title="2022.4.9"></a>2022.4.9</h1><p>P100<br>实际上，喝酒这件事，不需要破产或者家破人亡，哪怕摔伤了膝盖，或者一根手指不小心被划伤，都可以喝酒。</p><p>P136<br>“爱情有一个衰变期，如果之前没有变化的话，便会走向终结。”</p><p>P147<br>我喜欢庸俗的女人，以前还没有发现，现在我很确定了。比如归结到容貌、性格，或者其他乱七八糟的，根本不是。我只是喜欢庸俗的女人。她们考虑事情的角度差不多，有时候她们很聪明，但不会超过算清五毛钱的账。我很鄙视自己这一点，但不能控制。一开始我总以为是什么特别神秘的缘由，最后结果都是，我发现我们的生活就是坐在那，她可以做一晚上毛线球，我就在一旁刷手机，从下午到凌晨，之后我会打开窗户，如果有啤酒我也会开一瓶，站在窗前就好像发现了什么可悲的事情一样。其实一直如此，可能我三岁时就已经这样了，喜欢庸俗的女人。我们互相讲着社交网络上看来的笑话，就跟是自己身上发生的一样，再开怀大笑。有时我能笑得哭出来，但是没办法，我好像只能做这些事。比如她洗澡时会放三五年前的流行音乐，我听了也会很伤感，眼前浮现一个涂着星空眼影的过气女歌手，她一开口台下的人就开始哭，我听了也想哭，但其实我没什么好哭的。等她洗完澡走出来，我看着她，目光里都是，天啊这是世上最漂亮的女人了。就是这样的。起码今天就是这样的。”</p><h1 id="2022-4-10"><a href="#2022-4-10" class="headerlink" title="2022.4.10"></a>2022.4.10</h1><p>P173<br>我所珍藏的东西，总是在触碰的时候就轻易瓦解成粉尘，这便是一种可以称为陷阱的东西。</p><p>P184<br>我越是去经历和感受些什么，她就会越来越远离我。</p><p>P187<br>也就是说，那些十几年前所期待的——虽然我并不知道在期待什么——都没有发生，构成我生活的每一部分都原封不动地矗立在这里。</p>]]></content>
      
      
      <categories>
          
          <category> 解体与救赎 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 阅读 </tag>
            
            <tag> 文摘 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yolov5学习笔记9|YOLOv5-Face|改进原理解读与论文复现</title>
      <link href="/2022/03/30/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09/"/>
      <url>/2022/03/30/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09/</url>
      
        <content type="html"><![CDATA[<h1 id="Yolov5改进-YOLOv5-Face-改进原理解读与论文复现"><a href="#Yolov5改进-YOLOv5-Face-改进原理解读与论文复现" class="headerlink" title="Yolov5改进|YOLOv5-Face|改进原理解读与论文复现"></a>Yolov5改进|YOLOv5-Face|改进原理解读与论文复现</h1><h2 id="YOLOv5Face的设计目标和主要贡献"><a href="#YOLOv5Face的设计目标和主要贡献" class="headerlink" title="YOLOv5Face的设计目标和主要贡献"></a>YOLOv5Face的设计目标和主要贡献</h2><h3 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h3><p>YOLOv5Face针对人脸检测的对YOLOv5进行了再设计和修改，考虑到大人脸、小人脸、Landmark监督等不同的复杂性和应用。YOLOv5Face的目标是为不同的应用程序提供一个模型组合，从非常复杂的应用程序到非常简单的应用程序，以在嵌入式或移动设备上获得性能和速度的最佳权衡。</p><h3 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h3><ol><li>重新设计了YOLOV5来作为一个人脸检测器，并称之为YOLOv5Face。对网络进行了关键的修改，以提高平均平均精度(mAP)和速度方面的性能；</li><li>设计了一系列不同规模的模型，从大型模型到中型模型，再到超小模型，以满足不同应用中的需要。除了在YOLOv5中使用的Backbone外，还实现了一个基于ShuffleNetV2的Backbone，它为移动设备提供了最先进的性能和快速的速度；</li><li>在WiderFace数据集上评估了YOLOv5Face模型。在VGA分辨率的图像上，几乎所有的模型都达到了SOTA性能和速度。这也证明了前面的结论，不需要重新设计一个人脸检测器，因为YOLO5就可以完成它。</li></ol><h2 id="YOLOv5-Face的结构"><a href="#YOLOv5-Face的结构" class="headerlink" title="YOLOv5-Face的结构"></a>YOLOv5-Face的结构</h2><h3 id="YOLOv5-Face模型架构"><a href="#YOLOv5-Face模型架构" class="headerlink" title="YOLOv5-Face模型架构"></a>YOLOv5-Face模型架构</h3><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220329211411.png" alt="YOLOv5-Face架构图"></p><blockquote><p>YOLOv5Face是以YOLOv5作为Baseline来进行改进和再设计以适应人脸检测。这里主要是检测小脸和大脸的修改。</p></blockquote><p>YOLO5人脸检测器的网络架构如图1所示。它由Backbone、Neck和Head组成，描述了整体的网络体系结构。在YOLOv5中，使用了CSPNet Backbone。在Neck中使用了SPP和PAN来融合这些特征。在Head中也都使用了回归和分类。</p><h4 id="CBS-Block"><a href="#CBS-Block" class="headerlink" title="CBS Block"></a>CBS Block</h4><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220329211622.png"></p><p>在上图中重新定义了一个CBS Block，它由Conv、BN和SiLU激活函数组成。但其实架构和Yolov5的一样。</p><p>对应的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Conv</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Standard convolution</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=<span class="number">1</span>, s=<span class="number">1</span>, p=<span class="literal">None</span>, g=<span class="number">1</span>, act=<span class="literal">True</span></span>):  <span class="comment"># ch_in, ch_out, kernel, stride, padding, groups</span></span><br><span class="line">        <span class="built_in">super</span>(Conv, self).__init__()</span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># BN层</span></span><br><span class="line">        self.bn = nn.BatchNorm2d(c2)</span><br><span class="line">        <span class="comment"># SiLU激活层</span></span><br><span class="line">        self.act = nn.SiLU() <span class="keyword">if</span> act <span class="keyword">is</span> <span class="literal">True</span> <span class="keyword">else</span> (act <span class="keyword">if</span> <span class="built_in">isinstance</span>(act, nn.Module) <span class="keyword">else</span> nn.Identity())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.act(self.bn(self.conv(x)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fuseforward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.act(self.conv(x))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220329212205.png"></p><p>在上图中显示了Head的输出标签，其中包括边界框(bbox)、置信度(conf)、分类(cls)和5-Point Landmarks。这些Landmarks是对YOLOv5的改进点，使其成为一个具有Landmarks输出的人脸检测器。如果没有Landmarks，最后一个向量的长度应该是6而不是16。</p><p><strong>请注意，P3中的输出尺寸80×80×16，P4中的40×40×16，P5中的20×20×16，可选P6中的10×10×16为每个Anchor。实际的尺寸应该乘以Anchor的数量。</strong></p><h4 id="Stem-Block"><a href="#Stem-Block" class="headerlink" title="Stem Block"></a>Stem Block</h4><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220329220519.png"></p><p>上图为stem，它同于取代Yolov5中原来的Focus层(实际上在yolov5-v5.0之后就没有Focus层了)。在Yolov5中引入Stem模块用于人脸检测时Yolov5-Face创新之一。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">StemBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=<span class="number">3</span>, s=<span class="number">2</span>, p=<span class="literal">None</span>, g=<span class="number">1</span>, act=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(StemBlock, self).__init__()</span><br><span class="line">        <span class="comment"># 3×3卷积</span></span><br><span class="line">        self.stem_1 = Conv(c1, c2, k, s, p, g, act)</span><br><span class="line">        <span class="comment"># 1×1卷积</span></span><br><span class="line">        self.stem_2a = Conv(c2, c2 // <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 3×3卷积</span></span><br><span class="line">        self.stem_2b = Conv(c2 // <span class="number">2</span>, c2, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 最大池化层</span></span><br><span class="line">        self.stem_2p = nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>,ceil_mode=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 1×1卷积</span></span><br><span class="line">        self.stem_3 = Conv(c2 * <span class="number">2</span>, c2, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        stem_1_out  = self.stem_1(x)</span><br><span class="line">        stem_2a_out = self.stem_2a(stem_1_out)</span><br><span class="line">        stem_2b_out = self.stem_2b(stem_2a_out)</span><br><span class="line">        stem_2p_out = self.stem_2p(stem_1_out)</span><br><span class="line">        out = self.stem_3(torch.cat((stem_2b_out,stem_2p_out),<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>用Stem模块替代网络中原有的Focus模块，<strong>提高了网络的泛化能力，降低了计算复杂度，同时性能也没有下降</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># YOLOv5 backbone</span></span><br><span class="line">backbone:</span><br><span class="line">  <span class="comment"># [from, number, module, args]</span></span><br><span class="line">  [[-<span class="number">1</span>, <span class="number">1</span>, StemBlock, [<span class="number">64</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 0-P1/2</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">128</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]],      <span class="comment"># 2-P3/8</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">9</span>, C3, [<span class="number">256</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]],      <span class="comment"># 4-P4/16</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">9</span>, C3, [<span class="number">512</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>]],     <span class="comment"># 6-P5/32</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, SPP, [<span class="number">1024</span>, [<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>]]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">1024</span>, <span class="literal">False</span>]],      <span class="comment"># 8</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure><p>Stem模块的图示中虽然都是用的CBS，但是看代码可以看出来第2个和第4个CBS是1×1卷积，第1个和第3个CBS是3×3，stride&#x3D;2的卷积。配合yaml文件可以看到stem以后图像大小由640×640变成了160×160。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220329220426.png"></p><p>在上图中，显示了一个CSP Block(C3)。CSP Block的设计灵感来自于DenseNet。但是，不是在一些CNN层之后添加完整的输入和输出，输入被分成 2 部分。其中一半通过一个CBS Block，即一些Bottleneck Blocks，另一半是经过Conv层进行计算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">C3</span>(nn.Module):</span><br><span class="line">    <span class="comment"># CSP Bottleneck with 3 convolutions</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, n=<span class="number">1</span>, shortcut=<span class="literal">True</span>, g=<span class="number">1</span>, e=<span class="number">0.5</span></span>):  <span class="comment"># ch_in, ch_out, number, shortcut, groups, expansion</span></span><br><span class="line">        <span class="built_in">super</span>(C3, self).__init__()</span><br><span class="line">        c_ = <span class="built_in">int</span>(c2 * e)  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv3 = Conv(<span class="number">2</span> * c_, c2, <span class="number">1</span>)  <span class="comment"># act=FReLU(c2)</span></span><br><span class="line">        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=<span class="number">1.0</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><h4 id="Bottleneck-Block"><a href="#Bottleneck-Block" class="headerlink" title="Bottleneck Block"></a>Bottleneck Block</h4><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220329220241.png"></p><p>上图即为C3模块中的Bottleneck层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Standard bottleneck</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, shortcut=<span class="literal">True</span>, g=<span class="number">1</span>, e=<span class="number">0.5</span></span>):  <span class="comment"># ch_in, ch_out, shortcut, groups, expansion</span></span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line">        c_ = <span class="built_in">int</span>(c2 * e)  <span class="comment"># hidden channels</span></span><br><span class="line">        <span class="comment">#第1个CBS模块</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#第2个CBS模块</span></span><br><span class="line">        self.cv2 = Conv(c_, c2, <span class="number">3</span>, <span class="number">1</span>, g=g)</span><br><span class="line">        <span class="comment">#元素add操作</span></span><br><span class="line">        self.add = shortcut <span class="keyword">and</span> c1 == c2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x + self.cv2(self.cv1(x)) <span class="keyword">if</span> self.add <span class="keyword">else</span> self.cv2(self.cv1(x))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220329220924.png"></p><p>上图为SPP Block、。YOLOv5Face在这个Block中把YOLOv5中的13×13,9×9,5×5的kernel size被修改为7×7,5×5,3×3，这个改进更适用于人脸检测并提高了人脸检测的精度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SPP</span>(nn.Module):</span><br><span class="line">    <span class="comment"># 这里主要是讲YOLOv5中的kernel=(5,7,13)修改为(3, 5, 7)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=(<span class="params"><span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span></span>)</span>):</span><br><span class="line">        <span class="built_in">super</span>(SPP, self).__init__()</span><br><span class="line">        c_ = c1 // <span class="number">2</span>  <span class="comment"># hidden channels</span></span><br><span class="line">        <span class="comment"># 对应第1个CBS Block</span></span><br><span class="line">        self.conv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 对应第2个 cat后的 CBS Block</span></span><br><span class="line">        self.conv2 = Conv(c_ * (<span class="built_in">len</span>(k) + <span class="number">1</span>), c2, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># ModuleList=[3×3 MaxPool2d,5×5 MaxPool2d,7×7 MaxPool2d]</span></span><br><span class="line">        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=<span class="number">1</span>, padding=x // <span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> k])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> self.conv2(torch.cat([x] + [m(x) <span class="keyword">for</span> m <span class="keyword">in</span> self.m], <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>同时，YOLOv5Face添加一个stride&#x3D;64的P6输出块，P6可以提高对大人脸的检测性能。（之前的人脸检测模型大多关注提高小人脸的检测性能，这里作者关注了大人脸的检测效果，提高大人脸的检测性能来提升模型整体的检测性能）。P6的特征图大小为10x10。</p><blockquote><p>同时，YOLOv5Face添加一个stride&#x3D;64的P6输出块，P6可以提高对大人脸的检测性能。（之前的人脸检测模型大多关注提高小人脸的检测性能，这里作者关注了大人脸的检测效果，提高大人脸的检测性能来提升模型整体的检测性能）。P6的特征图大小为10x10。</p></blockquote><hr><h3 id="输入改进"><a href="#输入改进" class="headerlink" title="输入改进"></a>输入改进</h3><p>YOLOv5Face作者发现一些目标检测的数据增广方法并不适合用在人脸检测中，包括上下翻转和Mosaic数据增广。<strong>删除上下翻转可以提高模型性能</strong>。<strong>对小人脸进行Mosaic数据增广反而会降低模型性能</strong>，但是<strong>对中尺度和大尺度人脸进行Mosaic可以提高性能</strong>。<strong>随机裁剪有助于提高性能</strong>。</p><blockquote><p>这里主要还是COCO数据集和WiderFace数据集尺度有差异，WiderFace数据集小尺度数据相对较多。</p></blockquote><hr><h3 id="Landmark回归"><a href="#Landmark回归" class="headerlink" title="Landmark回归"></a>Landmark回归</h3><p>Landmark是人脸的重要特征。它们可以用于人脸比对、人脸识别、面部表情分析、年龄分析等任务。传统Landmark由68个点组成。它们被简化为5点时，这5点Landmark就被广泛应用于面部识别。人脸标识的质量直接影响人脸对齐和人脸识别的质量。</p><p>一般的物体检测器不包括Landmark。可以直接将其添加为回归Head。因此，作者将它添加到YOLO5Face中。Landmark输出将用于对齐人脸图像，然后将其发送到人脸识别网络。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220330085638.png"></p><p>用于Landmark回归的一般损失函数为L2、L1或smooth-L1。MTCNN使用的就是L2损失函数。然而，作者发现这些损失函数对小的误差并不敏感。为了克服这个问题，提出了Wing loss:</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220330085731.png"></p><p>w: 正数w将非线性部分的范围限制在[-w,w]之间；</p><p>$\varepsilon $: 约束非线性区域的曲率，并且$C&#x3D;\omega-\omega ln(1+\frac{x}{\varepsilon)}$是一个常数，可以平滑的连接分段的线性和非线性部分。$\varepsilon$的取值是一个很小的数值，因为它会使网络训练变得不稳定，并且会因为很小的误差导致梯度爆炸问题。</p><blockquote><p>实际上，的Wing loss函数的非线性部分只是简单地采用ln(x)在[$\frac{\varepsilon}{\omega},1+\frac{\varepsilon}{\omega}$]之间的曲线，并沿X轴和Y轴将其缩放比例为w。另外，沿y轴应用平移以使wing(0)&#x3D;0，并在损失函数上施加连续性。</p></blockquote><h4 id="landmark的获取："><a href="#landmark的获取：" class="headerlink" title="landmark的获取："></a>landmark的获取：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#landmarks</span></span><br><span class="line">lks = t[:,<span class="number">6</span>:<span class="number">14</span>]</span><br><span class="line">lks_mask = torch.where(lks &lt; <span class="number">0</span>, torch.full_like(lks, <span class="number">0.</span>), torch.full_like(lks, <span class="number">1.0</span>))</span><br><span class="line"><span class="comment">#应该是关键点的坐标除以anch的宽高才对，便于模型学习。使用gwh会导致不同关键点的编码不同，没有统一的参考标准</span></span><br><span class="line">lks[:, [<span class="number">0</span>, <span class="number">1</span>]] = (lks[:, [<span class="number">0</span>, <span class="number">1</span>]] - gij)</span><br><span class="line">lks[:, [<span class="number">2</span>, <span class="number">3</span>]] = (lks[:, [<span class="number">2</span>, <span class="number">3</span>]] - gij)</span><br><span class="line">lks[:, [<span class="number">4</span>, <span class="number">5</span>]] = (lks[:, [<span class="number">4</span>, <span class="number">5</span>]] - gij)</span><br><span class="line">lks[:, [<span class="number">6</span>, <span class="number">7</span>]] = (lks[:, [<span class="number">6</span>, <span class="number">7</span>]] - gij)</span><br></pre></td></tr></table></figure><p>Wing Loss的计算如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">WingLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, w=<span class="number">10</span>, e=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(WingLoss, self).__init__()</span><br><span class="line">        <span class="comment"># https://arxiv.org/pdf/1711.06753v4.pdf   Figure 5</span></span><br><span class="line">        self.w = w</span><br><span class="line">        self.e = e</span><br><span class="line">        self.C = self.w - self.w * np.log(<span class="number">1</span> + self.w / self.e)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, t, sigma=<span class="number">1</span></span>):  <span class="comment">#这里的x，t分别对应之后的pret，truel</span></span><br><span class="line">        weight = torch.ones_like(t) <span class="comment">#返回一个大小为1的张量，大小与t相同</span></span><br><span class="line">        weight[torch.where(t==-<span class="number">1</span>)] = <span class="number">0</span></span><br><span class="line">        diff = weight * (x - t)</span><br><span class="line">        abs_diff = diff.<span class="built_in">abs</span>()</span><br><span class="line">        flag = (abs_diff.data &lt; self.w).<span class="built_in">float</span>()</span><br><span class="line">        y = flag * self.w * torch.log(<span class="number">1</span> + abs_diff / self.e) + (<span class="number">1</span> - flag) * (abs_diff - self.C) <span class="comment">#全是0，1</span></span><br><span class="line">        <span class="keyword">return</span> y.<span class="built_in">sum</span>()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LandmarksLoss</span>(nn.Module):</span><br><span class="line">    <span class="comment"># BCEwithLogitLoss() with reduced missing label effects.</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, alpha=<span class="number">1.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(LandmarksLoss, self).__init__()</span><br><span class="line">        self.loss_fcn = WingLoss()<span class="comment">#nn.SmoothL1Loss(reduction=&#x27;sum&#x27;)</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, pred, truel, mask</span>): <span class="comment">#预测的，真实的 600（原来为62*10）(推测是去掉了那些没有标注的值)</span></span><br><span class="line">        loss = self.loss_fcn(pred*mask, truel*mask)  <span class="comment">#一个值（tensor）</span></span><br><span class="line">        <span class="keyword">return</span> loss / (torch.<span class="built_in">sum</span>(mask) + <span class="number">10e-14</span>)</span><br></pre></td></tr></table></figure><h4 id="分析比较L1，L2和Smooth-L1损失函数"><a href="#分析比较L1，L2和Smooth-L1损失函数" class="headerlink" title="分析比较L1，L2和Smooth L1损失函数"></a><strong>分析比较L1，L2和Smooth L1损失函数</strong></h4><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220330092332.png"></p><p>其中s是人脸关键点的ground-truth,函数f(x)就等价于：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220330092354.png"></p><p>损失函数对x的导数分别为:</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220330092423.png"></p><p>L2损失函数，<strong>当x增大时L2 loss对x的导数也增大，这就导致训练初期，预测值与ground-truth差异过大时，损失函数对预测值的梯度十分大，导致训练不稳定</strong>。</p><p>L1 loss的导数为常数，在训练后期，预测值与ground-truth差异很小时， 损失对预测值的导数的绝对值仍然为1，此时学习率(learning rate)如果不变，<strong>损失函数将在稳定值附近波动，难以继续收敛达到更高精度</strong>。</p><p>smooth L1损失函数，<strong>在x较小时，对x的梯度也会变小，而在x很大时，对x的梯度的绝对值达到上限 1，也不会太大以至于破坏网络参数。smooth L1完美地避开了L1和L2损失的缺陷</strong>。</p><p>此外，根据fast rcnn的说法，”… L1 loss that is less sensitive to outliers than the L2 loss used in R-CNN and SPPnet.” 也就是<strong>smooth L1让loss对于离群点更加鲁棒，即相比于L2损失函数，其对离群点、异常值（outlier）不敏感，梯度变化相对更小，训练时不容易跑飞</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220330092522.png"></p><p>上图描绘了这些损失函数的曲线图。需要注意的是，Smoolth L1损失是Huber损失的一种特殊情况，L2损失函数在人脸关键点检测中被广泛应用，然而，L2损失对异常值很敏感。</p><h4 id="为什么是Wing-Loss？"><a href="#为什么是Wing-Loss？" class="headerlink" title="为什么是Wing Loss？"></a>为什么是Wing Loss？</h4><p>上一部分中分析的所有损失函数在出现较大误差时表现良好。这说明神经网络的训练应更多地关注具有小或中误差的样本。为了实现此目标，提出了一种新的损失函数，即基于CNN的面部Landmark定位的Wing Loss。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220330092732.png"></p><blockquote><p>当NME在0.04的时候，测试数据比例已经接近1了，所以在0.04到0.05这一段，也就是所谓的large errros段，并没有分布更多的数据，说明各损失函数在large errors段都表现很好。</p><p>模型表现不一致的地方就在于small errors和medium errors段，例如，在NME为0.02的地方画一根竖线，相差甚远的。因此作者提出训练过程中应该更多关注samll or medium range errros样本。</p></blockquote><p>可以使用ln x来增强小误差的影响，它的梯度是$\frac{1}{x}$,对于接近0的值就会越大,optimal step size为$x^2$，这样gradient就由small errors“主导”，step size由large errors“主导”。这样可以恢复不同大小误差之间的平衡。</p><p>但是，为了防止在可能的错误方向上进行较大的更新步骤，重要的是不要过度补偿较小的定位错误的影响。这可以通过选择具有正偏移量的对数函数来实现。</p><p>但是这种类型的损失函数适用于处理相对较小的定位误差。在wild人脸关键点检测中，可能会处理极端姿势，这些姿势最初的定位误差可能非常大，在这种情况下，损失函数应促进从这些大错误中快速恢复。这表明损失函数的行为应更像L1或L2。由于L2对异常值敏感，因此选择了L1。</p><p>所以，对于小误差，它应该表现为具有偏移量的对数函数，而对于大误差，则应表现为L1。因此复合损失函数Wing Loss就诞生了。</p><h4 id="Yolov5-Face的后处理NMS"><a href="#Yolov5-Face的后处理NMS" class="headerlink" title="Yolov5-Face的后处理NMS"></a>Yolov5-Face的后处理NMS</h4><p>其实本质上没有改变，这里仅仅给出对比的代码。</p><p>Yolov5的NMS代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">non_max_suppression</span>(<span class="params">prediction, conf_thres=<span class="number">0.25</span>, iou_thres=<span class="number">0.45</span>, classes=<span class="literal">None</span>, agnostic=<span class="literal">False</span>, labels=(<span class="params"></span>)</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Performs Non-Maximum Suppression (NMS) on inference results</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">         detections with shape: nx6 (x1, y1, x2, y2, conf, cls)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"> </span><br><span class="line">    nc = prediction.shape[<span class="number">2</span>] -<span class="number">5</span>  <span class="comment"># number of classes</span></span><br></pre></td></tr></table></figure><p>Yolov5-Face的NMS代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def non_max_suppression_face(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, labels=()):</span><br><span class="line">    &quot;&quot;&quot;Performs Non-Maximum Suppression (NMS) on inference results</span><br><span class="line">    Returns:</span><br><span class="line">         detections with shape: nx6 (x1, y1, x2, y2, conf, cls)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 不同之处</span><br><span class="line">    nc = prediction.shape[2] - 15  # number of classes</span><br></pre></td></tr></table></figure><h2 id="论文复现"><a href="#论文复现" class="headerlink" title="论文复现"></a>论文复现</h2><ul><li><p>源码地址: <a href="https://github.com/deepcam-cn/yolov5-face">https://github.com/deepcam-cn/yolov5-face</a></p></li><li><p>widerface数据集: <a href="https://drive.google.com/file/d/1tU_IjyOwGQfGNUvZGwWWM4SwxKp2PUQ8/view?usp=sharing">https://drive.google.com/file/d/1tU_IjyOwGQfGNUvZGwWWM4SwxKp2PUQ8/view?usp=sharing</a></p></li></ul><blockquote><p>下载后，解压缩位置放到yolov5-face-master项目里data文件夹下的widerface文件夹下。</p></blockquote><ul><li>运行train2yolo.py和val2yolo.py</li></ul><blockquote><p>把数据集转成yolo的训练格式，</p></blockquote><ul><li>运行train.py</li></ul><h2 id="OpenCV-C-部署"><a href="#OpenCV-C-部署" class="headerlink" title="OpenCV-C++部署"></a>OpenCV-C++部署</h2><h3 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h3><p>该部分主要是输入输出尺寸、Anchor以及Strides设置等。</p><p>代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const <span class="built_in">float</span> anchors[<span class="number">3</span>][<span class="number">6</span>] = &#123; &#123;<span class="number">4</span>,<span class="number">5</span>,  <span class="number">8</span>,<span class="number">10</span>,  <span class="number">13</span>,<span class="number">16</span>&#125;, </span><br><span class="line">                              &#123;<span class="number">23</span>,<span class="number">29</span>,  <span class="number">43</span>,<span class="number">55</span>,  <span class="number">73</span>,<span class="number">105</span>&#125;,</span><br><span class="line">                              &#123;<span class="number">146</span>,<span class="number">217</span>,  <span class="number">231</span>,<span class="number">300</span>,  <span class="number">335</span>,<span class="number">433</span>&#125; &#125;;</span><br><span class="line">const <span class="built_in">float</span> stride[<span class="number">3</span>] = &#123; <span class="number">8.0</span>, <span class="number">16.0</span>, <span class="number">32.0</span> &#125;;</span><br><span class="line">const <span class="built_in">int</span> inpWidth = <span class="number">640</span>;</span><br><span class="line">const <span class="built_in">int</span> inpHeight = <span class="number">640</span>;</span><br><span class="line"><span class="built_in">float</span> confThreshold;</span><br><span class="line"><span class="built_in">float</span> nmsThreshold;</span><br><span class="line"><span class="built_in">float</span> objThreshold;</span><br></pre></td></tr></table></figure><h3 id="模型加载以及Sigmoid的定义"><a href="#模型加载以及Sigmoid的定义" class="headerlink" title="模型加载以及Sigmoid的定义"></a>模型加载以及Sigmoid的定义</h3><p>该部分主要设置ONNX模型的加载。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">YOLO::YOLO(Net_config config)</span><br><span class="line">&#123;</span><br><span class="line"> cout &lt;&lt; <span class="string">&quot;Net use &quot;</span> &lt;&lt; config.netname &lt;&lt; endl;</span><br><span class="line"> this-&gt;confThreshold = config.confThreshold;</span><br><span class="line"> this-&gt;nmsThreshold = config.nmsThreshold;</span><br><span class="line"> this-&gt;objThreshold = config.objThreshold;</span><br><span class="line"> strcpy_s(this-&gt;netname, config.netname.c_str());</span><br><span class="line"></span><br><span class="line"> string modelFile = this-&gt;netname;</span><br><span class="line"> modelFile += <span class="string">&quot;-face.onnx&quot;</span>;</span><br><span class="line"> this-&gt;net = readNet(modelFile);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void YOLO::sigmoid(Mat* out, <span class="built_in">int</span> length)</span><br><span class="line">&#123;</span><br><span class="line"> <span class="built_in">float</span>* pdata = (<span class="built_in">float</span>*)(out-&gt;data);</span><br><span class="line"> <span class="built_in">int</span> i = <span class="number">0</span>; </span><br><span class="line"> <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; length; i++)</span><br><span class="line"> &#123;</span><br><span class="line">  pdata[i] = <span class="number">1.0</span> / (<span class="number">1</span> + expf(-pdata[i]));</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="后处理部分"><a href="#后处理部分" class="headerlink" title="后处理部分"></a>后处理部分</h3><p>这里对坐标的处理和Yolov5保持一致，但是由于多出来的Landmark，所以也多出了这一部分的处理:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (box_score &gt; this-&gt;objThreshold)</span><br><span class="line">   &#123;</span><br><span class="line">    // 该部分与yolov5的保持一致</span><br><span class="line">    <span class="built_in">float</span> face_score = sigmoid_x(pdata[<span class="number">15</span>]);</span><br><span class="line">    <span class="built_in">float</span> cx = (sigmoid_x(pdata[<span class="number">0</span>]) * <span class="number">2.</span>f - <span class="number">0.5</span>f + j) * this-&gt;stride[n];  ///cx</span><br><span class="line">    <span class="built_in">float</span> cy = (sigmoid_x(pdata[<span class="number">1</span>]) * <span class="number">2.</span>f - <span class="number">0.5</span>f + i) * this-&gt;stride[n];   ///cy</span><br><span class="line">    <span class="built_in">float</span> w = powf(sigmoid_x(pdata[<span class="number">2</span>]) * <span class="number">2.</span>f, <span class="number">2.</span>f) * anchor_w;   ///w</span><br><span class="line">    <span class="built_in">float</span> h = powf(sigmoid_x(pdata[<span class="number">3</span>]) * <span class="number">2.</span>f, <span class="number">2.</span>f) * anchor_h;  ///h</span><br><span class="line"></span><br><span class="line">    <span class="built_in">int</span> left = (cx - <span class="number">0.5</span>*w)*ratiow;</span><br><span class="line">    <span class="built_in">int</span> top = (cy - <span class="number">0.5</span>*h)*ratioh;   </span><br><span class="line"></span><br><span class="line">    confidences.push_back(face_score);</span><br><span class="line">    boxes.push_back(Rect(left, top, (<span class="built_in">int</span>)(w*ratiow), (<span class="built_in">int</span>)(h*ratioh)));</span><br><span class="line">    // landmark的处理</span><br><span class="line">    vector&lt;<span class="built_in">int</span>&gt; landmark(<span class="number">10</span>);</span><br><span class="line">    <span class="keyword">for</span> (k = <span class="number">5</span>; k &lt; <span class="number">15</span>; k+=<span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">     const <span class="built_in">int</span> ind = k - <span class="number">5</span>;</span><br><span class="line">     landmark[ind] = (<span class="built_in">int</span>)(pdata[k] * anchor_w + j * this-&gt;stride[n])*ratiow;</span><br><span class="line">     landmark[ind + <span class="number">1</span>] = (<span class="built_in">int</span>)(pdata[k + <span class="number">1</span>] * anchor_h + i * this-&gt;stride[n])*ratioh;</span><br><span class="line">    &#125;</span><br><span class="line">    landmarks.push_back(landmark);</span><br><span class="line">   &#125;  </span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1].<a href="https://github.com/hpc203/yolov5-face-landmarks-opencv-v2">https://github.com/hpc203/yolov5-face-landmarks-opencv-v2</a><br>[2].<a href="https://github.com/deepcam-cn/yolov5-face">https://github.com/deepcam-cn/yolov5-face</a><br>[3].YOLO5Face: Why Reinventing a Face Detector<br>[4].<a href="https://zhuanlan.zhihu.com/p/375966269">https://zhuanlan.zhihu.com/p/375966269</a></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> yolov5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep_Learning学习笔记1</title>
      <link href="/2022/03/25/Deep_Learning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"/>
      <url>/2022/03/25/Deep_Learning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/</url>
      
        <content type="html"><![CDATA[<h1 id="Deep-Learning学习笔记——深度神经网络-DNN-实现手写数字识别"><a href="#Deep-Learning学习笔记——深度神经网络-DNN-实现手写数字识别" class="headerlink" title="Deep_Learning学习笔记——深度神经网络(DNN)实现手写数字识别"></a>Deep_Learning学习笔记——深度神经网络(DNN)实现手写数字识别</h1><p>深度神经网络（Deep Neural Networks， 以下简称DNN）是深度学习的基础，而要理解DNN，首先我们要理解DNN模型，下面我们就对DNN的模型与前向传播算法做一个总结。</p><h2 id="从感知机到神经网络"><a href="#从感知机到神经网络" class="headerlink" title="从感知机到神经网络"></a>从感知机到神经网络</h2><p>感知机接收多个输入信号，输出一个信号。如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/v2-8309413cef2521d53a8e0f8b82bc0e0c_r.jpg"></p><p>输出和输入之间学习到一个线性关系，得到中间输出结果：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/v2-91698dfe8a2cbf280d728fcda98dc6fb_r.jpg"><br>$$<br>x_i代表人们选择的输入信号，w_i为感知机的内部参数，称为权重，上图中的○通常称为“神经元”或“节点”。<br>$$<br>感知机的多个输入都有各自的权重，权重越大，对应信号的重要性就越高。</p><p>接着是一个神经元激活函数：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/v2-8d892ca795f7ef652b1b63a0f2335052_r.jpg"></p><p>当输出1时，称此神经元被激活，其中w是体现输入信号重要性的参数，而偏置b是调整神经元被激活的容易程度的参数。有时将w，b统称为权重。</p><p>这个模型只能用于二元分类，且无法学习比较复杂的非线性模型，因此在工业界无法使用。而神经网络则在感知机的模型上做了<strong>扩展</strong>，总结下主要有三点：</p><ol><li><strong>加入了隐藏层</strong>：隐藏层可以有多层，增强模型的表达能力，如下图实例，当然增加了这么多隐藏层模型的复杂度也增加了好多。</li><li><strong>输出层的神经元也可以不止一个输出，可以有多个输出</strong>，，这样模型可以灵活的应用于分类回归，以及其他的机器学习领域比如降维和聚类等。多个神经元输出的输出层对应的一个实例如下图，输出层现在有4个神经元了。</li><li>（3）对激活函数做扩展，感知机的激活函数是sign(z) ,虽然简单但是处理能力有限，因此神经网络中一般使用的其他的激活函数，比如我们在逻辑回归里面使用过的Sigmoid函数，即：</li></ol><p>$$<br>f(z)&#x3D;\frac{1}{1+e^{-z}}<br>$$</p><p>还有后来出现的tanx, softmax,和ReLU等。通过使用不同的激活函数，神经网络的表达能力进一步增强。</p><h2 id="DNN基本结构"><a href="#DNN基本结构" class="headerlink" title="DNN基本结构"></a>DNN基本结构</h2><p>神经网络是基于感知机的扩展，而DNN可以理解为有很多隐藏层的神经网络。多层神经网络和深度神经网络DNN其实也是指的一个东西，DNN有时也叫做多层感知机(Multi-Layer perceptron,MLP)。</p><p>从DNN按不同层的位置划分，DNN内部的神经网络层可以分为三类，输入层，隐藏层和输出层,如下图示例，一般来说第一层是输入层，最后一层是输出层，而中间的层数都是隐藏层。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/v2-1afa0c7d95bea01c038d82deca9d683b_720w.jpg"></p><p>层与层之间是全连接的，也就是说，第i层的任意一个神经元一定与第i+1层的任意一个神经元相连。虽然DNN看起来很复杂，但是从小的局部模型来说，还是和感知机一样，即一个线性关系<img src="F:\Blog\picture\equation1-1647673870094.svg"> 加上一个激活函数 <img src="F:\Blog\picture\equation-1647661061238-1647673900849.svg">。</p><p><strong>首先看线性关系系数w的定义。</strong>以下图一个三层的DNN为例，第二层的第4个神经元到第三层的第2个神经元的线性关系定义为<img src="F:\Blog\picture\equation-1647673316596-1647673958389.svg">.上标3代表线性系数w所在的层数，而下标对应的是输出的第三层索引2和输入的第二层索引4。你也许会问，为什么不是<img src="F:\Blog\picture\equation-1647673316631-1647674001886.svg">呢？这主要是为了便于模型用于矩阵表示运算，如果是<img src="F:\Blog\picture\equation-1647673316631-1647674022987.svg">而每次进行矩阵运算是<img src="F:\Blog\picture\equation-1647673316732-1647674053223.svg">，需要进行转置。将输出的索引放在前面的话，则线性运算不用转置，即直接为<img src="F:\Blog\picture\equation-1647673316774-1647674086090.svg">。第i−1层的第k个神经元到第l层的第j个神经元的线性系数定义为<img src="F:\Blog\picture\equation-1647673316822-1647674145381.svg">。注意，输入层是没有w参数的。</p><p><strong>再看偏倚b的定义。</strong>还是以这个三层的DNN为例，第二层的第三个神经元对应的偏倚定义为$b^2_3$.其中，上标2代表所在的层数，下标3代表偏倚所在的神经元的索引。同样的道理，第三层的第一个神经元的偏倚应该表示为$a^3_1$ .输出层是没有偏倚参数的。</p><h2 id="DNN反向传播算法"><a href="#DNN反向传播算法" class="headerlink" title="DNN反向传播算法"></a>DNN反向传播算法</h2><p>在进行DNN反向传播算法前，我们需要选择一个损失函数，来度量训练样本计算出的输出和真实的训练样本输出之间的损失。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>在神经网络中，衡量网络预测结果$y&#x3D;F(x)$与真实值$y$之间差别的指标称为<strong>损失函数</strong>。损失函数值越小，表示神经网络的预测结果越接近真实值。神经网络进行分类和回归任务时会使用不同的损失函数，下面列出一些常用的分类损失和回归损失。</p><h3 id="分类损失函数"><a href="#分类损失函数" class="headerlink" title="分类损失函数"></a>分类损失函数</h3><ol><li>Logistic损失:</li></ol><p>$$<br>loss(\widehat{y},y) &#x3D; \prod_{i&#x3D;1}^{N}\widehat{y}_i^{y_i}·{(1-\widehat{y}_i)}^{1-y_i}<br>$$</p><ol start="2"><li><p>负对数似然损失</p></li><li><p>交叉熵损失</p></li></ol><h3 id="回归损失函数"><a href="#回归损失函数" class="headerlink" title="回归损失函数"></a>回归损失函数</h3><ol><li>均方误差，也称L2损失</li><li>平均绝对误差，也称L1损失</li><li>均方对数差损失</li><li>HUber损失</li><li>Log-Cosh损失函数</li></ol><h2 id="DNN反向传播算法过程"><a href="#DNN反向传播算法过程" class="headerlink" title="DNN反向传播算法过程"></a>DNN反向传播算法过程</h2><p>由于梯度下降法有批量（Batch），小批量(mini-Batch)，随机三个变种，为了简化描述，这里我们以最基本的批量梯度下降法为例来描述反向传播算法。实际上在业界使用最多的是mini-Batch的梯度下降法。区别仅仅在于迭代时训练样本的选择。</p><p>输入：总层数<strong>L</strong>，以及各隐藏层与输出层的神经元个数，激活函数，损失函数，迭代步长<strong>a</strong>，最大迭代次数<strong>max</strong>与停止迭代阈值$\varepsilon$，输入的m个训练样本</p><p>输出：各隐藏层与输出层的线性关系系数矩阵W和偏倚向量。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deeplearning </tag>
            
            <tag> DNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文献阅读2-YoloF：You Only Look One-level Feature</title>
      <link href="/2022/03/25/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB2/"/>
      <url>/2022/03/25/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB2/</url>
      
        <content type="html"><![CDATA[<h1 id="文献阅读2-YoloF：You-Only-Look-One-level-Feature"><a href="#文献阅读2-YoloF：You-Only-Look-One-level-Feature" class="headerlink" title="文献阅读2-YoloF：You Only Look One-level Feature"></a>文献阅读2-YoloF：You Only Look One-level Feature</h1><blockquote><p>本文是旷视科技&amp;中科院孙剑团队在单阶段目标检测方面一次突破性的创新，它针对单阶段目标检测中的FPN(特征金字塔)进行了深入的分析并得出：FPN最重要的成分是分而治之的处理思路缓解了优化难问题。针对FPN的多尺度特征、分而治之思想分别提出了Dilated编码器提升特征感受野，Uniform Matching进行不同尺度目标框的匹配；结合所提两种方案得到了本文的YOLOF，在COCO数据集上，所提方案取得了与RetinaNet相当的性能且推理速度快2.5倍；所提方法取得了与YOLOv4相当的性能且推理速度快13%。</p></blockquote><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文对单阶段目标检测中的FPN进行了重思考并指出<strong>FPN的成功之处在于它对目标检测优化问题的分而治之解决思路而非多尺度特征融合</strong>。从优化的角度出发，作者引入了另一种方式替换复杂的特征金字塔来解决该优化问题：从而可以<strong>仅仅采用一级特征进行检测</strong>。基于所提简单而有效的解决方案，作者提出了YOLOF(You Only Look One-level Feature)。</p><p>YOLOF有两个关键性模块：Dilated Encoder与Uniform Matching，它们对最终的检测带来了显著的性能提升。COCO基准数据集的实验表明了所提YOLOF的有效性，YOLOF取得与RetinaNet-FPN同等的性能，同时快2.5倍；无需transformer层，YOLOF仅需一级特征即可取得与DETR相当的性能，同时训练时间少7倍。以608×608大小的图像作为输入，YOLOF取得了44.3mAP的指标且推理速度为60fps@2080Ti，它比YOLOv4快13%。</p><p>本文的贡献主要包含以下几点：</p><ul><li>FPN的关键在于针对稠密目标检测优化问题的“分而治之”解决思路，而非多尺度特征融合；</li><li>提出了一种简单而有效的无FPN的基线模型YOLOF，它包含两个关键成分(Dilated Encoder与Uniform Matching)以减轻与FPN的性能差异；</li><li>COCO数据集上的实验证明了所提方法每个成分的重要性，相比RetinaNet，DETR以及YOLOv4，所提方法取得相当的性能同时具有更快的推理速度。</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文主要针对单阶段检测器中的FPN的两个重要因素进行了研究，作者以RetinaNet为基线，通过解耦<strong>多尺度特征融合</strong>、<strong>分而治之</strong>进行实验设计。作者将FPN视作多输入多输出编码器(MiMo，见下图)，它对骨干网络的多尺度特征进行编码并为后接的解码器提供多尺度特征表达。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325110700.png"></p><p>为进行更好的对比分析，作者设计了MiMo、SiMo、MiSo、SiSo等四种类型的解码器，见上图。令人惊艳的是：<strong>SiMo编码器仅仅采用C5特征且不进行特征融合即可取得与MiMo编码器相当的性能</strong>，且性能差异小于1mAP。相反，<strong>MiSo编码器的性能则出现了显著下降</strong>。这个现象意味着：</p><ul><li>C5包含了充分的用于检测不同尺度目标的上下文信息，这促使SiMo编码器可以取得与MiMo相当的结果；</li><li>多尺度特征融合带来的收益要远小于分而治之带来的收益，因此多尺度特征融合可能并非FPN最重要的影响因素；相反，分而治之将不同尺度的目标检测进行拆分处理，缓解了优化问题。</li></ul><h2 id="Cost-Analysis-of-MiMo-Encoders"><a href="#Cost-Analysis-of-MiMo-Encoders" class="headerlink" title="Cost Analysis of MiMo Encoders"></a>Cost Analysis of MiMo Encoders</h2><p>如前所述FPN的成功在于它对于优化问题的解决思路，而非多尺度特征融合。为说明这一点，作者对FPN(即MiMo)进行了简单的分析。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325110918.png"></p><p>以RetinaNet-ResNet50为基线方案，作者将检测任务的流水线分解为三个关键部分：骨干网络、Encoder以及Decoder。下图给出了不同部分的Flops对比，可以看到：</p><ul><li>相比SiMoEncoder，MiMoEncoder带来显著的内存负载问题(134G vs 6G)；</li><li>基于MiMoEncoder的检测器推理速度明显要慢于SiSoEncoder检测器(13FPS vs 34FPS)；</li><li>这个推理速度的变慢主要是因为高分辨率特征部分的目标检测导致，即C3特征部分。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/1648177868000.png"></p><p>基于上述分析，作者期望寻找另一种解决优化问题的方案，且保持检测器检测、精确、快速。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>受上述目标驱动以及新发现：C5特征包含足够的信息进行大量目标检测，作者尝试用简单的SiSoEncoder替换复杂的MiCoEncoder。但是，这种简单的替换会带来显著性的性能下降(35.9mAP vs 23.7mAP)，见上图。对于这种情况 ，作者进行了仔细分析得出SiSoEncoder性能下降的两个重要原因：</p><ul><li>The range of scales matching to the C5 feature’s receptive field is limited</li><li>The imbalance problem on positive anchors</li></ul><p>接下来，作者将针对这两个问题进行讨论并提出对应的解决方案。</p><h3 id="Limited-Scale-Range"><a href="#Limited-Scale-Range" class="headerlink" title="Limited Scale Range"></a>Limited Scale Range</h3><p>识别不同尺寸的目标是目标检测的一个根本挑战。一种常见的方案是采用多级特征。在MiMo与SiMoEncoder检测器中，作者构建了不同感受野的多级特征(C3-C7)并在匹配尺度上进行目标检测。然而，单级特征破坏了上述游戏规则，在SiSoEncoder中仅有一个输出特征。</p><p>以下图(a)为例，C5特征感受野仅仅覆盖有限的尺度范围，当目标尺度与感受野尺度不匹配时就导致了检测性能的下降。为使得SiSoEncoder可以检测所有目标，作者需要寻找一种方案生成具有可变感受野的输出特征，以补偿多级特征的缺失。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/1648177983742.png"></p><p>在C5特征的基础上，作者采用堆叠扩张卷积方式提升其感受野。尽管其覆盖的尺度范围可以在一定程度上扩大，但它仍无法覆盖所有的目标尺度。以上图(b)为例，相比图(a)，它的感受野尺度朝着更大尺度进行了整体的偏移。然后，作者对原始尺度范围与扩大后尺度范围通过相加方式进行组合，因此得到了覆盖范围更广的输出特征，见上图(c)。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/1648178037832.png"></p><p>上图给出了采用本文所提SiSoEncoder结构示意图，作者称之为Dilated Encoder。它包含两个主要成分：Prejector与Residual Block。投影层采用1×1卷积，然后采用3×3卷积提取上下文语义信息(作用类似FPN)；然后堆叠四个不同扩张因子的残差模块以生成多感受野的输出特征(覆盖所有的目标尺度)。</p><h3 id="Imbalance-Problem-on-Positive-Anchors"><a href="#Imbalance-Problem-on-Positive-Anchors" class="headerlink" title="Imbalance Problem on Positive Anchors"></a>Imbalance Problem on Positive Anchors</h3><p>正锚点的定义对于目标检测中的优化问题尤其重要。在基于锚点的检测方案中，正锚点的定义策略主要受锚点与真实box之间的IoU决定。在RetinaNet中，如果IoU大于0.5则锚点设为正。作者称之为<em>Max-IoU matching</em>。</p><p>在MiMoEncoder中，锚点在多级特征上以稠密方式进行预定义，同时按照尺度生成特征级的正锚点。在分而治之的机制下，Max-IoU匹配使得每个尺度下的真实Box可以生成充分数量的正锚点。然而，**当作者采用SiSoEncoder时，锚点的数量会大量的减少(比如从100K减少到5K)**，导致了稀疏锚点。稀疏锚点进一步导致了采用Max-IoU匹配时的不匹配问题。以下图为例，大的目标框包含更多的正锚点，这就导致了正锚点的不平衡问题，进而导致了检测器更多关注于大目标而忽视了小目标。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/1648178166896.png"></p><p>为解决上述正锚点不平衡问题，作者提出了Uniform Matching策略：<strong>对于每个目标框采用k近邻锚点作为正锚点，这就确保了所有的目标框能够以相同数量的正锚点进行均匀匹配</strong>。正锚点的平衡确保了所有的目标框都参与了训练且贡献相等。在实现方面，参考了Max-IoU匹配，作者对<code>Uniform matching</code>中的IoU阈值进行设置以忽略大IoU负锚点和小IoU正锚点。</p><h3 id="YOLOF"><a href="#YOLOF" class="headerlink" title="YOLOF"></a>YOLOF</h3><p>基于上述解决方案呢，作者提出了一种快速而直接的单级特征检测框架YOLOF，它由骨干网络、Encoder以及Decoder构成，整体结构如下图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325111843.png"></p><ul><li>BackBone。在所有模型中，作者简单的采用了ResNet与ResNeXt作为骨干网络，所有模型在ImageNet上与训练，输出C5特征该通道数为2048，下采样倍率为32；</li><li>Encoder。在这部分，作者参考FPN添加了两个投影层，将通道数降到512，然后堆叠四个不同扩张因子的残差模块；</li><li>Decoder。在这部分，作者采用了RetinaNet的主要设计思路，它包含两个并行的任务相关的Head分别用于分类和回归。作者仅仅添加两个微小改动：(1) 参考DETR中的FFN设计让两个Head的卷积数量不同，回归Head包含4个卷积而分类Head则仅包含两个卷积；(2) 作者参考AutoAssign在回归Head上对每个锚点添加了一个隐式目标预测。</li><li>Other Detail。正如前面所提到的YOLOF中的预定义锚点是稀疏的，这会导致目标框与锚点之间的匹配质量下降。作者在图像上添加了一个随机移动操作以缓解该问题，同时作者发现这种移动对于最终的分类是有帮助的。</li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>为说明所提方案的有效性，作者在MS COC数据集上与RetinaNet、DETR、YOLOv4进行了对比。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325113201.png"></p><p>上表给出了所提方法与RetineNet在COCO数据集上的性能对比。从中可以看到：</p><ul><li>YOLOF取得了与改进版RetinaNet+相当的性能，同时减少了57%的计算量，推理速度快了2.5倍；</li><li>当采用相同骨干网络时，由于仅仅采用C5特征，YOLOF在小目标检测方面要比RetinaNet+弱一些(低3.1)；但在大目标检测方面更优(高3.3)；</li><li>当YOLOF采用ResNeXt作为骨干网络时，它可以取得与RetinaNet在小目标检测方面相当的性能且推理速度同样相当。</li><li>经由多尺度测试辅助，所提方法取得了47.1mAP的指标，且在小目标方面取得了极具竞争力的性能31.8mAP。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325113018.png"></p><p>上图给出了所提方法与DETR的性能对比。从中可以看到：</p><ul><li>YOLOF取得了与DETR相匹配的的性能；</li><li>相比DETR，YOLOF可以从更深的网络中收益更多，比如ResNet50时低0.4，在ResNet10时多了0.2；</li><li>在小目标检测方面，YOLOF要优于DETR；在大目标检测方面，YOLOF要弱于DETR。</li><li>在收敛方面，YOLOF要比DETR快7倍，这使得YOLOF更适合于作为单级特征检测器的基线。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325113409.png"></p><p>最后，作者再来看一下所提方法与YOLOv4的性能对比(注：这里采用了与YOLOv4类似的数据增强方法，并采用了三阶段训练方案，同时对骨干网络的最后阶段进行了调整)。从上表作者可以看到：</p><ul><li>YOLOF-DC5取得了比YOLOv4快13%的推理速度，且性能高0.8mAP；</li><li>YOLOF-DC5在小目标检测方面弱于YOLOv4，而在大目标检测方面显著优于YOLOv4；</li><li>这也就意味着：单级检测器具有极大的潜力获得SOTA速度-精度均衡性能。</li></ul><p>参考文献: <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_You_Only_Look_One-Level_Feature_CVPR_2021_paper.pdf">You Only Look One-level Feature</a> (点击链接下载PDF)</p><p>文献源码:<a href="https://github.com/megvii-model/YOLOF">https://github.com/megvii-model/YOLOF</a></p>]]></content>
      
      
      <categories>
          
          <category> 文献阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> yolov5 </tag>
            
            <tag> FPN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPN网络结构及源码分析</title>
      <link href="/2022/03/24/Yolov5%E6%94%AF%E7%BA%BF%E5%AD%A6%E4%B9%A0%E4%B9%8BFPN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84+%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2022/03/24/Yolov5%E6%94%AF%E7%BA%BF%E5%AD%A6%E4%B9%A0%E4%B9%8BFPN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84+%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="FPN网络结构及源码分析"><a href="#FPN网络结构及源码分析" class="headerlink" title="FPN网络结构及源码分析"></a>FPN网络结构及源码分析</h1><blockquote><p>FPN即Feature Pyramid Networks，特征金字塔。</p></blockquote><p>特征金字塔是<u><em>多尺度(muiti-scale)目标检测</em></u>领域中的重要组成部分，但是由于此方法对计算和内存的需求，在FPN之前的深度学习任务都刻意回避了这类模型。在文献阅读2中，作者利用深度神经网络固有的多尺度、多层级的金字塔结构，使用一种 <strong>自上而下的侧边连接</strong> 在所有尺度上构建出高级语义特征图，构造了特征金字塔的经典结构。</p><p>具体做法是:<strong>把低分辨率、高语义信息的高层特征和高分辨率、低语义信息的低层特征自上而下进行融合，使得所有尺度下的特征都有丰富的语义信息。</strong></p><p>其结构如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325142705.png"></p><p>在FPN网络结构中，还有很多图像算法。</p><h2 id="Featurized-image-pyramid"><a href="#Featurized-image-pyramid" class="headerlink" title="Featurized image pyramid"></a>Featurized image pyramid</h2><blockquote><p>生成不同尺寸的图片，每张图片生成不同的特征，分别进行预测，最后统计所有尺寸的预测结果。</p></blockquote><p>一种比较笨的多尺度方法，对输入图像设置不同的缩放比例实现多尺度。这样可以解决多尺度，但是相当于训练了多个模型（假设要求输入大小固定），即便允许输入大小不固定，但是也增加了存储不同尺度图像的内存空间。</p><h2 id="Single-feature-map"><a href="#Single-feature-map" class="headerlink" title="Single feature map"></a>Single feature map</h2><p>相当于早期的CNN模型，通过卷积层不断学习图像的高级语义特征。</p><blockquote><p>使用神经网络某一层输出的feature map进行预测，一般是网络最后一层feature map（例如Fast R-CNN、Faster R-CNN等）；然而靠近网络输入层的feature map包含粗略的位置信息，导致预测的目标狂bbox不准确，靠近最后网络最后一层的feature map会忽略小物体信息。</p></blockquote><h2 id="Pyramidal-feature-hierarchy"><a href="#Pyramidal-feature-hierarchy" class="headerlink" title="Pyramidal feature hierarchy"></a>Pyramidal feature hierarchy</h2><blockquote><p>使用不同层次的金字塔层feature map进行预测。SSD就是采用这种多尺度特征融合方法，从网络不同层抽取不同尺寸的特征做预测，没有增加额外的计算量。但是SSD没有使用足够底层的特征，SSD使用最底层的特征是VGG的conv4_3。</p></blockquote><p>SSD较早尝试了使用CNN金字塔形的层级特征，重用了前向过程计算出的多尺度特征图，因此这种形式是不消耗额外的资源的。但是SSD为了避免使用low-level的特征，放弃了浅层的特征图信息，直接从conv4_3开始建立金字塔，并且加入了一些新的层，但是这些低层级、高分辨率的特征图信息对检测小目标是非常重要的。</p><h2 id="Feature-Pyramid-Network"><a href="#Feature-Pyramid-Network" class="headerlink" title="Feature Pyramid Network"></a>Feature Pyramid Network</h2><blockquote><p>对最底层的特征进行向上采样，并与该底层特征进行融合，得到高分辨率、强语义的特征（即加强了特征的提取）。</p></blockquote><p>FPN为了能够自然地利用CNN层级特征的金字塔形式，同时生成在所有尺度上都具有强语义信息的特征金字塔，便以此为目的设计了top-down结构和lateral connection。这种金字塔结构以此融合具有高分辨率的浅层feature和具有丰富语义信息的深层feature。这样就实现了从单尺度的单张输入图像，快速构建在所有尺度上都具有强语义信息的特征金字塔，同时不产生明显的代价。</p><p>上述四种的FPN的网络结构如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325142959.png"></p><h2 id="FPN特征金字塔"><a href="#FPN特征金字塔" class="headerlink" title="FPN特征金字塔"></a>FPN特征金字塔</h2><p>FPN官方的backbone是ResNet。CNN的前馈计算就是自下而上的路径，特征图经过卷积核计算，通常是越变越小的，也有一些特征层的输出大小和输入大小一样。</p><p>特征金字塔网络包括自底向上、自顶向下和横向连接。</p><p>resnet特征提取（feature map）：自底向上</p><p>最后一层feature map上采样：自顶向下</p><p>特征融合：横向连接</p><p>横向连接的两层特征在空间尺寸上要相同，主要是为了利用底层的定位细节信息（由于底部的feature map包含更多的定位细节，而顶部的feature map包含更多的目标特征信息）。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> FPN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yolov5学习笔记8——v6.0源码剖析——Head部分</title>
      <link href="/2022/03/23/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08/"/>
      <url>/2022/03/23/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08/</url>
      
        <content type="html"><![CDATA[<h1 id="Yolov5学习笔记8——v6-0源码剖析——Head部分"><a href="#Yolov5学习笔记8——v6-0源码剖析——Head部分" class="headerlink" title="Yolov5学习笔记8——v6.0源码剖析——Head部分"></a>Yolov5学习笔记8——v6.0源码剖析——Head部分</h1><h2 id="Yolov5s网络结构总览"><a href="#Yolov5s网络结构总览" class="headerlink" title="Yolov5s网络结构总览"></a>Yolov5s网络结构总览</h2><blockquote><p>要了解head，就不能将其与前两部分割裂开。head中的主体部分就是三个Detect检测器，即利用基于网格的anchor在不同尺度的特征图上进行目标检测的过程。由下面的网络结构图可以很清楚的看出：当输入为640*640时，三个尺度上的特征图分别为：80x80、40x40、20x20。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325191212.png"></p><h2 id="Detect解析"><a href="#Detect解析" class="headerlink" title="Detect解析"></a>Detect解析</h2><h3 id="Detect源码"><a href="#Detect源码" class="headerlink" title="Detect源码"></a>Detect源码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Detect</span>(nn.Module):</span><br><span class="line">    stride = <span class="literal">None</span>  <span class="comment"># strides computed during build</span></span><br><span class="line">    onnx_dynamic = <span class="literal">False</span>  <span class="comment"># ONNX export parameter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nc=<span class="number">80</span>, anchors=(<span class="params"></span>), ch=(<span class="params"></span>), inplace=<span class="literal">True</span></span>):  <span class="comment"># detection layer</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.nc = nc  <span class="comment"># number of classes</span></span><br><span class="line">        self.no = nc + <span class="number">5</span>  <span class="comment"># number of outputs per anchor</span></span><br><span class="line">        self.nl = <span class="built_in">len</span>(anchors)  <span class="comment"># number of detection layers</span></span><br><span class="line">        self.na = <span class="built_in">len</span>(anchors[<span class="number">0</span>]) // <span class="number">2</span>  <span class="comment"># number of anchors</span></span><br><span class="line">        self.grid = [torch.zeros(<span class="number">1</span>)] * self.nl  <span class="comment"># init grid</span></span><br><span class="line">        self.anchor_grid = [torch.zeros(<span class="number">1</span>)] * self.nl  <span class="comment"># init anchor grid</span></span><br><span class="line">        self.register_buffer(<span class="string">&#x27;anchors&#x27;</span>, torch.tensor(anchors).<span class="built_in">float</span>().view(self.nl, -<span class="number">1</span>, <span class="number">2</span>))  <span class="comment"># shape(nl,na,2)</span></span><br><span class="line">        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, <span class="number">1</span>) <span class="keyword">for</span> x <span class="keyword">in</span> ch)  <span class="comment"># output conv</span></span><br><span class="line">        self.inplace = inplace  <span class="comment"># use in-place ops (e.g. slice assignment)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        z = []  <span class="comment"># inference output</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.nl):</span><br><span class="line">            x[i] = self.m[i](x[i])  <span class="comment"># conv</span></span><br><span class="line">            bs, _, ny, nx = x[i].shape  <span class="comment"># x(bs,255,20,20) to x(bs,3,20,20,85)</span></span><br><span class="line">            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>).contiguous()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self.training:  <span class="comment"># inference</span></span><br><span class="line">                <span class="keyword">if</span> self.onnx_dynamic <span class="keyword">or</span> self.grid[i].shape[<span class="number">2</span>:<span class="number">4</span>] != x[i].shape[<span class="number">2</span>:<span class="number">4</span>]:</span><br><span class="line">                    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)</span><br><span class="line"></span><br><span class="line">                y = x[i].sigmoid()</span><br><span class="line">                <span class="keyword">if</span> self.inplace:</span><br><span class="line">                    y[..., <span class="number">0</span>:<span class="number">2</span>] = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">                    y[..., <span class="number">2</span>:<span class="number">4</span>] = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">                <span class="keyword">else</span>:  <span class="comment"># for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953</span></span><br><span class="line">                    xy = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">                    wh = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">                    y = torch.cat((xy, wh, y[..., <span class="number">4</span>:]), -<span class="number">1</span>)</span><br><span class="line">                z.append(y.view(bs, -<span class="number">1</span>, self.no))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x <span class="keyword">if</span> self.training <span class="keyword">else</span> (torch.cat(z, <span class="number">1</span>), x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_grid</span>(<span class="params">self, nx=<span class="number">20</span>, ny=<span class="number">20</span>, i=<span class="number">0</span></span>):</span><br><span class="line">        d = self.anchors[i].device</span><br><span class="line">        <span class="keyword">if</span> check_version(torch.__version__, <span class="string">&#x27;1.10.0&#x27;</span>):  <span class="comment"># torch&gt;=1.10.0 meshgrid workaround for torch&gt;=0.7 compatibility</span></span><br><span class="line">            yv, xv = torch.meshgrid([torch.arange(ny, device=d), torch.arange(nx, device=d)], indexing=<span class="string">&#x27;ij&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            yv, xv = torch.meshgrid([torch.arange(ny, device=d), torch.arange(nx, device=d)])</span><br><span class="line">        grid = torch.stack((xv, yv), <span class="number">2</span>).expand((<span class="number">1</span>, self.na, ny, nx, <span class="number">2</span>)).<span class="built_in">float</span>()</span><br><span class="line">        anchor_grid = (self.anchors[i].clone() * self.stride[i]) \</span><br><span class="line">            .view((<span class="number">1</span>, self.na, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)).expand((<span class="number">1</span>, self.na, ny, nx, <span class="number">2</span>)).<span class="built_in">float</span>()</span><br><span class="line">        <span class="keyword">return</span> grid, anchor_grid</span><br></pre></td></tr></table></figure><h3 id="initial部分"><a href="#initial部分" class="headerlink" title="initial部分"></a>initial部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nc=<span class="number">80</span>, anchors=(<span class="params"></span>), ch=(<span class="params"></span>), inplace=<span class="literal">True</span></span>):  <span class="comment"># detection layer</span></span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.nc = nc  <span class="comment"># number of classes</span></span><br><span class="line">    self.no = nc + <span class="number">5</span>  <span class="comment"># number of outputs per anchor</span></span><br><span class="line">    self.nl = <span class="built_in">len</span>(anchors)  <span class="comment"># number of detection layers</span></span><br><span class="line">    self.na = <span class="built_in">len</span>(anchors[<span class="number">0</span>]) // <span class="number">2</span>  <span class="comment"># number of anchors</span></span><br><span class="line">    self.grid = [torch.zeros(<span class="number">1</span>)] * self.nl  <span class="comment"># init grid</span></span><br><span class="line">    self.anchor_grid = [torch.zeros(<span class="number">1</span>)] * self.nl  <span class="comment"># init anchor grid</span></span><br><span class="line">    self.register_buffer(<span class="string">&#x27;anchors&#x27;</span>, torch.tensor(anchors).<span class="built_in">float</span>().view(self.nl, -<span class="number">1</span>, <span class="number">2</span>))  <span class="comment"># shape(nl,na,2)</span></span><br><span class="line">    self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, <span class="number">1</span>) <span class="keyword">for</span> x <span class="keyword">in</span> ch)  <span class="comment"># output conv</span></span><br><span class="line">    self.inplace = inplace  <span class="comment"># use in-place ops (e.g. slice assignment)</span></span><br></pre></td></tr></table></figure><p>initial部分定义了Detect过程中的重要参数</p><ol><li>**nc:**类别数目</li><li>**no:**每个anchor的输出，包含类别数nc+置信度1+xywh4，故nc+5</li><li>**nl:**检测器的个数。以上图为例，我们有3个不同尺度上的检测器：[[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]，故检测器个数为3。</li><li>**na:**每个检测器中anchor的数量，个数为3。由于anchor是w h连续排列的，所以需要被2整除。</li><li>**grid:**检测器Detect的初始网格</li><li>**anchor_grid:**anchor的初始网格</li><li><strong>m：</strong>每个检测器的最终输出，即检测器中anchor的输出no×anchor的个数nl。打印出来很好理解（60是因为我的数据集nc为15，coco是80）：</li></ol><h3 id="forward"><a href="#forward" class="headerlink" title="forward"></a>forward</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    z = []  <span class="comment"># inference output</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.nl):</span><br><span class="line">        x[i] = self.m[i](x[i])  <span class="comment"># conv</span></span><br><span class="line">        bs, _, ny, nx = x[i].shape  <span class="comment"># x(bs,255,20,20) to x(bs,3,20,20,85)</span></span><br><span class="line">        x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>).contiguous()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.training:  <span class="comment"># inference</span></span><br><span class="line">            <span class="keyword">if</span> self.onnx_dynamic <span class="keyword">or</span> self.grid[i].shape[<span class="number">2</span>:<span class="number">4</span>] != x[i].shape[<span class="number">2</span>:<span class="number">4</span>]:</span><br><span class="line">                self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)</span><br><span class="line"></span><br><span class="line">            y = x[i].sigmoid()</span><br><span class="line">            <span class="keyword">if</span> self.inplace:</span><br><span class="line">                y[..., <span class="number">0</span>:<span class="number">2</span>] = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">                y[..., <span class="number">2</span>:<span class="number">4</span>] = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953</span></span><br><span class="line">                xy = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">                wh = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">                y = torch.cat((xy, wh, y[..., <span class="number">4</span>:]), -<span class="number">1</span>)</span><br><span class="line">            z.append(y.view(bs, -<span class="number">1</span>, self.no))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x <span class="keyword">if</span> self.training <span class="keyword">else</span> (torch.cat(z, <span class="number">1</span>), x)</span><br></pre></td></tr></table></figure><p>在forward操作中，网络接收3个不同尺度的特征图，分别为：128×80×80、256×40×40、512×20×20</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.nl):</span><br><span class="line">    x[i] = self.m[i](x[i])  <span class="comment"># conv</span></span><br><span class="line">    bs, _, ny, nx = x[i].shape  <span class="comment"># x(bs,255,20,20) to x(bs,3,20,20,85)</span></span><br><span class="line">    x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>).co</span><br></pre></td></tr></table></figure><p>网络的循环次数为3，也就是依次在这3个特征图上进行网格化预测，利用卷积操作得到通道数为no×nl的特征输出。拿128x80x80举例，在nc&#x3D;15的情况下经过卷积得到60x80x80的特征图，这个特征图就是后续用于格点检测的特征图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> self.training:  <span class="comment"># inference</span></span><br><span class="line">    <span class="keyword">if</span> self.onnx_dynamic <span class="keyword">or</span> self.grid[i].shape[<span class="number">2</span>:<span class="number">4</span>] != x[i].shape[<span class="number">2</span>:<span class="number">4</span>]:</span><br><span class="line">        self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_grid</span>(<span class="params">self, nx=<span class="number">20</span>, ny=<span class="number">20</span>, i=<span class="number">0</span></span>):</span><br><span class="line">    d = self.anchors[i].device</span><br><span class="line">    <span class="keyword">if</span> check_version(torch.__version__, <span class="string">&#x27;1.10.0&#x27;</span>):  <span class="comment"># torch&gt;=1.10.0 meshgrid workaround for torch&gt;=0.7 compatibility</span></span><br><span class="line">        yv, xv = torch.meshgrid([torch.arange(ny, device=d), torch.arange(nx, device=d)], indexing=<span class="string">&#x27;ij&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        yv, xv = torch.meshgrid([torch.arange(ny, device=d), torch.arange(nx, device=d)])</span><br><span class="line">    grid = torch.stack((xv, yv), <span class="number">2</span>).expand((<span class="number">1</span>, self.na, ny, nx, <span class="number">2</span>)).<span class="built_in">float</span>()</span><br><span class="line">    anchor_grid = (self.anchors[i].clone() * self.stride[i]) \</span><br><span class="line">        .view((<span class="number">1</span>, self.na, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)).expand((<span class="number">1</span>, self.na, ny, nx, <span class="number">2</span>)).<span class="built_in">float</span>()</span><br><span class="line">    <span class="keyword">return</span> grid, anchor_grid</span><br></pre></td></tr></table></figure><p>随后就是基于经过检测器卷积后的特征图划分网格，网格的尺寸是与输入尺寸相同的，如20x20的特征图会变成20x20的网格，那么一个网格对应到原图中就是32x32像素；40x40的一个网格就会对应到原图的16x16像素，以此类推。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">y = x[i].sigmoid()</span><br><span class="line"><span class="keyword">if</span> self.inplace:</span><br><span class="line">y[..., <span class="number">0</span>:<span class="number">2</span>] = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">y[..., <span class="number">2</span>:<span class="number">4</span>] = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line"><span class="keyword">else</span>:  <span class="comment"># for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953</span></span><br><span class="line">xy = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">wh = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">y = torch.cat((xy, wh, y[..., <span class="number">4</span>:]), -<span class="number">1</span>)</span><br><span class="line">z.append(y.view(bs, -<span class="number">1</span>, self.no))</span><br></pre></td></tr></table></figure><p>这部分代码是预测偏移的主体部分。</p><p><code>y[..., 0:2] = (y[..., 0:2] * 2 - 0.5 + self.grid[i]) * self.stride[i]  # xy</code></p><p>这一句是对x和y进行预测。x、y在输入网络前都是已经归一好的(0,1)，乘以2再减去0.5就是(-0.5,1.5)，也就是让x、y的预测能够跨网格进行。后边的<code>self.grid[i]) * self.stride[i]</code>就是将相对位置转为网格中的绝对位置。</p><p><code>y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh</code></p><p>这句是对宽和高进行预测的。</p><p><code>z.append(y.view(bs, -1, self.no))</code></p><p>最后再将结果填入z。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> yolov5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yolov5学习笔记7——v6.0源码剖析——Neck部分</title>
      <link href="/2022/03/22/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07/"/>
      <url>/2022/03/22/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07/</url>
      
        <content type="html"><![CDATA[<h1 id="Yolov5学习笔记7——v6-0源码剖析——Neck部分"><a href="#Yolov5学习笔记7——v6-0源码剖析——Neck部分" class="headerlink" title="Yolov5学习笔记7——v6.0源码剖析——Neck部分"></a>Yolov5学习笔记7——v6.0源码剖析——Neck部分</h1><blockquote><p>在网络结构配置文件yolov5s.yaml中，并未将neck和head区分开来，而是直接以head命名，这也是方便在model&#x2F;yolo.py中的加载。Yolov5学习笔记7只讨论head中的neck部分。</p></blockquote><h2 id="neck结构概览及参数"><a href="#neck结构概览及参数" class="headerlink" title="neck结构概览及参数"></a>neck结构概览及参数</h2><h3 id="neck部分结构图"><a href="#neck部分结构图" class="headerlink" title="neck部分结构图"></a>neck部分结构图</h3><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220325095329.png"></p><h3 id="neck部分参数配置源码"><a href="#neck部分参数配置源码" class="headerlink" title="neck部分参数配置源码"></a>neck部分参数配置源码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># YOLOv5 v6.0 head</span></span><br><span class="line">head:</span><br><span class="line">  [[-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, nn.Upsample, [<span class="literal">None</span>, <span class="number">2</span>, <span class="string">&#x27;nearest&#x27;</span>]],</span><br><span class="line">   [[-<span class="number">1</span>, <span class="number">6</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]],  <span class="comment"># cat backbone P4</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">512</span>, <span class="literal">False</span>]],  <span class="comment"># 13</span></span><br><span class="line"></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, nn.Upsample, [<span class="literal">None</span>, <span class="number">2</span>, <span class="string">&#x27;nearest&#x27;</span>]],</span><br><span class="line">   [[-<span class="number">1</span>, <span class="number">4</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]],  <span class="comment"># cat backbone P3</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">256</span>, <span class="literal">False</span>]],  <span class="comment"># 17 (P3/8-small)</span></span><br><span class="line"></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]],</span><br><span class="line">   [[-<span class="number">1</span>, <span class="number">14</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]],  <span class="comment"># cat head P4</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">512</span>, <span class="literal">False</span>]],  <span class="comment"># 20 (P4/16-medium)</span></span><br><span class="line"></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]],</span><br><span class="line">   [[-<span class="number">1</span>, <span class="number">10</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]],  <span class="comment"># cat head P5</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">1024</span>, <span class="literal">False</span>]],  <span class="comment"># 23 (P5/32-large)</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure><p>可以看到，Neck部分的组件相较于Backbone较为单一，基本上就由CBS、Upsample、Concat和不带shortcut的CSP（C3)。</p><h3 id="FPN和PAN"><a href="#FPN和PAN" class="headerlink" title="FPN和PAN"></a>FPN和PAN</h3><p>Neck的网络结构设计也是沿用了<strong>FPN+PAN的结构</strong>。FPN就是使用一种 自顶向下的侧边连接在所有尺度上构建出高级语义特征图，构造了特征金字塔的经典结构；PAN的结构也不稀奇，FPN中间经过多层的网络后，底层的目标信息已经非常模糊了，因此PAN又加入了自底向上的路线，弥补并加强了定位信息。</p><h2 id="Neck部分各模块"><a href="#Neck部分各模块" class="headerlink" title="Neck部分各模块"></a>Neck部分各模块</h2><h3 id="CBS模块"><a href="#CBS模块" class="headerlink" title="CBS模块"></a>CBS模块</h3><p>在Backbone中，为了进一步提取图像中的信息，CBS在改变特征图通道的同时，也会控制卷积模块中的步长s下采样来改变特征图的尺寸。Neck中左侧采用FPN自顶向下设计的过程中，是特征图上采样的过程，因此这个时候再下采样就不合时宜了，所以在FPN中s&#x3D;1；而到了右侧PAN再次自下而上提取位置信息时，就需要使用CBS继续下采样抽取高层次的语义信息，这也是CBS前后参数差异的原因。</p><h3 id="nn-Upsample"><a href="#nn-Upsample" class="headerlink" title="nn.Upsample"></a>nn.Upsample</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[-<span class="number">1</span>, <span class="number">1</span>, nn.Upsample, [<span class="literal">None</span>, <span class="number">2</span>, <span class="string">&#x27;nearest&#x27;</span>]],</span><br></pre></td></tr></table></figure><p>使用的是Pytroch内置的上采样模块，需要指定上采样的倍数和方式。</p><p>这里我们不指定size，上采样倍数为2，上采样方式为nearest，也就是最近填充。</p><h3 id="Concat"><a href="#Concat" class="headerlink" title="Concat"></a>Concat</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[-<span class="number">1</span>, <span class="number">6</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]],  <span class="comment"># cat backbone P4</span></span><br></pre></td></tr></table></figure><p>Concat即拼接，接对象通过from传入，拼接的维度由args参数指定，此处即按照维度1(channel)拼接，其他维度不变。</p><h3 id="CSP-x2F-C3"><a href="#CSP-x2F-C3" class="headerlink" title="CSP&#x2F;C3"></a>CSP&#x2F;C3</h3><p>Backbone需要更深层次的网络获取更多的信息，可以说backbone已经完成了主要特征信息的提取，所以在Neck阶段我们并不需要再一味地加深网络，采取不带残差的C3模块可能会更合适一些。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> yolov5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yolov5学习笔记6——v6.0源码剖析——Backbone部分3</title>
      <link href="/2022/03/21/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06/"/>
      <url>/2022/03/21/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06/</url>
      
        <content type="html"><![CDATA[<h1 id="Yolov5学习笔记6——v6-0源码剖析——Backbone部分3"><a href="#Yolov5学习笔记6——v6-0源码剖析——Backbone部分3" class="headerlink" title="Yolov5学习笔记6——v6.0源码剖析——Backbone部分3"></a>Yolov5学习笔记6——v6.0源码剖析——Backbone部分3</h1><h2 id="Backbone概览及参数"><a href="#Backbone概览及参数" class="headerlink" title="Backbone概览及参数"></a>Backbone概览及参数</h2><h3 id="源码如下"><a href="#源码如下" class="headerlink" title="源码如下"></a>源码如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Parameters</span></span><br><span class="line">nc: <span class="number">80</span>  <span class="comment"># number of classes</span></span><br><span class="line">depth_multiple: <span class="number">0.33</span>  <span class="comment"># model depth multiple</span></span><br><span class="line">width_multiple: <span class="number">0.50</span>  <span class="comment"># layer channel multiple</span></span><br><span class="line">anchors:</span><br><span class="line">  - [<span class="number">10</span>,<span class="number">13</span>, <span class="number">16</span>,<span class="number">30</span>, <span class="number">33</span>,<span class="number">23</span>]  <span class="comment"># P3/8</span></span><br><span class="line">  - [<span class="number">30</span>,<span class="number">61</span>, <span class="number">62</span>,<span class="number">45</span>, <span class="number">59</span>,<span class="number">119</span>]  <span class="comment"># P4/16</span></span><br><span class="line">  - [<span class="number">116</span>,<span class="number">90</span>, <span class="number">156</span>,<span class="number">198</span>, <span class="number">373</span>,<span class="number">326</span>]  <span class="comment"># P5/32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># YOLOv5 v6.0 backbone</span></span><br><span class="line">backbone:</span><br><span class="line">  <span class="comment"># [from, number, module, args]</span></span><br><span class="line">  [[-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">64</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">2</span>]],  <span class="comment"># 0-P1/2</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 1-P2/4</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">128</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 3-P3/8</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">6</span>, C3, [<span class="number">256</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 5-P4/16</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">9</span>, C3, [<span class="number">512</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 7-P5/32</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">1024</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, SPPF, [<span class="number">1024</span>, <span class="number">5</span>]],  <span class="comment"># 9</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure><blockquote><p>yolov5s的backbone部分如上，其网络结构使用yaml文件配置，通过.&#x2F;models&#x2F;yolo.py解析文件加了一个输入构成的网络模块。与v3和v4所使用的config设置的网络不同，yaml文件中的网络组件不需要进行叠加，只需要在配置文件中设置number即可。</p></blockquote><h4 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Parameters</span></span><br><span class="line">nc: <span class="number">80</span>  <span class="comment"># number of classes</span></span><br><span class="line">depth_multiple: <span class="number">0.33</span>  <span class="comment"># model depth multiple</span></span><br><span class="line">width_multiple: <span class="number">0.50</span>  <span class="comment"># layer channel multiple</span></span><br></pre></td></tr></table></figure><ul><li><p><strong>nc: 80</strong><br>代表数据集中的类别数目，例如MNIST中含有0-9共10个类.</p></li><li><p><strong>depth_multiple: 0.33</strong><br>用来控制模型的深度，仅在number≠1时启用。 如第一个C3层（c3具体是什么后续介绍）的参数设置为[-1, 3, C3, [128]]，其中number&#x3D;3，表示在v5s中含有1个C3（3*0.33）；同理，v5l中的C3个数就是3（v5l的depth_multiple参数为1）。</p></li><li><p><strong>width_multiple: 0.50</strong><br>用来控制模型的宽度，主要作用于args中的ch_out。如第一个Conv层，ch_out&#x3D;64，那么在v5s实际运算过程中，会将卷积过程中的卷积核设为64x0.5，所以会输出32通道的特征图。</p></li></ul><h4 id="backbone"><a href="#backbone" class="headerlink" title="backbone"></a>backbone</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">backbone:</span><br><span class="line">  <span class="comment"># [from, number, module, args]</span></span><br><span class="line">  [[-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">64</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">2</span>]],  <span class="comment"># 0-P1/2</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 1-P2/4</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">128</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 3-P3/8</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">6</span>, C3, [<span class="number">256</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 5-P4/16</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">9</span>, C3, [<span class="number">512</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 7-P5/32</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">1024</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, SPPF, [<span class="number">1024</span>, <span class="number">5</span>]],  <span class="comment"># 9</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure><ul><li><strong>from</strong>：-n表示从前n层获得的输入，如-1表示从前一层获得输入</li><li><strong>number</strong>：表示网络模块的数目，如[-1, 2, C3, [128] ]表示含有3个C3模块</li><li><strong>model</strong>：表示网络模块的名称，具体细节可以在&#x2F;models&#x2F;common.py中查看，如Conv、C3、SPPF都是已经在common中定义好的模块。</li><li><strong>args</strong>：表示向不同模块内传递的参数，即[ch_out, kernel, stride, padding, groups]，这里连ch_in都省去了，因为输入都是上层的输出（初始ch_in为3）。为了修改过于麻烦，这里输入的获取是从.&#x2F;models&#x2F;yolo.py的<code>def parse_model(md, ch)</code>函数中解析得到的。</li></ul><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">64</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">2</span>]],  <span class="comment"># 0-P1/2</span></span><br></pre></td></tr></table></figure><ul><li><p>input为：3×640×640</p></li><li><p>[ch_out，kernel，stride，padding]&#x3D;[64, 6, 2, 2]</p><blockquote><p>故新的通道数为64×0.5&#x3D;32</p><p>根据特征图计算公式：Feature_new&#x3D;(Feature_old-kernel+2xpadding)&#x2F;stride+1可得：</p><p>新的特征图尺寸为：Feature_new&#x3D;(640-6+2x2)&#x2F;2+1&#x3D;320</p></blockquote></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 1-P2/4</span></span><br></pre></td></tr></table></figure><ul><li><p>input为：32×320×320</p></li><li><p>[ch_out, kernel, stride]&#x3D;[128, 3, 2]</p><blockquote><p>同理可得：新的通道数为64，新的特征图尺寸为160</p></blockquote></li></ul><h2 id="Backbone组成"><a href="#Backbone组成" class="headerlink" title="Backbone组成"></a>Backbone组成</h2><p>v6.0版本的Backbone去除了Focus模块（便于模型导出部署），Backbone主要由CBL、BottleneckCSP&#x2F;C3以及SPP&#x2F;SPPF等组成，具体如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324165913.png"></p><h3 id="CBS模块"><a href="#CBS模块" class="headerlink" title="CBS模块"></a>CBS模块</h3><blockquote><p>CBS模块实际上就是Conv+BatchNorm+SiLU。</p></blockquote><ul><li><p>CBS模块框架图</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324170357.png"></p></li><li><p>CBS源码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Conv</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Standard convolution</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=<span class="number">1</span>, s=<span class="number">1</span>, p=<span class="literal">None</span>, g=<span class="number">1</span>, act=<span class="literal">True</span></span>):  <span class="comment"># ch_in, ch_out, kernel, stride, padding, groups</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn = nn.BatchNorm2d(c2)</span><br><span class="line">        self.act = nn.SiLU() <span class="keyword">if</span> act <span class="keyword">is</span> <span class="literal">True</span> <span class="keyword">else</span> (act <span class="keyword">if</span> <span class="built_in">isinstance</span>(act, nn.Module) <span class="keyword">else</span> nn.Identity())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.act(self.bn(self.conv(x)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_fuse</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.act(self.conv(x))</span><br></pre></td></tr></table></figure></li></ul><p>这里配合CBS模块的源码，分析Conv()函数里的一些参数，作为pytorch中卷积操作的复习。</p><p>从源码可以看出，Conv()包含7个参数，这些参数也是二维卷积Conv2d()中的重要参数。ch_in, ch_out, kernel, stride这4个参数前文已经提到过，是用来计算特征图尺寸的。主要分析后三个参数。</p><h4 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h4><blockquote><p>从目前主流卷积操作来看，大多数的研究者不会通过kernel来改变特征图的尺寸，如googlenet中3x3的kernel设定了padding&#x3D;1，所以当kernel≠1时需要对输入特征图进行填充。当指定p值时按照p值进行填充，当p值为默认时则通过autopad函数进行填充：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">autopad</span>(<span class="params">k, p=<span class="literal">None</span></span>):  <span class="comment"># kernel, padding</span></span><br><span class="line">    <span class="comment"># Pad to &#x27;same&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> p <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        p = k // <span class="number">2</span> <span class="keyword">if</span> <span class="built_in">isinstance</span>(k, <span class="built_in">int</span>) <span class="keyword">else</span> [x // <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> k]  <span class="comment"># auto-pad</span></span><br><span class="line">    <span class="keyword">return</span> p</span><br></pre></td></tr></table></figure><p>这里作者考虑到对不同的卷积操作使用不同大小的卷积核时padding也需要做出改变，所以这里在为p赋值时会首先检查k是否为int，如果k为列表则对列表中的每个元素整除。</p><h4 id="groups"><a href="#groups" class="headerlink" title="groups"></a>groups</h4><p>表示分组卷积，示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324171353.png"></p><blockquote><p>groups – 从输入通道到输出的阻塞连接数</p><ul><li>groups&#x3D;1 时，所有输入都卷积到所有输出。</li><li>groups&#x3D;2 时，该操作等效于并排具有两个凸层，每个凸层看到一半的输入通道，并产生一半的输出通道，随后两者都串联起来。</li><li>groups&#x3D; in_channels 时，每个输入通道都用自己的一组滤波器进行卷积，其大小为：⌊（out_channels）&#x2F;（in_channels）⌋。</li></ul></blockquote><h4 id="act参数"><a href="#act参数" class="headerlink" title="act参数"></a>act参数</h4><p>决定是否对特征图进行激活操作，SILU表示使用Sigmoid进行激活。</p><p><em>关于激活函数的内容在Yolov5学习笔记3中有提及</em></p><h4 id="补充：dilation参数"><a href="#补充：dilation参数" class="headerlink" title="补充：dilation参数"></a>补充：dilation参数</h4><p>在Conv2d()中有一个重要的参数——空洞卷积dilation</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dilation: _size_2_t = <span class="number">1</span>,</span><br></pre></td></tr></table></figure><p>通俗解释就是控制kernel点（卷积核点）间距的参数，通过改变卷积核间距实现特征图及特征信息的保留，在语义分割任务中空洞卷积比较有效。</p><h3 id="CSP-x2F-C3"><a href="#CSP-x2F-C3" class="headerlink" title="CSP&#x2F;C3"></a>CSP&#x2F;C3</h3><p><strong>注</strong>：CSP即backbone中的C3，因为在backbone中C3存在shortcut，而在neck中C3不使用shortcut，所以backbone中的C3层使用CSP1_x表示，neck中的C3使用CSP2_x表示。</p><h4 id="CSP结构"><a href="#CSP结构" class="headerlink" title="CSP结构"></a>CSP结构</h4><ul><li><p>源码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">C3</span>(nn.Module):</span><br><span class="line">    <span class="comment"># CSP Bottleneck with 3 convolutions</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, n=<span class="number">1</span>, shortcut=<span class="literal">True</span>, g=<span class="number">1</span>, e=<span class="number">0.5</span></span>):  <span class="comment"># ch_in, ch_out, number, shortcut, groups, expansion</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        c_ = <span class="built_in">int</span>(c2 * e)  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv3 = Conv(<span class="number">2</span> * c_, c2, <span class="number">1</span>)  <span class="comment"># act=FReLU(c2)</span></span><br><span class="line">        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=<span class="number">1.0</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)))</span><br><span class="line">        <span class="comment"># self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>从源码中可以看出：输入特征图一条分支先经过.cv1，再经过.m，得到子特征图1；另一分支经过.cv2后得到子特征图2。最后将子特征图1和子特征图2拼接后输入.cv3得到C3层的输出，如下图所示。</p><p><strong>这里的CV就是前面的Conv2d+BN+SiLU</strong></p></blockquote><ul><li><p>结构图</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324190458.png"></p></li></ul><blockquote><p>.m操作是用nn.Sequential将多个Bottleneck(也就是上图中的Res_u)串接到网络中，</p></blockquote><h4 id="Bottleneck"><a href="#Bottleneck" class="headerlink" title="Bottleneck"></a>Bottleneck</h4><p>在Resnet出现之前，人们的普遍为网络越深获取信息也越多，模型泛化效果越好。然而随后大量的研究表明，网络深度到达一定的程度后，模型的准确率反而大大降低。这并不是过拟合造成的，而是由于反向传播过程中的梯度爆炸和梯度消失。也就是说，<strong>网络越深，模型越难优化，而不是学习不到更多的特征。</strong></p><p>为了能让深层次的网络模型达到更好的训练效果，残差网络中提出的残差映射替换了以往的基础映射。对于输入x，期望输出H(x)，网络利用恒等映射将x作为初始结果，将原来的映射关系变成F(x)+x。与其让多层卷积去近似估计H(x) ，不如近似估计H(x)-x，即近似估计残差F(x)。因此，ResNet相当于将学习目标改变为目标值H(x)和x的差值，后面的训练目标就是要将残差结果逼近于0。</p><p>残差函数有什么好处呢？</p><blockquote><ul><li><strong>梯度弥散方面。</strong>加入ResNet中的shortcut结构之后，在反传时，每两个block之间不仅传递了梯度，还加上了求导之前的梯度，这相当于把每一个block中向前传递的梯度人为加大了，也就会减小梯度弥散的可能性。</li><li><strong>特征冗余方面。</strong>正向卷积时，对每一层做卷积其实只提取了图像的一部分信息，这样一来，越到深层，原始图像信息的丢失越严重，而仅仅是对原始图像中的一小部分特征做提取。这显然会发生类似欠拟合的现象。加入shortcut结构，相当于在每个block中又加入了上一层图像的全部信息，一定程度上保留了更多的原始信息。</li></ul></blockquote><p><strong>在resnet中，人们可以使用带有shortcut的残差模块搭建几百层甚至上千层的网络，而浅层的残差模块被命名为Basicblock（18、34），深层网络所使用的的残差模块，就被命名为了Bottleneck（50+）。</strong></p><p>Bottleneck与Basicblock最大的区别是卷积核的组成。 Basicblock由两个3x3的卷积层组成，Bottleneck由两个1x1卷积层夹一个3x3卷积层组成：其中1x1卷积层降维后再恢复维数，让3x3卷积在计算过程中的参数量更少、速度更快。<br>第一个1x1的卷积把256维channel降到64维，然后在最后通过1x1卷积恢复，整体上用的参数数目：1x1x256x64 + 3x3x64x64 + 1x1x64x256 &#x3D; 69632，而不使用bottleneck的话就是两个3x3x256的卷积，参数数目: 3x3x256x256x2 &#x3D; 1179648，差了16.94倍。<br><strong>Bottleneck减少了参数量，优化了计算，保持了原有的精度。</strong></p><ul><li>Bottleneck的源码如下：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Standard bottleneck</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, shortcut=<span class="literal">True</span>, g=<span class="number">1</span>, e=<span class="number">0.5</span></span>):  <span class="comment"># ch_in, ch_out, shortcut, groups, expansion</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        c_ = <span class="built_in">int</span>(c2 * e)  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = Conv(c_, c2, <span class="number">3</span>, <span class="number">1</span>, g=g)</span><br><span class="line">        self.add = shortcut <span class="keyword">and</span> c1 == c2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x + self.cv2(self.cv1(x)) <span class="keyword">if</span> self.add <span class="keyword">else</span> self.cv2(self.cv1(x))</span><br></pre></td></tr></table></figure><ul><li><p>结构图如下:</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324191951.png"></p></li></ul><p>可以看到，CSP中的Bottleneck同resnet模块中的类似，先是1x1的卷积层（CBS)，然后再是3x3的卷积层，最后通过shortcut与初始输入相加。但是这里与resnet的不通点在于：CSP将输入维度减半运算后并未再使用1x1卷积核进行升维，而是将原始输入x也降了维，采取concat的方法进行张量的拼接，得到与原始输入相同维度的输出。其实这里能区分一点就够了：<strong>resnet中的shortcut通过add实现，是特征图对应位置相加而通道数不变；而CSP中的shortcut通过concat实现，是通道数的增加。二者虽然都是信息融合的主要方式，但是对张量的具体操作又不相同.</strong></p><h3 id="SSPF模块"><a href="#SSPF模块" class="headerlink" title="SSPF模块"></a>SSPF模块</h3><ul><li>源码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SPPF</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=<span class="number">5</span></span>):  <span class="comment"># equivalent to SPP(k=(5, 9, 13))</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        c_ = c1 // <span class="number">2</span>  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = Conv(c_ * <span class="number">4</span>, c2, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.m = nn.MaxPool2d(kernel_size=k, stride=<span class="number">1</span>, padding=k // <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.cv1(x)</span><br><span class="line">        <span class="keyword">with</span> warnings.catch_warnings():</span><br><span class="line">            warnings.simplefilter(<span class="string">&#x27;ignore&#x27;</span>)  <span class="comment"># suppress torch 1.9.0 max_pool2d() warning</span></span><br><span class="line">            y1 = self.m(x)</span><br><span class="line">            y2 = self.m(y1)</span><br><span class="line">            <span class="keyword">return</span> self.cv2(torch.cat([x, y1, y2, self.m(y2)], <span class="number">1</span>))</span><br></pre></td></tr></table></figure><ul><li>结构图</li></ul><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324194944.png"></p><p>SSPF模块将经过<u>CBS的x</u>、<u>一次池化后的y1</u>、<u>两次池化后的y2和3次池化后的self.m(y2)</u>先进行拼接，然后再<u>CBS提取特征</u>。 仔细观察不难发现，虽然SSPF对特征图进行了多次池化，但是<strong>特征图尺寸并未发生变化</strong>，通道数更不会变化，所以后续的4个输出能够在channel维度进行融合。这一模块的主要作用是<strong>对高层特征进行提取并融合，在融合的过程中作者多次运用最大池化，尽可能多的去提取高层次的语义特征。</strong></p><h2 id="Yolov5s的Backbone总览"><a href="#Yolov5s的Backbone总览" class="headerlink" title="Yolov5s的Backbone总览"></a>Yolov5s的Backbone总览</h2><p>运行yolo.py，结合上述的分析，对输出的结果应该很容易理解了。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324195512.png"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> yolov5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于DNN神经网络的手写数字识别</title>
      <link href="/2022/03/21/Depp_Learning%E5%AE%9E%E6%88%98%E8%AE%AD%E7%BB%831/"/>
      <url>/2022/03/21/Depp_Learning%E5%AE%9E%E6%88%98%E8%AE%AD%E7%BB%831/</url>
      
        <content type="html"><![CDATA[<h1 id="基于DNN神经网络的手写数字识别"><a href="#基于DNN神经网络的手写数字识别" class="headerlink" title="基于DNN神经网络的手写数字识别"></a>基于DNN神经网络的手写数字识别</h1><p><strong>导入相关的库</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle <span class="keyword">as</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddle.fluid <span class="keyword">as</span> fluid</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">paddle.enable_static()</span><br></pre></td></tr></table></figure><p><strong>读取数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用多层感知器训练（DNN）模型，用于预测手写数字图片。</span></span><br><span class="line"></span><br><span class="line">BUF_SIZE=<span class="number">512</span></span><br><span class="line">BATCH_SIZE=<span class="number">128</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#用于训练的数据提供器，每次从缓存中随机读取批次大小的数据</span></span><br><span class="line">train_reader = paddle.batch(</span><br><span class="line">    paddle.reader.shuffle(paddle.dataset.mnist.train(),</span><br><span class="line">                          buf_size=BUF_SIZE),</span><br><span class="line">    batch_size=BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">#用于训练的数据提供器，每次从缓存中随机读取批次大小的数据</span></span><br><span class="line">test_reader = paddle.batch(</span><br><span class="line">    paddle.reader.shuffle(paddle.dataset.mnist.test(),</span><br><span class="line">                          buf_size=BUF_SIZE),</span><br><span class="line">    batch_size=BATCH_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="comment">#用于打印，查看mnist数据</span></span><br><span class="line">train_data=paddle.dataset.mnist.train();</span><br><span class="line">sampledata=<span class="built_in">next</span>(train_data())</span><br><span class="line"><span class="comment"># print(sampledata)</span></span><br></pre></td></tr></table></figure><p>定义一个多层感知器**</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">multilayer_perceptron</span>(<span class="params"><span class="built_in">input</span></span>):</span><br><span class="line">    <span class="comment"># 第一个全连接层，激活函数为ReLU</span></span><br><span class="line">    hidden1 = fluid.layers.fc(<span class="built_in">input</span>=<span class="built_in">input</span>, size=<span class="number">100</span>, act=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">    <span class="comment"># 第二个全连接层，激活函数为ReLU</span></span><br><span class="line">    hidden2 = fluid.layers.fc(<span class="built_in">input</span>=hidden1, size=<span class="number">100</span>, act=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">    <span class="comment"># 以softmax为激活函数的全连接输出层，输出层的大小必须为数字的个数10</span></span><br><span class="line">    prediction = fluid.layers.fc(<span class="built_in">input</span>=hidden2, size=<span class="number">10</span>, act=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> prediction</span><br></pre></td></tr></table></figure><p><strong>定义图像和标签数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入的原始图像数据，大小为1*28*28</span></span><br><span class="line">image = fluid.layers.data(name=<span class="string">&#x27;image&#x27;</span>, shape=[<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>], dtype=<span class="string">&#x27;float32&#x27;</span>)<span class="comment">#单通道，28*28像素值</span></span><br><span class="line"><span class="comment"># 标签，名称为label,对应输入图片的类别标签</span></span><br><span class="line">label = fluid.layers.data(name=<span class="string">&#x27;label&#x27;</span>, shape=[<span class="number">1</span>], dtype=<span class="string">&#x27;int64&#x27;</span>)          <span class="comment">#图片标签</span></span><br></pre></td></tr></table></figure><p><strong>获取分类器</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict = multilayer_perceptron(image)</span><br></pre></td></tr></table></figure><p><strong>损失函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用交叉熵损失函数,描述真实样本标签和预测概率之间的差值</span></span><br><span class="line">cost = fluid.layers.cross_entropy(<span class="built_in">input</span>=predict, label=label)</span><br><span class="line"><span class="comment"># 使用类交叉熵函数计算predict和label之间的损失函数</span></span><br><span class="line">avg_cost = fluid.layers.mean(cost)</span><br><span class="line"><span class="comment"># 计算分类准确率</span></span><br><span class="line">acc = fluid.layers.accuracy(<span class="built_in">input</span>=predict, label=label)</span><br></pre></td></tr></table></figure><p><strong>测试</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取测试程序</span></span><br><span class="line">test_program = fluid.default_main_program().clone(for_test=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#使用Adam算法进行优化, learning_rate 是学习率(它的大小与网络的训练收敛速度有关系)</span></span><br><span class="line">optimizer = fluid.optimizer.AdamOptimizer(learning_rate=<span class="number">0.001</span>)</span><br><span class="line">opts = optimizer.minimize(avg_cost)</span><br><span class="line"><span class="comment"># （1）创建训练的Executor</span></span><br><span class="line"><span class="comment"># 首先定义运算场所 fluid.CPUPlace()和 fluid.CUDAPlace(0)分别表示运算场所为CPU和GPU</span></span><br><span class="line"><span class="comment"># Executor:接收传入的program，通过run()方法运行program。</span></span><br><span class="line"><span class="comment"># 定义使用CPU还是GPU，使用CPU时use_cuda = False,使用GPU时use_cuda = True</span></span><br><span class="line">use_cuda = <span class="literal">False</span></span><br><span class="line">place = fluid.CUDAPlace(<span class="number">0</span>) <span class="keyword">if</span> use_cuda <span class="keyword">else</span> fluid.CPUPlace()</span><br><span class="line">exe = fluid.Executor(place)</span><br><span class="line">exe.run(fluid.default_startup_program())</span><br><span class="line"><span class="comment">#（2）告知网络传入的数据分为两部分，第一部分是image值，第二部分是label值</span></span><br><span class="line"><span class="comment"># DataFeeder负责将数据提供器（train_reader,test_reader）返回的数据转成一种特殊的数据结构，使其可以输入到Executor中。</span></span><br><span class="line">feeder = fluid.DataFeeder(place=place, feed_list=[image, label])</span><br><span class="line"></span><br><span class="line">all_train_iter=<span class="number">0</span></span><br><span class="line">all_train_iters=[]</span><br><span class="line">all_train_costs=[]</span><br><span class="line">all_train_accs=[]</span><br></pre></td></tr></table></figure><p>可视化与模型训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">draw_train_process</span>(<span class="params">title,iters,costs,accs,label_cost,lable_acc</span>):</span><br><span class="line">    plt.title(title, fontsize=<span class="number">24</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;iter&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;cost/acc&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">    plt.plot(iters, costs,color=<span class="string">&#x27;red&#x27;</span>,label=label_cost)</span><br><span class="line">    plt.plot(iters, accs,color=<span class="string">&#x27;green&#x27;</span>,label=lable_acc)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">EPOCH_NUM = <span class="number">2</span></span><br><span class="line">model_save_dir = <span class="string">&quot;CH4_File/model&quot;</span></span><br><span class="line"><span class="keyword">for</span> pass_id <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH_NUM):</span><br><span class="line">    <span class="comment"># 进行训练</span></span><br><span class="line">    <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_reader()):  <span class="comment"># 遍历train_reader</span></span><br><span class="line">        train_cost, train_acc = exe.run(program=fluid.default_main_program(),  <span class="comment"># 运行主程序</span></span><br><span class="line">                                        feed=feeder.feed(data),  <span class="comment"># 给模型喂入数据</span></span><br><span class="line">                                        fetch_list=[avg_cost, acc])  <span class="comment"># fetch 误差、准确率</span></span><br><span class="line"></span><br><span class="line">        all_train_iter = all_train_iter + BATCH_SIZE</span><br><span class="line">        all_train_iters.append(all_train_iter)</span><br><span class="line"></span><br><span class="line">        all_train_costs.append(train_cost[<span class="number">0</span>])</span><br><span class="line">        all_train_accs.append(train_acc[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每200个batch打印一次信息  误差、准确率</span></span><br><span class="line">        <span class="keyword">if</span> batch_id % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f&#x27;</span> %</span><br><span class="line">                  (pass_id, batch_id, train_cost[<span class="number">0</span>], train_acc[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进行测试</span></span><br><span class="line">    test_accs = []</span><br><span class="line">    test_costs = []</span><br><span class="line">    <span class="comment"># 每训练一轮 进行一次测试</span></span><br><span class="line">    <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_reader()):  <span class="comment"># 遍历test_reader</span></span><br><span class="line">        test_cost, test_acc = exe.run(program=test_program,  <span class="comment"># 执行训练程序</span></span><br><span class="line">                                      feed=feeder.feed(data),  <span class="comment"># 喂入数据</span></span><br><span class="line">                                      fetch_list=[avg_cost, acc])  <span class="comment"># fetch 误差、准确率</span></span><br><span class="line">        test_accs.append(test_acc[<span class="number">0</span>])  <span class="comment"># 每个batch的准确率</span></span><br><span class="line">        test_costs.append(test_cost[<span class="number">0</span>])  <span class="comment"># 每个batch的误差</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 求测试结果的平均值</span></span><br><span class="line">    test_cost = (<span class="built_in">sum</span>(test_costs) / <span class="built_in">len</span>(test_costs))  <span class="comment"># 每轮的平均误差</span></span><br><span class="line">    test_acc = (<span class="built_in">sum</span>(test_accs) / <span class="built_in">len</span>(test_accs))  <span class="comment"># 每轮的平均准确率</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test:%d, Cost:%0.5f, Accuracy:%0.5f&#x27;</span> % (pass_id, test_cost, test_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存模型</span></span><br><span class="line">    <span class="comment"># 如果保存路径不存在就创建</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(model_save_dir):</span><br><span class="line">    os.makedirs(model_save_dir)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;save models to %s&#x27;</span> % (model_save_dir))</span><br><span class="line">fluid.io.save_inference_model(model_save_dir,   <span class="comment"># 保存推理model的路径</span></span><br><span class="line">                              [<span class="string">&#x27;image&#x27;</span>],        <span class="comment"># 推理（inference）需要 feed 的数据</span></span><br><span class="line">                              [predict],        <span class="comment"># 保存推理（inference）结果的 Variables</span></span><br><span class="line">                              exe)              <span class="comment"># executor 保存 inference model</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练模型保存完成！&#x27;</span>)</span><br><span class="line">draw_train_process(<span class="string">&quot;training&quot;</span>, all_train_iters, all_train_costs, all_train_accs, <span class="string">&quot;trainning cost&quot;</span>, <span class="string">&quot;trainning acc&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">file</span>):</span><br><span class="line">    im = Image.<span class="built_in">open</span>(file).convert(<span class="string">&#x27;L&#x27;</span>)                          <span class="comment"># 将RGB转化为灰度图像，L代表灰度图像，像素值在0~255之间</span></span><br><span class="line">    im = im.resize((<span class="number">28</span>, <span class="number">28</span>), Image.ANTIALIAS)                   <span class="comment"># resize image with high-quality 图像大小为28*28</span></span><br><span class="line">    im = np.array(im).reshape(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).astype(np.float32)  <span class="comment"># 返回新形状的数组,把它变成一个 numpy 数组以匹配数据馈送格式。</span></span><br><span class="line">    <span class="comment"># print(im)</span></span><br><span class="line">    im = im / <span class="number">255.0</span> * <span class="number">2.0</span> - <span class="number">1.0</span>                                 <span class="comment"># 归一化到【-1~1】之间</span></span><br><span class="line">    <span class="keyword">return</span> im</span><br><span class="line"></span><br><span class="line">infer_path=<span class="string">&#x27;CH4_File/data/infer_3.png&#x27;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(infer_path)</span><br><span class="line">plt.imshow(img)   <span class="comment">#根据数组绘制图像</span></span><br><span class="line">plt.show()        <span class="comment">#显示图像</span></span><br></pre></td></tr></table></figure><p><strong>预测</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载数据并开始预测</span></span><br><span class="line"><span class="keyword">with</span> fluid.scope_guard(inference_scope):</span><br><span class="line">    <span class="comment">#获取训练好的模型</span></span><br><span class="line">    <span class="comment">#从指定目录中加载 推理model(inference model)</span></span><br><span class="line">    [inference_program,                                             <span class="comment"># 推理Program</span></span><br><span class="line">     feed_target_names,                                             <span class="comment"># 是一个str列表，它包含需要在推理 Program 中提供数据的变量的名称。</span></span><br><span class="line">     fetch_targets] = fluid.io.load_inference_model(model_save_dir, <span class="comment"># fetch_targets：是一个 Variable 列表，从中我们可以得到推断结果。model_save_dir：模型保存的路径</span></span><br><span class="line">                                                    infer_exe)      <span class="comment"># infer_exe: 运行 inference model的 executor</span></span><br><span class="line">    img = load_image(infer_path)</span><br><span class="line"></span><br><span class="line">    results = infer_exe.run(program=inference_program,              <span class="comment"># 运行推测程序</span></span><br><span class="line">                   feed=&#123;feed_target_names[<span class="number">0</span>]: img&#125;,                <span class="comment"># 喂入要预测的img</span></span><br><span class="line">                   fetch_list=fetch_targets)                        <span class="comment"># 得到推测结果,</span></span><br><span class="line">    <span class="comment"># 获取概率最大的label</span></span><br><span class="line">    lab = np.argsort(results)                                       <span class="comment"># argsort函数返回的是result数组值从小到大的索引值</span></span><br><span class="line">    <span class="comment">#print(lab)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;该图片的预测结果的label为: %d&quot;</span> % lab[<span class="number">0</span>][<span class="number">0</span>][-<span class="number">1</span>])             <span class="comment"># -1代表读取数组中倒数第一列</span></span><br></pre></td></tr></table></figure><p><strong>结果</strong></p><p>训练过程可视化：<br><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/%E8%AE%AD%E7%BB%83%E6%9B%B2%E7%BA%BF.png"></p><p>识别如下图片：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/%E8%AF%86%E5%88%AB%E7%9A%84%E5%9B%BE%E7%89%87.png"></p><p>预测的结果为：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220319162335.png"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deeplearning </tag>
            
            <tag> DNN </tag>
            
            <tag> 手写数字识别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yolov5学习笔记5——v5.0源码剖析——Backbone部分2</title>
      <link href="/2022/03/20/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05/"/>
      <url>/2022/03/20/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05/</url>
      
        <content type="html"><![CDATA[<h1 id="Yolov5学习笔记5——v5-0源码剖析——Backbone部分2"><a href="#Yolov5学习笔记5——v5-0源码剖析——Backbone部分2" class="headerlink" title="Yolov5学习笔记5——v5.0源码剖析——Backbone部分2"></a>Yolov5学习笔记5——v5.0源码剖析——Backbone部分2</h1><p>用<strong>netron</strong>得到yolov5s的框架结构图如下，可以非常直观的得到关于backbone部分的网络结构图。</p><p><strong>注</strong>：所使用的代码版本为 2020年11月24日发布的Yolov5-master。</p><h2 id="YOLOv5s结构图如下所示："><a href="#YOLOv5s结构图如下所示：" class="headerlink" title="YOLOv5s结构图如下所示："></a>YOLOv5s结构图如下所示：</h2><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/yolov5s_2.png"></p><h2 id="Backbone结构图"><a href="#Backbone结构图" class="headerlink" title="Backbone结构图"></a>Backbone结构图</h2><ul><li><p>backbone的意义是：在不同图像细粒度上聚合并形成图像特征的卷积神经网络；</p></li><li><p>backbone所需的主要模块在common.py里面可以找到。</p></li></ul><p>从整体结构中我们抽出backbone部分学习：</p><p>backbone的结构图如下：<br><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220323212340.png"></p><p>Netron打开yolov5s.pt导出的BackBone部分的框架图如下：<br><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220323212829.png"></p><p>backbone对应的代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># YOLOv5 backbone</span></span><br><span class="line">backbone:</span><br><span class="line">  <span class="comment"># [from, number, module, args]</span></span><br><span class="line">  [[-<span class="number">1</span>, <span class="number">1</span>, Focus, [<span class="number">64</span>, <span class="number">3</span>]],  <span class="comment"># 0-P1/2</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 1-P2/4</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, BottleneckCSP, [<span class="number">128</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 3-P3/8</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">9</span>, BottleneckCSP, [<span class="number">256</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 5-P4/16</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">9</span>, BottleneckCSP, [<span class="number">512</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 7-P5/32</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, SPP, [<span class="number">1024</span>, [<span class="number">5</span>, <span class="number">9</span>, <span class="number">13</span>]]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, BottleneckCSP, [<span class="number">1024</span>, <span class="literal">False</span>]],  <span class="comment"># 9</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure><p>从上述代码中我们可以看到backbone由如下组成：</p><p>BACKBONE &#x3D;FOCUS(1个)+CONV (1个)+BCSP(3个)+CONV (1个)+BCSP(9个)+CONV (1个)+SPP(1个)+BCSP(1个)</p><ul><li>注：这里的BCSP相当于CSP</li></ul><h2 id="Backbone源码解析"><a href="#Backbone源码解析" class="headerlink" title="Backbone源码解析"></a>Backbone源码解析</h2><h3 id="Focus模块"><a href="#Focus模块" class="headerlink" title="Focus模块"></a>Focus模块</h3><p>Focus()函数在common.py中，对应的源码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Focus</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Focus wh information into c-space</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=<span class="number">1</span>, s=<span class="number">1</span>, p=<span class="literal">None</span>, g=<span class="number">1</span>, act=<span class="literal">True</span></span>):  <span class="comment"># ch_in, ch_out, kernel, stride, padding, groups</span></span><br><span class="line">        <span class="built_in">super</span>(Focus, self).__init__()</span><br><span class="line">        self.conv = Conv(c1 * <span class="number">4</span>, c2, k, s, p, g, act)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)</span></span><br><span class="line">        <span class="keyword">return</span> self.conv(torch.cat([x[..., ::<span class="number">2</span>, ::<span class="number">2</span>], x[..., <span class="number">1</span>::<span class="number">2</span>, ::<span class="number">2</span>], x[..., ::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>], x[..., <span class="number">1</span>::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>]], <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>根据前述代码我们知道，输入的图片尺寸为640×640×3，而Focus()函数的功能为：<em>将640 × 640 × 3的图像输入Focus结构，采用切片操作，先变成320 × 320 × 12的特征图，再经过3 × 3的卷积操作，输出通道32，最终变成320 × 320 × 32的特征图</em></p><p>Focus模块的结构图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324110433.png"></p><h3 id="CBL模块-CBH"><a href="#CBL模块-CBH" class="headerlink" title="CBL模块(CBH)"></a>CBL模块(CBH)</h3><p>该部分对应的源码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Conv</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Standard convolution</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=<span class="number">1</span>, s=<span class="number">1</span>, p=<span class="literal">None</span>, g=<span class="number">1</span>, act=<span class="literal">True</span></span>):  <span class="comment"># ch_in, ch_out, kernel, stride, padding, groups</span></span><br><span class="line">        <span class="built_in">super</span>(Conv, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn = nn.BatchNorm2d(c2)</span><br><span class="line">        self.act = nn.Hardswish() <span class="keyword">if</span> act <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.act(self.bn(self.conv(x)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fuseforward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.act(self.conv(x))</span><br></pre></td></tr></table></figure><p>CONV是一个标准的卷积模块。</p><p>从源码第5 6 7行可以看出，激活函数变成了Hardwish()，实际上这里不应该叫CBL模块了，应该是CBH模块。</p><ul><li>conv：来自于代码的torch.nn.Conv2d,是一个卷积操作</li><li>bn：来自于代码的torch.nn.BatchNorm2d：归一化处理，使batch里面的feature map 满足均值为1，方差为0 的正太分布</li><li>Hardswish：激活函数<br>故：CBL&#x3D;CONV+BN+Hardswish</li></ul><h3 id="BottleneckCSP模块"><a href="#BottleneckCSP模块" class="headerlink" title="BottleneckCSP模块"></a>BottleneckCSP模块</h3><p>3个BCSP相当于是几个标准的Bottleneck的堆叠+几个标准卷积层。</p><ul><li><p>BottleneckCSP的网络结构如下：<br><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324115258.png"></p></li><li><p>残差组件Resunit的网络结构如下：<br><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324143720.png"></p></li><li><p>BottleneckCSP的源码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BottleneckCSP</span>(nn.Module):</span><br><span class="line">    <span class="comment"># CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, n=<span class="number">1</span>, shortcut=<span class="literal">True</span>, g=<span class="number">1</span>, e=<span class="number">0.5</span></span>):  <span class="comment"># ch_in, ch_out, number, shortcut, groups, expansion</span></span><br><span class="line">        <span class="built_in">super</span>(BottleneckCSP, self).__init__()</span><br><span class="line">        c_ = <span class="built_in">int</span>(c2 * e)  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = nn.Conv2d(c1, c_, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.cv3 = nn.Conv2d(c_, c_, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.cv4 = Conv(<span class="number">2</span> * c_, c2, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.bn = nn.BatchNorm2d(<span class="number">2</span> * c_)  <span class="comment"># applied to cat(cv2, cv3)</span></span><br><span class="line">        self.act = nn.LeakyReLU(<span class="number">0.1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=<span class="number">1.0</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y1 = self.cv3(self.m(self.cv1(x)))</span><br><span class="line">        y2 = self.cv2(x)</span><br><span class="line">        <span class="keyword">return</span> self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=<span class="number">1</span>))))</span><br></pre></td></tr></table></figure></li></ul><p><strong>注</strong>：nn.sequential将所有的块链接在一起。self.bn &#x3D; nn.BatchNorm2d(2 * c_)就是concat 块，cv2,cv3对应于图中的concat;</p><ul><li><p>Resunit的源码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Standard bottleneck</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, shortcut=<span class="literal">True</span>, g=<span class="number">1</span>, e=<span class="number">0.5</span></span>):  <span class="comment"># ch_in, ch_out, shortcut, groups, expansion</span></span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line">        c_ = <span class="built_in">int</span>(c2 * e)  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = Conv(c_, c2, <span class="number">3</span>, <span class="number">1</span>, g=g)</span><br><span class="line">        self.add = shortcut <span class="keyword">and</span> c1 == c2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x + self.cv2(self.cv1(x)) <span class="keyword">if</span> self.add <span class="keyword">else</span> self.cv2(self.cv1(x))</span><br></pre></td></tr></table></figure></li></ul><p><strong>注</strong>：cv1、cv2对应于图中的CBL模块，add不变。</p><h3 id="SPP某块"><a href="#SPP某块" class="headerlink" title="SPP某块"></a>SPP某块</h3><blockquote><ul><li><p>SPP模块，就是常说的<em>空间金字塔池化模块</em>，分别采用5&#x2F;9&#x2F;13的最大池化，在进行concat融合，提高感受野。</p></li><li><p>SPP的输入时512×512×20，经过1×1的卷积层后输出256×20×20，然后经过并列的三个Maxpool进行下采样，将结果与其初始特征相加，输出1024×20×20，最后用512的卷积核将其恢复到512×20×20.</p></li></ul></blockquote><ul><li><p>SPP模块的结构图如下：<br><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220324143720.png"></p></li><li><p>SPP模块对应的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SPP</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Spatial pyramid pooling layer used in YOLOv3-SPP</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=(<span class="params"><span class="number">5</span>, <span class="number">9</span>, <span class="number">13</span></span>)</span>):</span><br><span class="line">        <span class="built_in">super</span>(SPP, self).__init__()</span><br><span class="line">        c_ = c1 // <span class="number">2</span>  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = Conv(c_ * (<span class="built_in">len</span>(k) + <span class="number">1</span>), c2, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=<span class="number">1</span>, padding=x // <span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> k])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.cv1(x)</span><br><span class="line">        <span class="keyword">return</span> self.cv2(torch.cat([x] + [m(x) <span class="keyword">for</span> m <span class="keyword">in</span> self.m], <span class="number">1</span>))</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> yolov5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文献阅读1-YOLO-Z</title>
      <link href="/2022/03/20/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB1/"/>
      <url>/2022/03/20/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB1/</url>
      
        <content type="html"><![CDATA[<h1 id="文献阅读1-YOLO-Z-Improving-small-object-detection-in-YOLOv5-for-autonomous-vehicles"><a href="#文献阅读1-YOLO-Z-Improving-small-object-detection-in-YOLOv5-for-autonomous-vehicles" class="headerlink" title="文献阅读1-YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles"></a>文献阅读1-YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles</h1><p>本文的中文题目为：YOLO-Z:基于改进YOLOv5的自动驾驶车辆小目标检测算法。</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>本研究探索了如何对YOLOv5进行修改，以提高其在检测较小目标时的性能，并在自动赛车中进行了特殊应用。为了实现这一点，作者研究了替换模型的某些结构会如何影响性能和推理时间。在这一过程中在不同的尺度上提出一系列的模型YOLO-Z，并得到高达6.9%的改善，相比原YOLOv5推理时间检测更小的目标时的成本就增加3ms。</p><h2 id="数据集-Dataset"><a href="#数据集-Dataset" class="headerlink" title="数据集(Dataset)"></a>数据集(Dataset)</h2><p>本文所采用的数据集为基于自动驾驶赛车视角的带注释的锥体数据集。该数据集包括数字增强图像和具有挑战性天气条件的情况。数据集共有4类圆锥体(黄色、蓝色、橙色和大橙色)，接近4000张图像。</p><p>数据集以65:15:20的比例分为训练、验证和测试。</p><h2 id="架构改进"><a href="#架构改进" class="headerlink" title="架构改进"></a>架构改进</h2><p>YOLOv5使用yaml文件来指导解析器如何构建模型。为了实现新的YOLOv5模型结构，作者为原有的YOLOv5的每个构建模块或层提供参数，并在必要时指导解析器如何构建它。换句话说，作者利用YOLOv5提供的基础和实验网络块，同时在需要模拟所需结构的地方实现额外的块。</p><h3 id="Backbone部分"><a href="#Backbone部分" class="headerlink" title="Backbone部分"></a>Backbone部分</h3><p>模型的Backbone是用于获取输入图像并从中提取特征映射的组件。这是任何目标检测器的关键步骤，因为它是负责从输入图像提取上下文信息以及将该信息提取为模式的主要结构。</p><p>作者尝试用2个Backbone替换YOLOv5中现有的Backbone。</p><ul><li>ResNet是一种流行的结构，它引入残差连接来减少在深层神经网络中收益递减的影响。</li><li>DenseNet使用类似的连接，在网络中尽可能多地保存信息。实现这些结构需要将它们分解为基本块，并确保各层适当的通信。这包括确保正确的特征图尺寸，这有时需要为模型的宽度和深度略微修改缩放因子。</li></ul><p><strong>改进部分如下</strong></p><ul><li>使用ResNet50</li><li>按比例缩小DenseNet</li><li>YOLOv5利用了Backbone和Neck之间的空间金字塔池化(SPP)层，改进的代码中没有用到。</li></ul><p><strong>实验结果</strong>：对于小目标 DenseNet性能更好，增加的推理时间也相对较少，ResNet性能较差。</p><h3 id="Neck部分"><a href="#Neck部分" class="headerlink" title="Neck部分"></a>Neck部分</h3><p>Neck部分的作用是将Backbone提取的信息反馈到Head之前尽可能多地聚合这些信息。该结构通过防止小目标信息丢失，在传递小目标信息方面发挥了重要作用。它通过再次提高特征图的分辨率来做到这一点，这样来自Backbone的不同层的特征就可以被聚合，以提升整体的检测性能。</p><p><strong>改进部分</strong>：</p><p>当前的PAN-Net替换为bi-FPN。</p><p>虽然都保留了类似的特征，但复杂性不同，因此实现所需的层数和连接数也不同。</p><h3 id="其他修改"><a href="#其他修改" class="headerlink" title="其他修改"></a>其他修改</h3><p>作者提到为了提高小目标检测性能，YOLOv5的改进除了输入图像的大小之外，还可以<strong>修改模型的深度和宽度</strong>(废话)，以改变处理的主要方向；<strong>Neck和Head的层连接方式</strong>也可以手动改变，以便专注于检测特定的特征图。</p><p>作者探索了涉及高分辨率特征映射的重定向连接的效果，以便将它们直接反馈到Neck和Head，做了如下修改：</p><ul><li><strong>扩大Neck以适应额外的特征图</strong>来实现</li><li>通过<strong>替换最低分辨率的特征图以适应新的特征图</strong>来实现</li></ul><p>用这两种方式在Neck中整合。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220321112728.png"></p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220321113416.png"></p><h3 id="Backbone改进的影响"><a href="#Backbone改进的影响" class="headerlink" title="Backbone改进的影响"></a>Backbone改进的影响</h3><p>DenseNet在推理时间(约3ms)相对较低的固定增加时，始终显示出显著的改进。作者的结论是：一般来说，DenseNet是一个更适合于小尺度目标检测。在较小比例的模型中，这可能是因为没有足够深的网络来获得ResNet骨干网的好处，而DenseNet在保存特征地图的细节方面做得很好。</p><h3 id="Neck结构改进的影响"><a href="#Neck结构改进的影响" class="headerlink" title="Neck结构改进的影响"></a>Neck结构改进的影响</h3><p>使用FPN只在S尺度上优于双FPN。</p><h3 id="Feature-maps"><a href="#Feature-maps" class="headerlink" title="Feature maps"></a>Feature maps</h3><p>作者的实验表明重定向向颈部和头部提供的特征映射具有最显著的影响。在头部包含了更高分辨率的地图后，小对象最终占据了更多的像素，因此具有更大的影响力，而不是在脊柱的卷积阶段“丢失”。</p><p>但对于超大规模的(即yolov5x)，在这种情况下，改进并不显著，保持较低分辨率的特征图实际上似乎对性能有害。</p><h3 id="Influence-of-the-number-of-anchors-锚点数"><a href="#Influence-of-the-number-of-anchors-锚点数" class="headerlink" title="Influence of the number of anchors(锚点数)"></a>Influence of the number of anchors(锚点数)</h3><p>作者的实验表明：让YOLO根据所提供的数据集生成锚被证明在性能上是有效的，而且不会影响推理时间。在S模型下，3个锚点的表现优于5个锚点的表现，而在M模型下，差距减小。另一方面，L模型和X模型在5个锚点显示出更好的性能。</p><p><strong>结论</strong>：更复杂或更深入的模型可能确实受益于额外的锚点，或者换句话说，可能更有能力利用额外锚点提供的细节。</p><h3 id="其他因素"><a href="#其他因素" class="headerlink" title="其他因素"></a>其他因素</h3><ul><li>更大的学习率被证明可以更好地利用模型</li><li>较宽的模型(较高的宽度乘法器)对较小的尺度显示出积极的影响，而对较深的尺度(图6中既深又宽)则相反。</li><li>类型的改变对推理速度有明显的负面影响，阻碍了它们的使用。</li></ul><h3 id="改进模型"><a href="#改进模型" class="headerlink" title="改进模型"></a>改进模型</h3><p>作者通过使用上述修改方法的各种组合进行了其他测试，以寻找进一步偏离原始但同时又能进一步提高性能的模型——即YOLO-z，结论如下：</p><ul><li>Neck的<strong>FPN</strong>结构往往优于双<strong>FPN</strong></li><li>X量表，它似乎从这些变化中获益较少，即使使用不同的颈部结构，也不会像其他量表那样带来显著的改善。</li><li>对于所有对象，在50% IoU的绝对mAP上，YOLO-Z模型的性能平均提高了2.7，而对于所有尺度上相同IoU的小对象，性能的绝对提高了5.9。这是以平均增加2.6ms的推理时间为代价的。</li></ul><h2 id="讨论与结论"><a href="#讨论与结论" class="headerlink" title="讨论与结论"></a>讨论与结论</h2><p>在对YOLOv5进行调整以更好地检测更小的目标的方法的实验中，本文能够识别体系结构修改，这种修改在性能上比原始的检测器有明显改善，而且成本相对较低，因为新的模型保持了实时推理速度。</p><p>所应用的技术，即自动赛车技术，可以从这样的改进中获益良多。在这项工作中，不仅显著提高了Baseline模型的性能，而且还确定了一些特定的技术，这些技术可以应用于任何其他应用程序，包括检测小或远的物体。</p><p>最终结果是YOLO-Z系列的模型优于的YOLOv5类，同时保留一个推理时间等实时应用程序兼容的自动化赛车(见表2和图7)。特别是较小的目标是本研究的重点(图7中，中间)，而对于中等大小的目标(下图)，性能是稳定的。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://arxiv.org/pdf/2112.11798.pdf">YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles</a></li><li><a href="https://blog.csdn.net/shanglianlm/article/details/122301921">深度学习论文及PyTorch实现</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 文献阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> yolov5 </tag>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yolov5学习笔记4——源码剖析——Head部分</title>
      <link href="/2022/03/19/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04/"/>
      <url>/2022/03/19/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04/</url>
      
        <content type="html"><![CDATA[<h1 id="Yolov5学习笔记4——源码剖析——Head部分"><a href="#Yolov5学习笔记4——源码剖析——Head部分" class="headerlink" title="Yolov5学习笔记4——源码剖析——Head部分"></a>Yolov5学习笔记4——源码剖析——Head部分</h1><p>Detect类对应yolov5的检查头(head)部分</p><p>Detect类在yolo.py程序中的33行。</p><h2 id="class-Detect-代码分析"><a href="#class-Detect-代码分析" class="headerlink" title="class Detect()代码分析"></a>class Detect()代码分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Detect</span>(nn.Module):</span><br><span class="line">    stride = <span class="literal">None</span>  <span class="comment"># strides computed during build</span></span><br><span class="line">    onnx_dynamic = <span class="literal">False</span>  <span class="comment"># ONNX export parameter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nc=<span class="number">80</span>, anchors=(<span class="params"></span>), ch=(<span class="params"></span>), inplace=<span class="literal">True</span></span>):  <span class="comment"># detection layer</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.nc = nc  <span class="comment"># number of classes</span></span><br><span class="line">        self.no = nc + <span class="number">5</span>  <span class="comment"># number of outputs per anchor</span></span><br><span class="line">        self.nl = <span class="built_in">len</span>(anchors)  <span class="comment"># number of detection layers</span></span><br><span class="line">        self.na = <span class="built_in">len</span>(anchors[<span class="number">0</span>]) // <span class="number">2</span>  <span class="comment"># number of anchors</span></span><br><span class="line">        self.grid = [torch.zeros(<span class="number">1</span>)] * self.nl  <span class="comment"># init grid</span></span><br><span class="line">        self.anchor_grid = [torch.zeros(<span class="number">1</span>)] * self.nl  <span class="comment"># init anchor grid</span></span><br><span class="line">        self.register_buffer(<span class="string">&#x27;anchors&#x27;</span>, torch.tensor(anchors).<span class="built_in">float</span>().view(self.nl, -<span class="number">1</span>, <span class="number">2</span>))  <span class="comment"># shape(nl,na,2)</span></span><br><span class="line">        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, <span class="number">1</span>) <span class="keyword">for</span> x <span class="keyword">in</span> ch)  <span class="comment"># output conv</span></span><br><span class="line">        self.inplace = inplace  <span class="comment"># use in-place ops (e.g. slice assignment)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        z = []  <span class="comment"># inference output</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.nl):</span><br><span class="line">            x[i] = self.m[i](x[i])  <span class="comment"># conv</span></span><br><span class="line">            bs, _, ny, nx = x[i].shape  <span class="comment"># x(bs,255,20,20) to x(bs,3,20,20,85)</span></span><br><span class="line">            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>).contiguous()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self.training:  <span class="comment"># inference</span></span><br><span class="line">                <span class="keyword">if</span> self.onnx_dynamic <span class="keyword">or</span> self.grid[i].shape[<span class="number">2</span>:<span class="number">4</span>] != x[i].shape[<span class="number">2</span>:<span class="number">4</span>]:</span><br><span class="line">                    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)</span><br><span class="line"></span><br><span class="line">                y = x[i].sigmoid()</span><br><span class="line">                <span class="keyword">if</span> self.inplace:</span><br><span class="line">                    y[..., <span class="number">0</span>:<span class="number">2</span>] = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">                    y[..., <span class="number">2</span>:<span class="number">4</span>] = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">                <span class="keyword">else</span>:  <span class="comment"># for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953</span></span><br><span class="line">                    xy = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">                    wh = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">                    y = torch.cat((xy, wh, y[..., <span class="number">4</span>:]), -<span class="number">1</span>)</span><br><span class="line">                z.append(y.view(bs, -<span class="number">1</span>, self.no))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x <span class="keyword">if</span> self.training <span class="keyword">else</span> (torch.cat(z, <span class="number">1</span>), x)</span><br></pre></td></tr></table></figure><h3 id="初始化函数init"><a href="#初始化函数init" class="headerlink" title="初始化函数init()"></a>初始化函数init()</h3><p>首先分析这个类的初始化函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nc=<span class="number">80</span>, anchors=(<span class="params"></span>), ch=(<span class="params"></span>), inplace=<span class="literal">True</span></span>):  <span class="comment"># 检测头</span></span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.nc = nc  <span class="comment"># 类别数</span></span><br><span class="line">    self.no = nc + <span class="number">5</span>  <span class="comment"># 输出的锚点数量</span></span><br><span class="line">    self.nl = <span class="built_in">len</span>(anchors)  <span class="comment"># 检测的层数</span></span><br><span class="line">    self.na = <span class="built_in">len</span>(anchors[<span class="number">0</span>]) // <span class="number">2</span>  <span class="comment"># 锚点的数量</span></span><br><span class="line">    self.grid = [torch.zeros(<span class="number">1</span>)] * self.nl  <span class="comment"># 初始化网格</span></span><br><span class="line">    self.anchor_grid = [torch.zeros(<span class="number">1</span>)] * self.nl  <span class="comment"># 初始化锚点框</span></span><br><span class="line">    self.register_buffer(<span class="string">&#x27;anchors&#x27;</span>, torch.tensor(anchors).<span class="built_in">float</span>().view(self.nl, -<span class="number">1</span>, <span class="number">2</span>))  <span class="comment"># shape(nl,na,2)=shape(3,3,2)</span></span><br><span class="line">    self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, <span class="number">1</span>) <span class="keyword">for</span> x <span class="keyword">in</span> ch)  <span class="comment"># 输出卷积结果</span></span><br><span class="line">    self.inplace = inplace  <span class="comment"># use in-place ops (e.g. slice assignment)</span></span><br></pre></td></tr></table></figure><p>yolov5的检测头仍为<strong>FPN结构</strong>，所以self.m为3个输出卷积。这三个输出卷积模块的channel变化分别为128$\longrightarrow$255|256$\longrightarrow$255|512$\longrightarrow$255。<br>self.no为每个anchor位置的输出channel维度，每个位置都预测80个类（coco）+ 4个位置坐标xywh + 1个confidence score。所以输出channel为85。每个尺度下有3个anchor位置，所以输出85*3&#x3D;255个channel。检测层数为3，锚点数量为85</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220319214026.png"></p><h3 id="forward-函数"><a href="#forward-函数" class="headerlink" title="forward()函数"></a>forward()函数</h3><p>接下来看head部分的forward()函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    z = []  <span class="comment"># inference output</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.nl):</span><br><span class="line">        x[i] = self.m[i](x[i])  <span class="comment"># conv</span></span><br><span class="line">        bs, _, ny, nx = x[i].shape  <span class="comment"># x(bs,255,20,20) to x(bs,3,20,20,85)</span></span><br><span class="line">        x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>).contiguous()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.training:  <span class="comment"># inference</span></span><br><span class="line">            <span class="keyword">if</span> self.onnx_dynamic <span class="keyword">or</span> self.grid[i].shape[<span class="number">2</span>:<span class="number">4</span>] != x[i].shape[<span class="number">2</span>:<span class="number">4</span>]:</span><br><span class="line">                self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)</span><br><span class="line"></span><br><span class="line">            y = x[i].sigmoid()</span><br><span class="line">            <span class="keyword">if</span> self.inplace:</span><br><span class="line">                y[..., <span class="number">0</span>:<span class="number">2</span>] = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">                y[..., <span class="number">2</span>:<span class="number">4</span>] = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953</span></span><br><span class="line">                xy = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">                wh = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">                y = torch.cat((xy, wh, y[..., <span class="number">4</span>:]), -<span class="number">1</span>)</span><br><span class="line">            z.append(y.view(bs, -<span class="number">1</span>, self.no))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x <span class="keyword">if</span> self.training <span class="keyword">else</span> (torch.cat(z, <span class="number">1</span>), x)</span><br></pre></td></tr></table></figure><p>x是一个列表的形式，分别对应着3个head的输入。它们的shape分别为：</p><ul><li>[bs, 128, 32, 32]</li><li>[1, 256, 16, 16]</li><li>[1, 512, 8, 8]</li></ul><p>三个输入先后被送入了3个卷积，得到输出结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>).contiguous()</span><br></pre></td></tr></table></figure><p>这里将x进行变换从：</p><p>x[0]：(bs,255,32,32) &#x3D;&gt; x(bs,3,32,32,85)<br>x[1]：(bs,255,32,32) &#x3D;&gt; x(bs,3,16,16,85)<br>x[2]：(bs,255,32,32) &#x3D;&gt; x(bs,3,8,8,85)</p><h3 id="make-grid-函数"><a href="#make-grid-函数" class="headerlink" title="make_grid()函数"></a>make_grid()函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_grid</span>(<span class="params">self, nx=<span class="number">20</span>, ny=<span class="number">20</span>, i=<span class="number">0</span></span>):</span><br><span class="line">    d = self.anchors[i].device</span><br><span class="line">    <span class="keyword">if</span> check_version(torch.__version__, <span class="string">&#x27;1.10.0&#x27;</span>):  <span class="comment"># torch&gt;=1.10.0 meshgrid workaround for torch&gt;=0.7 compatibility</span></span><br><span class="line">        yv, xv = torch.meshgrid([torch.arange(ny, device=d), torch.arange(nx, device=d)], indexing=<span class="string">&#x27;ij&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        yv, xv = torch.meshgrid([torch.arange(ny, device=d), torch.arange(nx, device=d)])</span><br><span class="line">    grid = torch.stack((xv, yv), <span class="number">2</span>).expand((<span class="number">1</span>, self.na, ny, nx, <span class="number">2</span>)).<span class="built_in">float</span>()</span><br><span class="line">    anchor_grid = (self.anchors[i].clone() * self.stride[i]) \</span><br><span class="line">        .view((<span class="number">1</span>, self.na, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)).expand((<span class="number">1</span>, self.na, ny, nx, <span class="number">2</span>)).<span class="built_in">float</span>()</span><br><span class="line">    <span class="keyword">return</span> grid, anchor_grid</span><br></pre></td></tr></table></figure><p>这里的_make_grid()函数是准备好格点。所有的预测的单位长度都是基于grid层面的而不是原图。注意每一层的grid的尺寸都是不一样的，和每一层输出的尺寸w,h是一样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">y = x[i].sigmoid()</span><br><span class="line"><span class="keyword">if</span> self.inplace:</span><br><span class="line">    y[..., <span class="number">0</span>:<span class="number">2</span>] = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">    y[..., <span class="number">2</span>:<span class="number">4</span>] = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line"><span class="keyword">else</span>:  <span class="comment"># for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953</span></span><br><span class="line">    xy = (y[..., <span class="number">0</span>:<span class="number">2</span>] * <span class="number">2</span> - <span class="number">0.5</span> + self.grid[i]) * self.stride[i]  <span class="comment"># xy</span></span><br><span class="line">    wh = (y[..., <span class="number">2</span>:<span class="number">4</span>] * <span class="number">2</span>) ** <span class="number">2</span> * self.anchor_grid[i]  <span class="comment"># wh</span></span><br><span class="line">    y = torch.cat((xy, wh, y[..., <span class="number">4</span>:]), -<span class="number">1</span>)</span><br><span class="line">z.append(y.view(bs, -<span class="number">1</span>, self.no))</span><br></pre></td></tr></table></figure><p>这里是inference的核心代码，对应的是yolov5的bbox回归机制。yolov5的回归机制如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/587c92d2ea4f4be386365fce177112f6.png"></p><p>相较于yolov3的回归机制，可以明显的发现box center的x，y的预测被乘以2并减去了0.5，所以这里的值域从yolov3里的(0，1)注意是开区间，变成了(-0.5， 1.5)。从表面理解是yolov5可以跨半个格点预测了，这样可以提高对格点周围的bbox的召回。当然还有一个好处就是也解决了yolov3中因为sigmoid开区间而导致中心无法到达边界处的问题。</p><p>同样，在w，h的回归上，yolov5也有了新的变化，同样对比yolov3的源代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = torch.sigmoid(prediction[..., <span class="number">0</span>])  <span class="comment"># Center x  #B A H W</span></span><br><span class="line">y = torch.sigmoid(prediction[..., <span class="number">1</span>])  <span class="comment"># Center y  #B A H W</span></span><br><span class="line">w = prediction[..., <span class="number">2</span>]  <span class="comment"># Width                    #B A H W</span></span><br><span class="line">h = prediction[..., <span class="number">3</span>]  <span class="comment"># Height                   #B A H W</span></span><br><span class="line">pred_conf = torch.sigmoid(prediction[..., <span class="number">4</span>])  <span class="comment"># Conf</span></span><br><span class="line">pred_cls = torch.sigmoid(prediction[..., <span class="number">5</span>:])  <span class="comment"># Cls pred.</span></span><br></pre></td></tr></table></figure><p>很明显yolov3对于w，h没有做sigmoid，而在yolov5中对于x，y，w，h都做了sigmoid。其次yolov5的预测缩放比例变成了：(2*w_pred&#x2F;h_pred) ^2。<br>值域从基于anchor宽高的（0，+∞）变成了（0，4）。这可能目的在于使预测的框范围更精准，通过sigmoid约束，让回归的框比例尺寸更为合理。</p><h2 id="class-Model-代码分析"><a href="#class-Model-代码分析" class="headerlink" title="class Model()代码分析"></a>class Model()代码分析</h2><p>接下来分析Model类里面的函数。主要分析它的前向传播过程，这里有两个函数：forward()和forward_once()。</p><h3 id="forward-函数-1"><a href="#forward-函数-1" class="headerlink" title="forward()函数"></a>forward()函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, augment=<span class="literal">False</span>, profile=<span class="literal">False</span>, visualize=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">if</span> augment:</span><br><span class="line">        <span class="keyword">return</span> self._forward_augment(x)  <span class="comment"># augmented inference, None</span></span><br><span class="line">    <span class="keyword">return</span> self._forward_once(x, profile, visualize)  <span class="comment"># single-scale inference, train</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_augment</span>(<span class="params">self, x</span>):</span><br><span class="line">    img_size = x.shape[-<span class="number">2</span>:]  <span class="comment"># height, width</span></span><br><span class="line">    s = [<span class="number">1</span>, <span class="number">0.83</span>, <span class="number">0.67</span>]  <span class="comment"># scales</span></span><br><span class="line">    f = [<span class="literal">None</span>, <span class="number">3</span>, <span class="literal">None</span>]  <span class="comment"># flips (2-ud, 3-lr)</span></span><br><span class="line">    y = []  <span class="comment"># outputs</span></span><br><span class="line">    <span class="keyword">for</span> si, fi <span class="keyword">in</span> <span class="built_in">zip</span>(s, f):</span><br><span class="line">        xi = scale_img(x.flip(fi) <span class="keyword">if</span> fi <span class="keyword">else</span> x, si, gs=<span class="built_in">int</span>(self.stride.<span class="built_in">max</span>()))</span><br><span class="line">        yi = self._forward_once(xi)[<span class="number">0</span>]  <span class="comment"># forward</span></span><br><span class="line">        <span class="comment"># cv2.imwrite(f&#x27;img_&#123;si&#125;.jpg&#x27;, 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1])  # save</span></span><br><span class="line">        yi = self._descale_pred(yi, fi, si, img_size)</span><br><span class="line">        y.append(yi)</span><br><span class="line">    y = self._clip_augmented(y)  <span class="comment"># clip augmented tails</span></span><br><span class="line">    <span class="keyword">return</span> torch.cat(y, <span class="number">1</span>), <span class="literal">None</span>  <span class="comment"># augmented inference, train</span></span><br></pre></td></tr></table></figure><p>self.forward()函数里面augment可以理解为控制TTA，如果打开会对图片进行<strong>scale</strong>和<strong>flip</strong>。默认是关闭的。</p><p>scale_img的源码如下：</p><h4 id="scale-img-函数"><a href="#scale-img-函数" class="headerlink" title="scale_img()函数"></a>scale_img()函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scale_img</span>(<span class="params">img, ratio=<span class="number">1.0</span>, same_shape=<span class="literal">False</span>, gs=<span class="number">32</span></span>):  <span class="comment"># img(16,3,256,416)</span></span><br><span class="line">    <span class="comment"># Scales img(bs,3,y,x) by ratio constrained to gs-multiple</span></span><br><span class="line">    <span class="keyword">if</span> ratio == <span class="number">1.0</span>:</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        h, w = img.shape[<span class="number">2</span>:]</span><br><span class="line">        s = (<span class="built_in">int</span>(h * ratio), <span class="built_in">int</span>(w * ratio))  <span class="comment"># new size</span></span><br><span class="line">        img = F.interpolate(img, size=s, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">False</span>)  <span class="comment"># resize</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> same_shape:  <span class="comment"># pad/crop img</span></span><br><span class="line">            h, w = (math.ceil(x * ratio / gs) * gs <span class="keyword">for</span> x <span class="keyword">in</span> (h, w))</span><br><span class="line">        <span class="keyword">return</span> F.pad(img, [<span class="number">0</span>, w - s[<span class="number">1</span>], <span class="number">0</span>, h - s[<span class="number">0</span>]], value=<span class="number">0.447</span>)  <span class="comment"># value = imagenet mean</span></span><br></pre></td></tr></table></figure><p>通过普通的双线性插值实现，根据ratio来控制图片的缩放比例，最后通过pad 0补齐到原图的尺寸。</p><h3 id="forward-once-函数"><a href="#forward-once-函数" class="headerlink" title="forward_once()函数"></a>forward_once()函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_forward_once</span>(<span class="params">self, x, profile=<span class="literal">False</span>, visualize=<span class="literal">False</span></span>):</span><br><span class="line">    y, dt = [], []  <span class="comment"># outputs</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> self.model:</span><br><span class="line">        <span class="keyword">if</span> m.f != -<span class="number">1</span>:  <span class="comment"># if not from previous layer</span></span><br><span class="line">            x = y[m.f] <span class="keyword">if</span> <span class="built_in">isinstance</span>(m.f, <span class="built_in">int</span>) <span class="keyword">else</span> [x <span class="keyword">if</span> j == -<span class="number">1</span> <span class="keyword">else</span> y[j] <span class="keyword">for</span> j <span class="keyword">in</span> m.f]  <span class="comment"># from earlier layers</span></span><br><span class="line">        <span class="keyword">if</span> profile:</span><br><span class="line">            self._profile_one_layer(m, x, dt)</span><br><span class="line">        x = m(x)  <span class="comment"># run</span></span><br><span class="line">        y.append(x <span class="keyword">if</span> m.i <span class="keyword">in</span> self.save <span class="keyword">else</span> <span class="literal">None</span>)  <span class="comment"># save output</span></span><br><span class="line">        <span class="keyword">if</span> visualize:</span><br><span class="line">            feature_visualization(x, m.<span class="built_in">type</span>, m.i, save_dir=visualize)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>self.foward_once()就是前向执行一次model里的所有module，得到结果。profile参数打开会记录每个模块的平均执行时长和flops用于分析模型的瓶颈，提高模型的执行速度和降低显存占用。</p><p>本文分析了yolov5head部分的前向传播和inference的源码。</p><p>参考资料：</p><ol><li><p><a href="https://blog.csdn.net/weixin_36714575/article/details/114238645">yolov5深度剖析+源码debug级讲解系列（三）yolov5 head源码解析</a></p></li><li><p><a href="https://www.likecs.com/show-204961615.html">YOLO全系列更新,YOLO的进化历程</a></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> yolov5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yolov5学习笔记3——源码剖析——Backbone部分1</title>
      <link href="/2022/03/18/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03/"/>
      <url>/2022/03/18/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03/</url>
      
        <content type="html"><![CDATA[<h1 id="Yolov5学习笔记3——源码剖析——Backbone部分1"><a href="#Yolov5学习笔记3——源码剖析——Backbone部分1" class="headerlink" title="Yolov5学习笔记3——源码剖析——Backbone部分1"></a>Yolov5学习笔记3——源码剖析——Backbone部分1</h1><h2 id="yolo-py源码解析"><a href="#yolo-py源码解析" class="headerlink" title="yolo.py源码解析"></a>yolo.py源码解析</h2><p>该代码路径为”<strong>models&#x2F;yolo.py</strong>“</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cfg=<span class="string">&#x27;yolov5s.yaml&#x27;</span>, ch=<span class="number">3</span>, nc=<span class="literal">None</span>, anchors=<span class="literal">None</span></span>):  <span class="comment"># model, input channels, number of classes</span></span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(cfg, <span class="built_in">dict</span>):</span><br><span class="line">        self.yaml = cfg  <span class="comment"># model dict</span></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># is *.yaml</span></span><br><span class="line">        <span class="keyword">import</span> yaml  <span class="comment"># for torch hub</span></span><br><span class="line">        self.yaml_file = Path(cfg).name</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(cfg, encoding=<span class="string">&#x27;ascii&#x27;</span>, errors=<span class="string">&#x27;ignore&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.yaml = yaml.safe_load(f)  <span class="comment"># model dict</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define model</span></span><br><span class="line">    ch = self.yaml[<span class="string">&#x27;ch&#x27;</span>] = self.yaml.get(<span class="string">&#x27;ch&#x27;</span>, ch)  <span class="comment"># input channels</span></span><br><span class="line">    <span class="keyword">if</span> nc <span class="keyword">and</span> nc != self.yaml[<span class="string">&#x27;nc&#x27;</span>]:</span><br><span class="line">        LOGGER.info(<span class="string">f&quot;Overriding model.yaml nc=<span class="subst">&#123;self.yaml[<span class="string">&#x27;nc&#x27;</span>]&#125;</span> with nc=<span class="subst">&#123;nc&#125;</span>&quot;</span>)</span><br><span class="line">        self.yaml[<span class="string">&#x27;nc&#x27;</span>] = nc  <span class="comment"># override yaml value</span></span><br><span class="line">    <span class="keyword">if</span> anchors:</span><br><span class="line">        LOGGER.info(<span class="string">f&#x27;Overriding model.yaml anchors with anchors=<span class="subst">&#123;anchors&#125;</span>&#x27;</span>)</span><br><span class="line">        self.yaml[<span class="string">&#x27;anchors&#x27;</span>] = <span class="built_in">round</span>(anchors)  <span class="comment"># override yaml value</span></span><br><span class="line">    self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])  <span class="comment"># model, savelist</span></span><br><span class="line">    self.names = [<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.yaml[<span class="string">&#x27;nc&#x27;</span>])]  <span class="comment"># default names</span></span><br><span class="line">    self.inplace = self.yaml.get(<span class="string">&#x27;inplace&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build strides, anchors</span></span><br><span class="line">    m = self.model[-<span class="number">1</span>]  <span class="comment"># Detect()</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, Detect):</span><br><span class="line">        s = <span class="number">256</span>  <span class="comment"># 2x min stride</span></span><br><span class="line">        m.inplace = self.inplace</span><br><span class="line">        m.stride = torch.tensor([s / x.shape[-<span class="number">2</span>] <span class="keyword">for</span> x <span class="keyword">in</span> self.forward(torch.zeros(<span class="number">1</span>, ch, s, s))])  <span class="comment"># forward</span></span><br><span class="line">        m.anchors /= m.stride.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        check_anchor_order(m)</span><br><span class="line">        self.stride = m.stride</span><br><span class="line">        self._initialize_biases()  <span class="comment"># only run once</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Init weights, biases</span></span><br><span class="line">    initialize_weights(self)</span><br><span class="line">    self.info()</span><br><span class="line">    LOGGER.info(<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><p>首先需要解析yaml配置文件，以yolov5s.yaml进行debug，可以看到解析后是一个dict形式：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220319201158.png"></p><ul><li>nc代表类别数量</li><li>depth_multiple是控制模型深度的参数。</li><li>width_multiple是一个控制模型宽度的参数。</li><li>anchors是预置的锚框，FPN每层设置3个，共有3*3&#x3D;9个。</li><li>backbone是backbone网络的构建参数，根据这个配置可以加载出backbone网络。</li><li>head是yolo head网络的构建参数，根据这个配置可以加载出yolo head的网络。（其实可以认为这部分是neck+head）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line">ch = self.yaml[<span class="string">&#x27;ch&#x27;</span>] = self.yaml.get(<span class="string">&#x27;ch&#x27;</span>, ch)  <span class="comment"># 输入通道</span></span><br><span class="line"><span class="keyword">if</span> nc <span class="keyword">and</span> nc != self.yaml[<span class="string">&#x27;nc&#x27;</span>]:</span><br><span class="line">    LOGGER.info(<span class="string">f&quot;Overriding model.yaml nc=<span class="subst">&#123;self.yaml[<span class="string">&#x27;nc&#x27;</span>]&#125;</span> with nc=<span class="subst">&#123;nc&#125;</span>&quot;</span>)</span><br><span class="line">    self.yaml[<span class="string">&#x27;nc&#x27;</span>] = nc  <span class="comment"># 覆盖yaml的值</span></span><br></pre></td></tr></table></figure><p>这里判断一下输入的channel和配置文件里的是否一致，不一致则以输入参数为准。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])  <span class="comment"># 模型, 保存列表</span></span><br></pre></td></tr></table></figure><p>然后进入核心的parse_model()函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_model</span>(<span class="params">d, ch</span>):  <span class="comment"># model_dict, input_channels(3)</span></span><br><span class="line">    </span><br><span class="line">    LOGGER.info(<span class="string">f&quot;\n<span class="subst">&#123;<span class="string">&#x27;&#x27;</span>:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;from&#x27;</span>:&gt;<span class="number">18</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;n&#x27;</span>:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;params&#x27;</span>:&gt;<span class="number">10</span>&#125;</span>  <span class="subst">&#123;<span class="string">&#x27;module&#x27;</span>:&lt;<span class="number">40</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;arguments&#x27;</span>:&lt;<span class="number">30</span>&#125;</span>&quot;</span>)</span><br><span class="line">    anchors, nc, gd, gw = d[<span class="string">&#x27;anchors&#x27;</span>], d[<span class="string">&#x27;nc&#x27;</span>], d[<span class="string">&#x27;depth_multiple&#x27;</span>], d[<span class="string">&#x27;width_multiple&#x27;</span>]</span><br><span class="line">    na = (<span class="built_in">len</span>(anchors[<span class="number">0</span>]) // <span class="number">2</span>) <span class="keyword">if</span> <span class="built_in">isinstance</span>(anchors, <span class="built_in">list</span>) <span class="keyword">else</span> anchors  <span class="comment"># number of anchors</span></span><br><span class="line">    no = na * (nc + <span class="number">5</span>)  <span class="comment"># number of outputs = anchors * (classes + 5)</span></span><br><span class="line"><span class="comment"># 这部分很简单，读出配置dict里面的参数，na是判断anchor的数量,no是根据anchor数量推断的输出维度，比如对于coco是255。输出维度=anchor数量*（类别数量+置信度+xywh四个回归坐标）。</span></span><br><span class="line"></span><br><span class="line">    layers, save, c2 = [], [], ch[-<span class="number">1</span>]  <span class="comment"># layers, savelist, ch out</span></span><br><span class="line">    <span class="keyword">for</span> i, (f, n, m, args) <span class="keyword">in</span> <span class="built_in">enumerate</span>(d[<span class="string">&#x27;backbone&#x27;</span>] + d[<span class="string">&#x27;head&#x27;</span>]):  <span class="comment"># from, number, module, args</span></span><br><span class="line">        m = <span class="built_in">eval</span>(m) <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, <span class="built_in">str</span>) <span class="keyword">else</span> m  <span class="comment"># eval strings</span></span><br><span class="line">        <span class="keyword">for</span> j, a <span class="keyword">in</span> <span class="built_in">enumerate</span>(args):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                args[j] = <span class="built_in">eval</span>(a) <span class="keyword">if</span> <span class="built_in">isinstance</span>(a, <span class="built_in">str</span>) <span class="keyword">else</span> a  <span class="comment"># eval strings</span></span><br><span class="line">            <span class="keyword">except</span> NameError:</span><br><span class="line">                <span class="keyword">pass</span>           </span><br><span class="line"><span class="comment"># 这里开始迭代循环backbone与head的配置。f，n，m，args分别代表着从哪层开始，模块的默认深度，模块的类型和模块的参数。</span></span><br><span class="line"></span><br><span class="line">        n = n_ = <span class="built_in">max</span>(<span class="built_in">round</span>(n * gd), <span class="number">1</span>) <span class="keyword">if</span> n &gt; <span class="number">1</span> <span class="keyword">else</span> n  <span class="comment"># depth gain</span></span><br><span class="line"><span class="comment"># 网络用n*gd控制模块的深度缩放，比如对于yolo5s来讲，gd为0.33，也就是把默认的深度缩放为原来的1/3。深度在这里指的是类似CSP这种模块的重复迭代次数。而宽度一般我们指的是特征图的channel。一般控制模型的缩放，我们就会控制深度、宽度和resolution（efficientnet的思路）。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> m <span class="keyword">in</span> [Conv, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, DWConv, MixConv2d, Focus, CrossConv,</span><br><span class="line">                 BottleneckCSP, C3, C3TR, C3SPP, C3Ghost]:</span><br><span class="line">            c1, c2 = ch[f], args[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> c2 != no:  <span class="comment"># if not output</span></span><br><span class="line">                c2 = make_divisible(c2 * gw, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">            args = [c1, c2, *args[<span class="number">1</span>:]]</span><br><span class="line">            <span class="keyword">if</span> m <span class="keyword">in</span> [BottleneckCSP, C3, C3TR, C3Ghost]:</span><br><span class="line">                args.insert(<span class="number">2</span>, n)  <span class="comment"># number of repeats</span></span><br><span class="line">                n = <span class="number">1</span></span><br><span class="line"><span class="comment"># 对于以上的这几种类型的模块，ch是一个用来保存之前所有的模块输出的channle，ch[-1]代表着上一个模块的输出通道。args[0]是默认的输出通道。</span></span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> nn.BatchNorm2d:</span><br><span class="line">            args = [ch[f]]</span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> Concat:</span><br><span class="line">            c2 = <span class="built_in">sum</span>(ch[x] <span class="keyword">for</span> x <span class="keyword">in</span> f)</span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> Detect:</span><br><span class="line">            args.append([ch[x] <span class="keyword">for</span> x <span class="keyword">in</span> f])</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(args[<span class="number">1</span>], <span class="built_in">int</span>):  <span class="comment"># number of anchors</span></span><br><span class="line">                args[<span class="number">1</span>] = [<span class="built_in">list</span>(<span class="built_in">range</span>(args[<span class="number">1</span>] * <span class="number">2</span>))] * <span class="built_in">len</span>(f)</span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> Contract:</span><br><span class="line">            c2 = ch[f] * args[<span class="number">0</span>] ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> Expand:</span><br><span class="line">            c2 = ch[f] // args[<span class="number">0</span>] ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            c2 = ch[f]</span><br><span class="line"></span><br><span class="line">        m_ = nn.Sequential(*(m(*args) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n))) <span class="keyword">if</span> n &gt; <span class="number">1</span> <span class="keyword">else</span> m(*args)  <span class="comment"># module</span></span><br><span class="line">        t = <span class="built_in">str</span>(m)[<span class="number">8</span>:-<span class="number">2</span>].replace(<span class="string">&#x27;__main__.&#x27;</span>, <span class="string">&#x27;&#x27;</span>)  <span class="comment"># module type</span></span><br><span class="line">        np = <span class="built_in">sum</span>(x.numel() <span class="keyword">for</span> x <span class="keyword">in</span> m_.parameters())  <span class="comment"># number params</span></span><br><span class="line">        m_.i, m_.f, m_.<span class="built_in">type</span>, m_.np = i, f, t, np  <span class="comment"># attach index, &#x27;from&#x27; index, type, number params</span></span><br><span class="line">        LOGGER.info(<span class="string">f&#x27;<span class="subst">&#123;i:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;<span class="built_in">str</span>(f):&gt;<span class="number">18</span>&#125;</span><span class="subst">&#123;n_:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;np:<span class="number">10.0</span>f&#125;</span>  <span class="subst">&#123;t:&lt;<span class="number">40</span>&#125;</span><span class="subst">&#123;<span class="built_in">str</span>(args):&lt;<span class="number">30</span>&#125;</span>&#x27;</span>)  <span class="comment"># print</span></span><br><span class="line">        save.extend(x % i <span class="keyword">for</span> x <span class="keyword">in</span> ([f] <span class="keyword">if</span> <span class="built_in">isinstance</span>(f, <span class="built_in">int</span>) <span class="keyword">else</span> f) <span class="keyword">if</span> x != -<span class="number">1</span>)  <span class="comment"># append to savelist</span></span><br><span class="line">        layers.append(m_)</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            ch = []</span><br><span class="line">        ch.append(c2)</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers), <span class="built_in">sorted</span>(save)</span><br></pre></td></tr></table></figure><p>逐步分析这个函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LOGGER.info(<span class="string">f&quot;\n<span class="subst">&#123;<span class="string">&#x27;&#x27;</span>:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;from&#x27;</span>:&gt;<span class="number">18</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;n&#x27;</span>:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;params&#x27;</span>:&gt;<span class="number">10</span>&#125;</span>  <span class="subst">&#123;<span class="string">&#x27;module&#x27;</span>:&lt;<span class="number">40</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;arguments&#x27;</span>:&lt;<span class="number">30</span>&#125;</span>&quot;</span>)</span><br><span class="line">anchors, nc, gd, gw = d[<span class="string">&#x27;anchors&#x27;</span>], d[<span class="string">&#x27;nc&#x27;</span>], d[<span class="string">&#x27;depth_multiple&#x27;</span>], d[<span class="string">&#x27;width_multiple&#x27;</span>]</span><br><span class="line">na = (<span class="built_in">len</span>(anchors[<span class="number">0</span>]) // <span class="number">2</span>) <span class="keyword">if</span> <span class="built_in">isinstance</span>(anchors, <span class="built_in">list</span>) <span class="keyword">else</span> anchors  <span class="comment"># number of anchors</span></span><br><span class="line">no = na * (nc + <span class="number">5</span>)  <span class="comment"># number of outputs = anchors * (classes + 5)</span></span><br></pre></td></tr></table></figure><p>这部分很简单，读出配置dict里面的参数，na是判断anchor的数量,no是根据anchor数量推断的输出维度，比如对于coco是255。输出维度&#x3D;anchor数量*（类别数量+置信度+xywh四个回归坐标）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, (f, n, m, args) <span class="keyword">in</span> <span class="built_in">enumerate</span>(d[<span class="string">&#x27;backbone&#x27;</span>] + d[<span class="string">&#x27;head&#x27;</span>]):  <span class="comment"># from, number, module, args</span></span><br><span class="line">    m = <span class="built_in">eval</span>(m) <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, <span class="built_in">str</span>) <span class="keyword">else</span> m  <span class="comment"># eval strings</span></span><br><span class="line">    <span class="keyword">for</span> j, a <span class="keyword">in</span> <span class="built_in">enumerate</span>(args):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            args[j] = <span class="built_in">eval</span>(a) <span class="keyword">if</span> <span class="built_in">isinstance</span>(a, <span class="built_in">str</span>) <span class="keyword">else</span> a  <span class="comment"># eval strings</span></span><br><span class="line">        <span class="keyword">except</span> NameError:</span><br><span class="line">            <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>这里开始迭代循环backbone与head的配置。f，n，m，args分别代表着从哪层开始，模块的默认深度，模块的类型和模块的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n = n_ = <span class="built_in">max</span>(<span class="built_in">round</span>(n * gd), <span class="number">1</span>) <span class="keyword">if</span> n &gt; <span class="number">1</span> <span class="keyword">else</span> n  <span class="comment"># depth gain</span></span><br></pre></td></tr></table></figure><p>网络用n*gd控制模块的深度缩放，比如对于yolo5s来讲，gd为0.33，也就是把默认的深度缩放为原来的1&#x2F;3。深度在这里指的是类似CSP这种模块的重复迭代次数。而宽度一般我们指的是特征图的channel。一般控制模型的缩放，我们就会控制深度、宽度和resolution（efficientnet的思路）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> m <span class="keyword">in</span> [Conv, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, DWConv, MixConv2d, Focus, CrossConv,</span><br><span class="line">         BottleneckCSP, C3, C3TR, C3SPP, C3Ghost]:</span><br><span class="line">    c1, c2 = ch[f], args[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> c2 != no:  <span class="comment"># if not output</span></span><br><span class="line">        c2 = make_divisible(c2 * gw, <span class="number">8</span>)</span><br></pre></td></tr></table></figure><p>对于以上的这几种类型的模块，ch是一个用来保存之前所有的模块输出的channle，ch[-1]代表着上一个模块的输出通道。args[0]是默认的输出通道</p><p>上述第五行make_divisible()函数的源代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_divisible</span>(<span class="params">x, divisor</span>):</span><br><span class="line">    <span class="comment"># Returns nearest x divisible by divisor</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(divisor, torch.Tensor):</span><br><span class="line">        divisor = <span class="built_in">int</span>(divisor.<span class="built_in">max</span>())  <span class="comment"># to int</span></span><br><span class="line">    <span class="keyword">return</span> math.ceil(x / divisor) * divisor</span><br></pre></td></tr></table></figure><p>这里配合make_divisible()函数，是为了放缩网络模块的宽度（既输出的通道数），比如对于第一个模块“Focus”，默认的输出通道是64，而yolov5s里的放缩系数是0.5，所以通过以上代码变换，最终的输出通道为32。make_divisible()函数保证了输出的通道是8的倍数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">args = [c1, c2, *args[<span class="number">1</span>:]]</span><br><span class="line"><span class="keyword">if</span> m <span class="keyword">in</span> [BottleneckCSP, C3, C3TR, C3Ghost]:</span><br><span class="line"> args.insert(<span class="number">2</span>, n)  <span class="comment"># number of repeats</span></span><br><span class="line">n = <span class="number">1</span></span><br></pre></td></tr></table></figure><p>经过以上处理，args里面保存的前两个参数就是module的输入通道数、输出通道数。只有BottleneckCSP和C3这两种module会根据深度参数n被调整该模块的重复迭加次数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">elif</span> m <span class="keyword">is</span> nn.BatchNorm2d:</span><br><span class="line">    args = [ch[f]]</span><br><span class="line"><span class="keyword">elif</span> m <span class="keyword">is</span> Concat:</span><br><span class="line">    c2 = <span class="built_in">sum</span>(ch[x] <span class="keyword">for</span> x <span class="keyword">in</span> f)</span><br><span class="line"><span class="keyword">elif</span> m <span class="keyword">is</span> Detect:</span><br><span class="line">    args.append([ch[x] <span class="keyword">for</span> x <span class="keyword">in</span> f])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(args[<span class="number">1</span>], <span class="built_in">int</span>):  <span class="comment"># number of anchors</span></span><br><span class="line">        args[<span class="number">1</span>] = [<span class="built_in">list</span>(<span class="built_in">range</span>(args[<span class="number">1</span>] * <span class="number">2</span>))] * <span class="built_in">len</span>(f)</span><br><span class="line"><span class="keyword">elif</span> m <span class="keyword">is</span> Contract:</span><br><span class="line">    c2 = ch[f] * args[<span class="number">0</span>] ** <span class="number">2</span></span><br><span class="line"><span class="keyword">elif</span> m <span class="keyword">is</span> Expand:</span><br><span class="line">    c2 = ch[f] // args[<span class="number">0</span>] ** <span class="number">2</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    c2 = ch[f]</span><br></pre></td></tr></table></figure><p>以上是其他几种类型的Module。<br>如果是nn.BatchNorm2d则通道数保持不变。<br>如果是Concat则f是所有需要拼接层的index，则输出通道c2是所有层的和。<br>如果是Detect则对应检测头，这部分后面再详细讲。<br>Contract和Expand目前未在模型中使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">m_ = nn.Sequential(*(m(*args) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n))) <span class="keyword">if</span> n &gt; <span class="number">1</span> <span class="keyword">else</span> m(*args)  <span class="comment"># module</span></span><br></pre></td></tr></table></figure><p>这里把args里的参数用于构建了module m，然后模块的循环次数用参数n控制。整体都受到宽度缩放，C3模块受到深度缩放。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t = <span class="built_in">str</span>(m)[<span class="number">8</span>:-<span class="number">2</span>].replace(<span class="string">&#x27;__main__.&#x27;</span>, <span class="string">&#x27;&#x27;</span>)  <span class="comment"># module type</span></span><br><span class="line">np = <span class="built_in">sum</span>(x.numel() <span class="keyword">for</span> x <span class="keyword">in</span> m_.parameters())  <span class="comment"># number params</span></span><br><span class="line">m_.i, m_.f, m_.<span class="built_in">type</span>, m_.np = i, f, t, np  <span class="comment"># attach index, &#x27;from&#x27; index, type, number params</span></span><br><span class="line">LOGGER.info(<span class="string">f&#x27;<span class="subst">&#123;i:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;<span class="built_in">str</span>(f):&gt;<span class="number">18</span>&#125;</span><span class="subst">&#123;n_:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;np:<span class="number">10.0</span>f&#125;</span>  <span class="subst">&#123;t:&lt;<span class="number">40</span>&#125;</span><span class="subst">&#123;<span class="built_in">str</span>(args):&lt;<span class="number">30</span>&#125;</span>&#x27;</span>)  <span class="comment"># print</span></span><br></pre></td></tr></table></figure><p>这里做了一些输出打印，可以看到每一层module构建的编号、参数量等情况，如下所示：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220319203847.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">save.extend(x % i <span class="keyword">for</span> x <span class="keyword">in</span> ([f] <span class="keyword">if</span> <span class="built_in">isinstance</span>(f, <span class="built_in">int</span>) <span class="keyword">else</span> f) <span class="keyword">if</span> x != -<span class="number">1</span>)  <span class="comment"># append to savelist</span></span><br><span class="line">    layers.append(m_)</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        ch = []</span><br><span class="line">    ch.append(c2)</span><br><span class="line"><span class="keyword">return</span> nn.Sequential(*layers), <span class="built_in">sorted</span>(save)</span><br></pre></td></tr></table></figure><p>最后把构建的模块保存到layers里，把该层的输出通道数写入ch列表里。<br>待全部循环结束后再构建成模型。至此模型就全部构建完毕了。</p><p>再回到yolo.py里刚刚调用parse_model的位置继续学习init()函数的学习。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">m = self.model[-<span class="number">1</span>]  <span class="comment"># Detect()</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(m, Detect):</span><br><span class="line">    s = <span class="number">256</span>  <span class="comment"># 2x min stride</span></span><br><span class="line">    m.inplace = self.inplace</span><br><span class="line">    m.stride = torch.tensor([s / x.shape[-<span class="number">2</span>] <span class="keyword">for</span> x <span class="keyword">in</span> self.forward(torch.zeros(<span class="number">1</span>, ch, s, s))])  <span class="comment"># forward</span></span><br><span class="line">    m.anchors /= m.stride.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    check_anchor_order(m)</span><br><span class="line">    self.stride = m.stride</span><br><span class="line">    self._initialize_biases()  <span class="comment"># only run once</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Init weights, biases</span></span><br><span class="line">initialize_weights(self)</span><br><span class="line">self.info()</span><br><span class="line">LOGGER.info(<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><p>这里通过调用一次forward()函数，输入了一个[1, 3, 256, 256]的tensor(ch&#x3D;3)，然后得到FPN输出结果的维度。然后求出了下次采样的倍数stride：8，16，32。<br>最后把anchor除以以上的数值，将anchor放缩到了3个不同的尺度上。anchor的最终shape是[3,3,2]。<br>至此init()函数已经完整的过了一遍。</p><h2 id="其他Modules中的源码解析"><a href="#其他Modules中的源码解析" class="headerlink" title="其他Modules中的源码解析"></a>其他Modules中的源码解析</h2><p>在网络构建的过程中涉及到了多种Modules，这些Modules默认在models文件夹下面的common.py文件里我们下面还过一下这些函数。</p><h3 id="普通卷积Conv"><a href="#普通卷积Conv" class="headerlink" title="普通卷积Conv"></a>普通卷积Conv</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Conv</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Standard convolution</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=<span class="number">1</span>, s=<span class="number">1</span>, p=<span class="literal">None</span>, g=<span class="number">1</span>, act=<span class="literal">True</span></span>):  <span class="comment"># ch_in, ch_out, kernel, stride, padding, groups</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn = nn.BatchNorm2d(c2)</span><br><span class="line">        self.act = nn.SiLU() <span class="keyword">if</span> act <span class="keyword">is</span> <span class="literal">True</span> <span class="keyword">else</span> (act <span class="keyword">if</span> <span class="built_in">isinstance</span>(act, nn.Module) <span class="keyword">else</span> nn.Identity())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.act(self.bn(self.conv(x)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_fuse</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.act(self.conv(x))</span><br></pre></td></tr></table></figure><p>普通的卷积，这里调用了autopad()函数计算了same-padding所需要的padding数量。<br>默认的激活函数是SiLU()，即Sigmoid激活函数。各种激活函数见下图。<br>SiLU函数形式：f(x)&#x3D;x⋅σ(x)<br>导函数形式： f’(x)&#x3D;f(x)+σ(x)(1−f(x))</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/1b4516bab0d8e3664e773d091d59ea32.png"></p><p><strong>yolo5的作者使用了 Leaky ReLU 和 Sigmoid 激活函数。yolo5中中间&#x2F;隐藏层使用了 Leaky ReLU 激活函数，最后的检测层使用了 Sigmoid 形激活函数。而YOLO V4使用Mish激活函数。</strong></p><h3 id="BottleNeck结构"><a href="#BottleNeck结构" class="headerlink" title="BottleNeck结构"></a>BottleNeck结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Standard bottleneck</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, shortcut=<span class="literal">True</span>, g=<span class="number">1</span>, e=<span class="number">0.5</span></span>):  <span class="comment"># ch_in, ch_out, shortcut, groups, expansion</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        c_ = <span class="built_in">int</span>(c2 * e)  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = Conv(c_, c2, <span class="number">3</span>, <span class="number">1</span>, g=g)</span><br><span class="line">        self.add = shortcut <span class="keyword">and</span> c1 == c2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x + self.cv2(self.cv1(x)) <span class="keyword">if</span> self.add <span class="keyword">else</span> self.cv2(self.cv1(x))</span><br></pre></td></tr></table></figure><p>可以看出BottleNeck结构默认是先1x1卷积缩小channel为原来的1&#x2F;2，再通过3x3卷积提取特征。如果输入通道c1和3x3卷积输出通道c2相等，则进行残差输出。shortcut参数控制是否进行残差连接。</p><h3 id="BottleNeckCSP和C3"><a href="#BottleNeckCSP和C3" class="headerlink" title="BottleNeckCSP和C3"></a>BottleNeckCSP和C3</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BottleneckCSP</span>(nn.Module):</span><br><span class="line">    <span class="comment"># CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, n=<span class="number">1</span>, shortcut=<span class="literal">True</span>, g=<span class="number">1</span>, e=<span class="number">0.5</span></span>):  <span class="comment"># ch_in, ch_out, number, shortcut, groups, expansion</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        c_ = <span class="built_in">int</span>(c2 * e)  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = nn.Conv2d(c1, c_, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.cv3 = nn.Conv2d(c_, c_, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.cv4 = Conv(<span class="number">2</span> * c_, c2, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.bn = nn.BatchNorm2d(<span class="number">2</span> * c_)  <span class="comment"># applied to cat(cv2, cv3)</span></span><br><span class="line">        self.act = nn.SiLU()</span><br><span class="line">        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=<span class="number">1.0</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y1 = self.cv3(self.m(self.cv1(x)))</span><br><span class="line">        y2 = self.cv2(x)</span><br><span class="line">        <span class="keyword">return</span> self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=<span class="number">1</span>))))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">C3</span>(nn.Module):</span><br><span class="line">    <span class="comment"># CSP Bottleneck with 3 convolutions</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, n=<span class="number">1</span>, shortcut=<span class="literal">True</span>, g=<span class="number">1</span>, e=<span class="number">0.5</span></span>):  <span class="comment"># ch_in, ch_out, number, shortcut, groups, expansion</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        c_ = <span class="built_in">int</span>(c2 * e)  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv3 = Conv(<span class="number">2</span> * c_, c2, <span class="number">1</span>)  <span class="comment"># act=FReLU(c2)</span></span><br><span class="line">        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=<span class="number">1.0</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)))</span><br><span class="line">        <span class="comment"># self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>在common.py里实现了两种csp结构：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20210228161030675.png"></p><p>BottleneckCSP就完全对应着上面的结构。但是作者在yoloV5 4.0的版本中将这部分结构改成了C3。C3的结构如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20210228161503472.png"></p><p>残差之后的Conv被去掉了，激活函数从上面的LeakyRelu变为了SiLU。</p><h3 id="SPP"><a href="#SPP" class="headerlink" title="SPP"></a>SPP</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SPP</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Spatial Pyramid Pooling (SPP) layer https://arxiv.org/abs/1406.4729</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=(<span class="params"><span class="number">5</span>, <span class="number">9</span>, <span class="number">13</span></span>)</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        c_ = c1 // <span class="number">2</span>  <span class="comment"># hidden channels</span></span><br><span class="line">        self.cv1 = Conv(c1, c_, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.cv2 = Conv(c_ * (<span class="built_in">len</span>(k) + <span class="number">1</span>), c2, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=<span class="number">1</span>, padding=x // <span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> k])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.cv1(x)</span><br><span class="line">        <span class="keyword">with</span> warnings.catch_warnings():</span><br><span class="line">            warnings.simplefilter(<span class="string">&#x27;ignore&#x27;</span>)  <span class="comment"># suppress torch 1.9.0 max_pool2d() warning</span></span><br><span class="line">            <span class="keyword">return</span> self.cv2(torch.cat([x] + [m(x) <span class="keyword">for</span> m <span class="keyword">in</span> self.m], <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>SPP模块将输入通道减半，然后分别做kernel size为5，9，13的maxpooling，最后将结过拼接，包含原始输入的四组结果合并后通道应该是原来的2倍。</p><h3 id="Focus"><a href="#Focus" class="headerlink" title="Focus"></a>Focus</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Focus</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Focus wh information into c-space</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, c1, c2, k=<span class="number">1</span>, s=<span class="number">1</span>, p=<span class="literal">None</span>, g=<span class="number">1</span>, act=<span class="literal">True</span></span>):  <span class="comment"># ch_in, ch_out, kernel, stride, padding, groups</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = Conv(c1 * <span class="number">4</span>, c2, k, s, p, g, act)</span><br><span class="line">        <span class="comment"># self.contract = Contract(gain=2)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)</span></span><br><span class="line">        <span class="keyword">return</span> self.conv(torch.cat([x[..., ::<span class="number">2</span>, ::<span class="number">2</span>], x[..., <span class="number">1</span>::<span class="number">2</span>, ::<span class="number">2</span>], x[..., ::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>], x[..., <span class="number">1</span>::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>]], <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># return self.conv(self.contract(x))</span></span><br></pre></td></tr></table></figure><p>把feature map 切成四等分，然后叠加起来。最后的结果是通道数变为原来的四倍，resolution为原来的1&#x2F;4（H，W分别减半）。最后通过一个卷积调整通道数为预先设置。</p><p>参考文章：</p><ol><li><p><a href="https://blog.csdn.net/weixin_36714575/article/details/114211796?spm=1001.2014.3001.5501">yolov5深度剖析+源码debug级讲解系列（二）backbone构建</a></p></li><li><p><a href="https://blog.csdn.net/l641208111/article/details/109286497">yolo5的改进策略</a></p></li><li><p>[深入浅出Yolo系列之Yolov5核心基础知识完整讲解](<a href="https://zhuanlan.zhihu.com/p/172121380">深入浅出Yolo系列之Yolov5核心基础知识完整讲解 - 知乎 (zhihu.com)</a>)</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> yolov5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实用软件、脚本和工具</title>
      <link href="/2022/03/17/%E5%AE%9E%E7%94%A8%E8%BD%AF%E4%BB%B6%E3%80%81%E6%8F%92%E4%BB%B6%E5%92%8C%E8%84%9A%E6%9C%AC/"/>
      <url>/2022/03/17/%E5%AE%9E%E7%94%A8%E8%BD%AF%E4%BB%B6%E3%80%81%E6%8F%92%E4%BB%B6%E5%92%8C%E8%84%9A%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<h1 id="实用软件、脚本和工具。"><a href="#实用软件、脚本和工具。" class="headerlink" title="实用软件、脚本和工具。"></a>实用软件、脚本和工具。</h1><h2 id="Tampermonkey油猴插件"><a href="#Tampermonkey油猴插件" class="headerlink" title="Tampermonkey油猴插件"></a>Tampermonkey油猴插件</h2><p>油猴浏览器插件实际上是一个用户脚本管理器，主要依靠各大社区编写的扩展脚本（JavaScript代码）运行在浏览器上，来改变被访问网页的功能，提升我们的网页浏览体验 。</p><h3 id="插件的安装"><a href="#插件的安装" class="headerlink" title="插件的安装"></a>插件的安装</h3><p><strong>方法一</strong></p><p>①途径——浏览器上打开<a href="https://chrome.google.com/webstore/search/tampermonkey?hl=zh-CN">谷歌网上应用店</a>搜索 ,然后点击<strong>添加至Chrome</strong>。(谷歌浏览器专用，一般需要科学上网。)</p><p>②途径——或者直接进入<a href="https://www.tampermonkey.net/">Tampermonkey官网</a><strong>下载</strong>然后添加到浏览器中。</p><p><img src="F:\Blog\picture\20220317232319.png"></p><p>以上，<strong>Tampermonkey Stable</strong>为正式版，<strong>Tampermonkey Beta</strong>为测试版</p><p><strong>方法二</strong></p><p>由<strong>方法一</strong>可得知Tampermonkey是附属于google上的，考虑到文明上网的普及问题，这里我们也可以在其他渠道获取<a href="https://wmhl.lanzoui.com/ib8glab">Tampermonkey的crx文件</a>，然后解压提取出来。</p><p>然后进入浏览器<strong>设置</strong>→<strong>扩展程序</strong>，进入后再打开右上角的<strong>开发者模式</strong>并保持该窗口的开启。之后找到被解压后的<code>tampermonkey.crx</code>文件，将其拖动到<strong>扩展程序</strong>界面，释放并同意安装。</p><p><img src="F:\Blog\picture\20220317233113.png"></p><h3 id="获取脚本的方式"><a href="#获取脚本的方式" class="headerlink" title="获取脚本的方式"></a><strong>获取脚本的方式</strong></h3><p>我常用<a href="https://greasyfork.org/zh-CN/scripts/28497-%E7%BD%91%E9%A1%B5%E9%99%90%E5%88%B6%E8%A7%A3%E9%99%A4-%E6%94%B9">GreasyFork</a>，用的人也多，最重要的是支持中文！想用什么脚本吗，或者脚本应用在什么网站都可以直接搜索。</p><h3 id="我的常用脚本。"><a href="#我的常用脚本。" class="headerlink" title="我的常用脚本。"></a>我的常用脚本。</h3><table><thead><tr><th align="center">脚本</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center"><a href="https://greasyfork.org/zh-CN/scripts/28497-%E7%BD%91%E9%A1%B5%E9%99%90%E5%88%B6%E8%A7%A3%E9%99%A4-%E6%94%B9">网页限制解除(改)</a></td><td align="center">通杀大部分网站,可以解除禁止复制、剪切、选择文本、右键菜单的限制。</td></tr><tr><td align="center"><a href="https://greasyfork.org/scripts/412245">Github增强-高速下载</a></td><td align="center">高速下载 Git Clone&#x2F;SSH、Release、Raw、Code(ZIP) 等文件、项目列表单文件快捷下载 (☁)</td></tr><tr><td align="center"><a href="https://greasyfork.org/zh-CN/scripts/389343">知网PDF下载助手</a></td><td align="center">添加知网文献PDF下载按钮，支持搜索列表、详情页，下载论文章节目录，批量下载文献，一键切换CAJ和PDF格式</td></tr><tr><td align="center"><a href="https://greasyfork.org/zh-CN/scripts/428960">免登录去弹窗</a></td><td align="center">CSDN&#x2F;知乎&#x2F;哔哩哔哩&#x2F;简书免登录去除弹窗广告+去除所有广告+界面优化</td></tr><tr><td align="center"><a href="https://greasyfork.org/zh-CN/scripts/419224">蓝奏云网盘增强</a></td><td align="center">刷新不回根目录、后退返回上一级、右键文件显示菜单、点击直接下载文件、点击空白进入目录、自动显示更多文件、一键复制所有分享链接、自定义分享链接域名、自动打开&#x2F;复制分享链接、带密码的分享链接自动输密码、拖入文件自动显示上传框、输入密码后回车确认</td></tr><tr><td align="center"><a href="https://greasyfork.org/zh-CN/scripts/438563">电子书下载1</a></td><td align="center">直接下载全国图书馆参考咨询联盟为PDF，有目录书签</td></tr><tr><td align="center"><a href="https://greasyfork.org/zh-CN/scripts/432075">电子书下载2</a></td><td align="center">查询全国图书馆参考咨询联盟、读秀、超星、龙岩是否有书互助,自动获取435w无重全文PDF,（全网独家）不需要某度会员高速下载PDF！另（独家）全程免注册、免脚本、手机即可搜,下,看，复制浏览器打开： <a href="http://172.247.14.184/">http://172.247.14.184/</a></td></tr><tr><td align="center"><a href="https://greasyfork.org/zh-CN/scripts/418804">VIP视频网站</a></td><td align="center">解锁B站大会员番剧、B站视频解析下载；全网VIP视频免费破解去广告；全网音乐直接下载；油管、Facebook等国外视频解析下载</td></tr><tr><td align="center">……</td><td align="center">有需求就进脚本网站找对应脚本即可</td></tr></tbody></table><h2 id="一些其他插件"><a href="#一些其他插件" class="headerlink" title="一些其他插件"></a>一些其他插件</h2><h3 id="ublock-origin插件"><a href="#ublock-origin插件" class="headerlink" title="ublock origin插件"></a>ublock origin插件</h3><p><a href="https://chrome.zzzmh.cn/info?token=cjpalhdlnbpafiamejdnhcphjbkeiagm">ublock origin</a>是一款高效的网络请求过滤工具，占用极低的内存和 CPU，占用极低的内存和CPU，和其他常见的过滤工具相比，它能够加载并执行上千条过滤规则。</p><h3 id="IGG谷歌访问助手"><a href="#IGG谷歌访问助手" class="headerlink" title="IGG谷歌访问助手"></a>IGG谷歌访问助手</h3><p><a href="https://chrome.zzzmh.cn/info?token=ncldcbhpeplkfijdhnoepdgdnmjkckij">IGG谷歌访问助手</a>免费为广大科研及医务工作者、高校学生提供谷歌学术文献、期刊等资料产品的查询与加速访问。<br>您可以从一个位置搜索众多学科和资料来源：来自学术著作出版商、专业性社团、预印本、各大学及其他学术组织的经同行评论的文章、论文、图书、摘要和文章。可帮助您在整个学术领域中确定相关性最强的研究。</p><h3 id="Abcd-PDF"><a href="#Abcd-PDF" class="headerlink" title="Abcd PDF"></a>Abcd PDF</h3><p><a href="https://chrome.zzzmh.cn/info?token=mcgnagemenncafhpabimmooimpngdcpn">Abcd PDF</a>可以在线将PDF转换为 Word、Excel和PPT。可在线编辑Word和PDF。100%免费，提高您的生产力。<br>Abcd PDF 扩展是 100% 免费的多合一 PDF 工具</p><h3 id="Infinity新标签页"><a href="#Infinity新标签页" class="headerlink" title="Infinity新标签页"></a>Infinity新标签页</h3><p><a href="https://chrome.zzzmh.cn/info?token=dbfmnekepjoapopniengjbcpnbljalfg">Infinity新标签页</a>是一款基于html5的Chrome扩展程序，它重新定义了您的Chrome新标签页。相比Chrome自带的新标签页，您可以通过Infinity自定义添加自己喜爱的网站，我们重绘了上千图标，当然您也可以自定义这些网站的图标。除此之外，您还可以更新新标签页的背景图片，既可以使用您自己的图片，也可以使用自动更换图片。集成了天气，待办事项，笔记等功能，甚至还能显示你的Gmail邮件数量和通知。</p><h3 id="彩云小译"><a href="#彩云小译" class="headerlink" title="彩云小译"></a>彩云小译</h3><p><a href="https://chrome.zzzmh.cn/info?token=jmpepeebcbihafjjadogphmbgiffiajh">彩云小译</a>双语对照网页翻译插件，针对浏览器开发的一款网页翻译工具，一键高效获取母语阅读体验。</p><blockquote><p>上文中提到的所有插件的某度链接如下：</p><p>​    链接: <a href="https://pan.baidu.com/s/17yGQF_krywzgEFEli60zsg?pwd=wz83">https://pan.baidu.com/s/17yGQF_krywzgEFEli60zsg?pwd=wz83</a> </p><p>​    提取码: wz83</p></blockquote><h2 id="一些软件"><a href="#一些软件" class="headerlink" title="一些软件"></a>一些软件</h2><h3 id="Everything"><a href="#Everything" class="headerlink" title="Everything"></a>Everything</h3><p>“<a href="https://www.voidtools.com/zh-cn/">Everything</a>“ 是 Windows 上一款搜索引擎，它能够基于文件名快速定文件和文件夹位置。<br>不像 Windows 内置搜索，”Everything” 默认显示电脑上每个文件和文件夹 (就如其名 “Everything”)。<br>您在搜索框输入的关键词将会筛选显示的文件和文件夹。</p><h3 id="流量盘"><a href="#流量盘" class="headerlink" title="流量盘"></a>流量盘</h3><p>流量盘是一款高速下载某度云资源的软件。</p><p>某度链接：</p><p>​    链接: <a href="https://pan.baidu.com/s/1Ukaw2MCfg7uJJ_t32fwOmA">https://pan.baidu.com/s/1Ukaw2MCfg7uJJ_t32fwOmA</a> </p><p>​    提取码: ivky </p><p>未完待续……</p>]]></content>
      
      
      <categories>
          
          <category> 效率 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv5学习笔记2</title>
      <link href="/2022/03/17/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/"/>
      <url>/2022/03/17/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/</url>
      
        <content type="html"><![CDATA[<h1 id="Yolov5学习笔记2——代码框架"><a href="#Yolov5学习笔记2——代码框架" class="headerlink" title="Yolov5学习笔记2——代码框架"></a>Yolov5学习笔记2——代码框架</h1><p>打开Yolov5的代码，可以看到有许多文件夹和很多的子文件。本文主要弄清楚Yolov5的代码框架。</p><h2 id="data文件夹"><a href="#data文件夹" class="headerlink" title="data文件夹"></a>data文件夹</h2><p>该文件夹下主要存放项目运行所需要的数据，包括一些超参、默认输入的图片等。</p><h3 id="hyps文件夹"><a href="#hyps文件夹" class="headerlink" title="hyps文件夹"></a>hyps文件夹</h3><p>该文件夹下存放的都是训练参数</p><ol><li><code>hyp.Objects365.yaml</code>——项目在进行Objects365训练的超参数。</li><li><code>hyp.scratch-high.yaml</code>——里面的参数为对COCO数据集从零开始进行高增强训练的超参数。</li><li><code>hyp.scratch-low.yaml</code>——对COCO数据集从零开始进行低增强训练的超参数。</li><li><code>hyp.scratch-med.yaml</code>——对COCO数据集从零开始进行中等增强训练的超参数。</li><li><code>hyp.VOC.yaml</code>——对VOC数据集进行训练时的超参数。</li></ol><p>一般这些参数都不需要改动，这是作者团队大量训练记录的最好的参数结果。</p><h3 id="images文件夹"><a href="#images文件夹" class="headerlink" title="images文件夹"></a>images文件夹</h3><p>该文件夹下存放了代码默认执行detect.py时检测的图片，执行后会在目录中新建一个<strong>runs</strong>文件夹并将检测的结果存放在&#x2F;runs&#x2F;detect文件夹下。</p><h3 id="scripts文件夹"><a href="#scripts文件夹" class="headerlink" title="scripts文件夹"></a>scripts文件夹</h3><p>脚本文件夹。提供了下载权重文件夹、COCO数据集、COCO128数据集的方法。直接执行该脚本文件就可以直接下载<code>yolov5x.pt</code>文件和训练的数据集。</p><p><strong>注意</strong>：如果想要运行脚本文件的话，首先要确定<code>PyCharm</code>有没有安装<code>PowerShell</code>平台，一般<code>PyCharm</code>会提示你安装的。</p><p>当然我还是比较推荐直接从<code>github</code>官网中下载。而数据集当然是自制。</p><h3 id="其他-yaml文件"><a href="#其他-yaml文件" class="headerlink" title="其他.yaml文件"></a>其他.yaml文件</h3><p>这些文件主要是对一些数据集做一个补充说明。如存放的路径、训练的路径、测试的路径等，以及这些数据集有多少张图片，定义了多少个类别等。当然代码中也写了下载这些数据集的方法。</p><ol><li><p><code>Argoverse.yaml</code>——Argo AI提供的Argoverse-HD数据集(环形前置中央摄像头)</p></li><li><p><code>coco.yaml</code>——由微软提供的COCO 2017数据集，网址为：<a href="http://cocodataset.org/">http://cocodataset.org</a></p></li><li><p><code>coco128.yaml</code>——由作者所在公司Ultralytics提供的COCO128数据集(来自COCO train2017的前128张图片)，网址为：<a href="https://www.kaggle.com/ultralytics/coco128">https://www.kaggle.com/ultralytics/coco128</a></p></li><li><p><code>GlobalWheat2020.yaml</code>——由萨斯喀彻温大学提供  全球小麦2020数据集网址为：<a href="http://www.global-wheat.com/">http://www.global-wheat.com/</a></p></li><li><p><code>Objects365.yaml</code>——提供了365个检测对象的数据集，几乎涵盖了生活中的各种常见物体。</p></li><li><p><code>SKU-110K.yaml</code>——由Trax retail提供的SKU-110K零售项目数据集网址为：<a href="https://github.com/eg4000/SKU110K_CVPR19">https://github.com/eg4000/SKU110K_CVPR19</a></p></li><li><p><code>VisDrone.yaml</code>——由天津大学提供的VisDrone2019-DET数据集(无人机拍摄的图片)<a href="https://github.com/VisDrone/VisDrone-Dataset">https://github.com/VisDrone/VisDrone-Dataset</a></p></li><li><p><code>VOC.yaml</code>——由牛津大学提供的PASCAL VOC数据集<a href="http://host.robots.ox.ac.uk/pascal/VOC">http://host.robots.ox.ac.uk/pascal/VOC</a></p></li><li><p><code>xView.yaml</code>——由美国国家地理空间情报局(NGA)提供的DIUx xView 2018挑战赛中的数据集。<a href="https://challenge.xviewdataset.org/">https://challenge.xviewdataset.org</a></p></li></ol><h2 id="model文件夹——模型文件"><a href="#model文件夹——模型文件" class="headerlink" title="model文件夹——模型文件"></a>model文件夹——模型文件</h2><p>在本文件夹中主要存放了各种Yolo算法的模型文件。在这些模型文件中定义了如下参数：</p><table><thead><tr><th align="center">参数</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">nc</td><td align="center">训练和检测的类别数量</td></tr><tr><td align="center">depth_multiple</td><td align="center">网络深度</td></tr><tr><td align="center">width_multiple</td><td align="center">网络宽度</td></tr><tr><td align="center">anchors</td><td align="center">锚点框参数</td></tr><tr><td align="center">backbone</td><td align="center">骨干网络参数</td></tr><tr><td align="center">head</td><td align="center">检测头</td></tr></tbody></table><p><strong>下面以yolov5s.yaml为例，对里面的相关参数进行详细解释。</strong></p><h3 id="yaml介绍"><a href="#yaml介绍" class="headerlink" title=".yaml介绍"></a>.yaml介绍</h3><ol><li>YAML(YAML Ain&#96;t Markup language)文件， <strong>它不是一个标记语言</strong>。配置文件有xml、properties等，但 **YAML是以数据为中心 **，更适合做配置文件。</li><li>YAML的语法和其他高级语言类似，并且可以 <strong>简单表达清单、散列表，标量</strong>等数据形态。</li><li>它使用 **空白符号缩进 **和大量依赖外观的特色，特别适合用来表达或编辑数据结构、各种配置文件、倾印调试内容、文件大纲。 <a href="https://links.jianshu.com/go?to=https://www.runoob.com/w3cnote/yaml-intro.html">yaml介绍</a></li><li>大小写敏感；缩进不允许使用tab，只允许空格；缩进的空格数不重要，只要相同层级的元素左对齐即可；’#’表示注释；使用缩进表示层级关系。</li></ol><p><strong>注意</strong>，在<code>yaml</code>文件中空格数其实也是重要的！在建立YAML 对象时，对象键值对使用冒号结构表示 <code>key: value</code>， <strong>冒号后面要加一个空格</strong>。</p><h3 id="parameters"><a href="#parameters" class="headerlink" title="parameters"></a>parameters</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Parameters</span></span><br><span class="line">nc: <span class="number">80</span>  <span class="comment"># number of classes</span></span><br><span class="line">depth_multiple: <span class="number">0.33</span>  <span class="comment"># model depth multiple</span></span><br><span class="line">width_multiple: <span class="number">0.50</span>  <span class="comment"># layer channel multiple</span></span><br></pre></td></tr></table></figure><ol><li>nc： <strong>类别数</strong>，你的类别有多少就填写多少。从1开始算起，不是0-14这样算。</li><li>depth_multiple：控制 <strong>模型的深度</strong>。</li><li>width_multiple：控制 <strong>卷积核的个数</strong>。</li></ol><blockquote><p>**depth_multiple **是用在 **backbone **中的 **number≠1的情况下， **即在Bottleneck层使用，控制模型的深度，yolov5s中设置为0.33，假设yolov5l中有三个Bottleneck，那yolov5s中就只有一个Bottleneck。<br>因为一般 **number&#x3D;1 **表示的是 **功能背景的层 **，比如说下采样Conv、Focus、SPP（空间金字塔池化）。<br>——————————————————————————————————————<br>**width_multiple **主要是用于设置arguments，例如yolov5s设置为0.5，Focus就变成[32, 3]，Conv就变成[64, 3, 2]。<br>以此类推，卷积核的个数都变成了设置的一半。</p></blockquote><p>yolov5提供了s、m、l、x四种，所有的<code>.yaml</code>文件都设置差不多，只有上面2和3的设置不同，作者团队很厉害，只需要修改这两个参数就可以调整模型的网络结构。</p><h3 id="anchors"><a href="#anchors" class="headerlink" title="anchors"></a>anchors</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">anchors:</span><br><span class="line">  - [<span class="number">10</span>,<span class="number">13</span>, <span class="number">16</span>,<span class="number">30</span>, <span class="number">33</span>,<span class="number">23</span>]  <span class="comment"># P3/8</span></span><br><span class="line">  - [<span class="number">30</span>,<span class="number">61</span>, <span class="number">62</span>,<span class="number">45</span>, <span class="number">59</span>,<span class="number">119</span>]  <span class="comment"># P4/16</span></span><br><span class="line">  - [<span class="number">116</span>,<span class="number">90</span>, <span class="number">156</span>,<span class="number">198</span>, <span class="number">373</span>,<span class="number">326</span>]  <span class="comment"># P5/32</span></span><br></pre></td></tr></table></figure><p>首先，anchor box就是从训练集中真实框（ground truth）中统计或聚类得到的几个不同尺寸的框。避免模型在训练的时候盲目的找，有助于模型快速收敛。假设每个网格对应k个anchor，也就是模型在训练的时候，它只是会在每一个网格附近找出这k种形状，不会找其他的。</p><p>anchor其实就是对预测的对象范围进行约束，并加入了尺寸先验经验，从而实现多尺度学习的目的。</p><p>而对于yolov5l来说，输出为3个尺度的特征图，分别为13×13、26×26、52×52，对应着9个anchor，每个尺度均分3个anchor。</p><blockquote><p>最小的13×13的特征图上由于其感受野最大，应该使用大的anchor(116x90)，(156x198)，(373x326)，这几个坐标是针对原始输入的，即416×416的，因此要除以32把尺度缩放到13×3下使用，适合较大的目标检测。中等的26×26特征图上由于其具有中等感受野故应用中等的anchor box (30x61)，(62x45)，(59x119)，适合检测中等大小的目标。较大的33×23特征图上由于其具有较小的感受野故应用最小的anchor box(10x13)，(16x30)，(33x23)，适合检测较小的目标。具体使用就是每个grid cell都有3个anchor box。</p></blockquote><p>根据检测层来相应增加anchors。</p><h3 id="backbone"><a href="#backbone" class="headerlink" title="backbone"></a>backbone</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">backbone:</span><br><span class="line">  <span class="comment"># [from, number, module, args]</span></span><br><span class="line">  [[-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">64</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">2</span>]],  <span class="comment"># 0-P1/2</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 1-P2/4</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">128</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 3-P3/8</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">6</span>, C3, [<span class="number">256</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 5-P4/16</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">9</span>, C3, [<span class="number">512</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>]],  <span class="comment"># 7-P5/32</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">1024</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, SPPF, [<span class="number">1024</span>, <span class="number">5</span>]],  <span class="comment"># 9</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure><ol><li>Bottleneck 可以译为“瓶颈层”。</li><li>from列参数： <strong>-1</strong>代表是从上一层获得的输入 ， <strong>-2</strong>表示从上两层获得的输入 （head同理）。</li><li>number列参数： 1表示只有一个，3表示有三个相同的模块。</li><li>SPPF、Conv、Bottleneck、BottleneckCSP的代码可以在 <code>./models/common.py</code>中获取到。</li><li>[64, 6, 2, 2]解析得到[3, 32, 3] ，输入为3（RGB），输出为32，卷积核k为3；<!--存疑，暂时没有太搞懂args里的参数--></li><li>[128, 3, 2]这是固定的，128表示输出128个卷积核个数。根据[128, 3, 2]解析得到[32, 64, 3, 2] ，32是输入，64是输出（128×0.5&#x3D;64），3表示3×3的卷积核，2表示步长为2。</li><li>主干网是图片从大到小，深度不断加深。</li><li><code>args</code>这里的输入都省去了，因为输入都是上层的输出。为了修改过于麻烦，这里输入的获取是从.&#x2F;models&#x2F;yolo.py的 <code>def parse_model(md, ch)</code>函数中解析得到的。</li></ol><h3 id="head"><a href="#head" class="headerlink" title="head"></a>head</h3><p><strong>head检测头</strong>：一般表示的是经过主干网后输出的特征图，特征图输入head中进行检测，包括类别和位置的检测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># YOLOv5 v6.0 head</span></span><br><span class="line">head:</span><br><span class="line">  [[-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, nn.Upsample, [<span class="literal">None</span>, <span class="number">2</span>, <span class="string">&#x27;nearest&#x27;</span>]],</span><br><span class="line">   [[-<span class="number">1</span>, <span class="number">6</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]],  <span class="comment"># cat backbone P4</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">512</span>, <span class="literal">False</span>]],  <span class="comment"># 13</span></span><br><span class="line"></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">1</span>, <span class="number">1</span>]],</span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, nn.Upsample, [<span class="literal">None</span>, <span class="number">2</span>, <span class="string">&#x27;nearest&#x27;</span>]],</span><br><span class="line">   [[-<span class="number">1</span>, <span class="number">4</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]],  <span class="comment"># cat backbone P3</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">256</span>, <span class="literal">False</span>]],  <span class="comment"># 17 (P3/8-small)</span></span><br><span class="line"></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]],</span><br><span class="line">   [[-<span class="number">1</span>, <span class="number">14</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]],  <span class="comment"># cat head P4</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">512</span>, <span class="literal">False</span>]],  <span class="comment"># 20 (P4/16-medium)</span></span><br><span class="line"></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]],</span><br><span class="line">   [[-<span class="number">1</span>, <span class="number">10</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]],  <span class="comment"># cat head P5</span></span><br><span class="line">   [-<span class="number">1</span>, <span class="number">3</span>, C3, [<span class="number">1024</span>, <span class="literal">False</span>]],  <span class="comment"># 23 (P5/32-large)</span></span><br><span class="line"></span><br><span class="line">   [[<span class="number">17</span>, <span class="number">20</span>, <span class="number">23</span>], <span class="number">1</span>, Detect, [nc, anchors]],  <span class="comment"># Detect(P3, P4, P5)</span></span><br><span class="line">  ]</span><br></pre></td></tr></table></figure><p>运行models文件夹下yolo.py文件，得到的解析图如下所示：<br><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/20220317165308.png"></p><p>与上面的模型似乎不太一样。</p><p>后面弄清楚了再来补充。</p><h3 id="common-py"><a href="#common-py" class="headerlink" title="common.py"></a>common.py</h3><p>该部分是backbone各个模块参数讲解。</p><h2 id="utils文件夹——工具包"><a href="#utils文件夹——工具包" class="headerlink" title="utils文件夹——工具包"></a>utils文件夹——工具包</h2><hr><p>这三个文件夹都用的很少，需要用到时再做了解。</p><h3 id="aws文件夹"><a href="#aws文件夹" class="headerlink" title="aws文件夹"></a>aws文件夹</h3><p>里面是一些跟其他语言对接的文件</p><h3 id="flask-rest-api"><a href="#flask-rest-api" class="headerlink" title="flask_rest_api"></a>flask_rest_api</h3><p>存放了做后端API的一些例程代码和封装好的函数</p><h3 id="loggers"><a href="#loggers" class="headerlink" title="loggers"></a>loggers</h3><p>终端需要打印任务信息的接口函数。</p><hr><h3 id="工具包函数"><a href="#工具包函数" class="headerlink" title="工具包函数"></a>工具包函数</h3><table><thead><tr><th align="center">文件名</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">activations.py</td><td align="center">激活函数</td></tr><tr><td align="center">augmentations.py</td><td align="center">图片增强函数</td></tr><tr><td align="center">autoanchor.py</td><td align="center">自动锚点工具函数</td></tr><tr><td align="center">autobatch.py</td><td align="center">自动批量处理工具</td></tr><tr><td align="center">benchmarks.py</td><td align="center">&#x2F;</td></tr><tr><td align="center">callbacks.py</td><td align="center">回调函数</td></tr><tr><td align="center">datasets.py</td><td align="center">用于数据加载和数据集的工具</td></tr><tr><td align="center">downloads.py</td><td align="center">下载工具</td></tr><tr><td align="center">general.py</td><td align="center">通用工具函数</td></tr><tr><td align="center">loss.py</td><td align="center">计算损失函数工具</td></tr><tr><td align="center">metrics.py</td><td align="center">模型验证函数</td></tr><tr><td align="center">plots.py</td><td align="center">可视化工具</td></tr><tr><td align="center">torch_utils.py</td><td align="center"><code>PyTorch</code>相关工具</td></tr></tbody></table><h2 id="主目录下其他-py代码"><a href="#主目录下其他-py代码" class="headerlink" title="主目录下其他.py代码"></a>主目录下其他.py代码</h2><h3 id="detect-py"><a href="#detect-py" class="headerlink" title="detect.py"></a>detect.py</h3><p>对图像、视频、路径、流媒体等进行推理检测。  </p><h3 id="export-py"><a href="#export-py" class="headerlink" title="export.py"></a>export.py</h3><p>导出<code>YOLOv5 PyTorch</code>模型到其他格式。如ONNX、OpenVINO、Core ML以及TensorFlow相关的格式。</p><h3 id="train-py"><a href="#train-py" class="headerlink" title="train.py"></a>train.py</h3><p>训练程序，在自定义数据集上训练YOLOv5模型。</p><h3 id="val-py"><a href="#val-py" class="headerlink" title="val.py"></a>val.py</h3><p>在自定义数据集上验证经过训练的YOLOv5模型的准确性 。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> yolov5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数学建模学习笔记1</title>
      <link href="/2022/03/16/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AD%A6%E4%B9%A01/"/>
      <url>/2022/03/16/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AD%A6%E4%B9%A01/</url>
      
        <content type="html"><![CDATA[<h1 id="数学建模学习笔记1——AHP层次分析法"><a href="#数学建模学习笔记1——AHP层次分析法" class="headerlink" title="数学建模学习笔记1——AHP层次分析法"></a>数学建模学习笔记1——AHP层次分析法</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><strong>作为建模比赛中最基础的模型之一，其主要用于解决评价类问题。(例如：选择哪种方案更好、哪种运动员或者员工表现的更优秀)</strong></p><p>AHP的主要特点是通过建立递阶层次结构，把人类的判断转化到若干因素两两之间重要度的比较上，从而把难于量化的定性判断转化为可操作的重要度的比较上面。在许多情况下，决策者可以直接使用AHP进行决策，极大地提高了决策的有效性、可靠性和可行性，但其本质是一种思维方式，它把复杂问题分解成多个组成因素，又将这些因素按支配关系分别形成递阶层次结构，通过两两比较的方法确定决策阀杆相对重要度的总排序。整个过程体现了人类决策思维的基本特征，即分解、判断、综合。克服了其他方法回避决策者主观判断的缺点。 </p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="方法一：使用打分法解决评价问题"><a href="#方法一：使用打分法解决评价问题" class="headerlink" title="方法一：使用打分法解决评价问题"></a>方法一：使用打分法解决评价问题</h3><p>需要完成权重表格：</p><table><thead><tr><th></th><th>指标权重</th><th>方案1</th><th>方案2</th><th>……</th></tr></thead><tbody><tr><td>指标1</td><td></td><td></td><td></td><td></td></tr><tr><td>指标2</td><td></td><td></td><td></td><td></td></tr><tr><td>指标3</td><td></td><td></td><td></td><td></td></tr><tr><td>……</td><td></td><td></td><td></td><td></td></tr></tbody></table><p>同颜色的单元格的和为1，它们表示的针对某一因素所占的权重。</p><h4 id="例题1：小明想去旅游，初步选择苏杭、北戴河和桂林三地之一作为目标景点。请你确定评价指标、形成评价体系来为小明选择最佳方案。"><a href="#例题1：小明想去旅游，初步选择苏杭、北戴河和桂林三地之一作为目标景点。请你确定评价指标、形成评价体系来为小明选择最佳方案。" class="headerlink" title="例题1：小明想去旅游，初步选择苏杭、北戴河和桂林三地之一作为目标景点。请你确定评价指标、形成评价体系来为小明选择最佳方案。"></a>例题1：小明想去旅游，初步选择苏杭、北戴河和桂林三地之一作为目标景点。请你确定评价指标、形成评价体系来为小明选择最佳方案。</h4><p><strong>分析：</strong>解决评价类问题，首先要想到一下三个问题：</p><p>① 我们评价的目标是什么？</p><p>② 为了达到这个目标有哪几种可选的方案？</p><p>③ 评价的准则或指标是什么？(我们根据什么东西来评价好坏)</p><p>一般而言前两个问题的答案是显而易见的，第三个问题的答案需要我们根据题目汇总的<em>背景材料、常识以及网上搜集到的参考资料</em>进行结合，从中筛选出最合适的指标。</p><h5 id="一致矩阵"><a href="#一致矩阵" class="headerlink" title="一致矩阵"></a>一致矩阵</h5><p>$$<br>a_{ij}&#x3D;\frac{i的重要程度}{j的重要程度}<br>$$</p><p>$$<br>a_{jk}&#x3D;\frac{j的重要程度}{k的重要程度}<br>$$</p><p>$$<br>a_{ik}&#x3D;\frac{i的重要程度}{k的重要程度}&#x3D;a_{ij} \times a_{jk}<br>$$</p><h5 id="一致性检验"><a href="#一致性检验" class="headerlink" title="一致性检验"></a>一致性检验</h5><p><strong>原理：</strong>检验我们构造的判断矩阵和一致矩阵是否有太大的差别。</p><h5 id="一致性检验的步骤"><a href="#一致性检验的步骤" class="headerlink" title="一致性检验的步骤"></a>一致性检验的步骤</h5><p>第一步：计算一致性指标CI：</p><p>$$<br>CI &#x3D; \frac{\lambda_{max}-n}{n-1}<br>$$<br>第二步：计算查找对应的平均随机一致性指标RI</p><table><thead><tr><th align="center">n</th><th>1</th><th>2</th><th align="center">3</th><th align="center">4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th></tr></thead><tbody><tr><td align="center">RI</td><td>0</td><td>0</td><td align="center">0.52</td><td align="center">0.89</td><td>1.12</td><td>1.26</td><td>1.36</td><td>1.41</td><td>1.46</td><td>1.49</td><td>1.52</td><td>1.54</td><td>1.56</td><td>1.58</td><td>1.59</td></tr></tbody></table><p>平均随机一致性RI的表格中n最多是15。</p><p>第三步：计算一致性比例CR<br>$$<br>CR&#x3D; \frac{CI}{RI}<br>$$<br>若CR＜0.1，则可认为判断矩阵的一致性可以接受；否则需要对判断矩阵进行修正。</p><p>第四步：计算各层元素度系统目标的合成权重，并进行排序。</p><h5 id="层次分析法的一些局限性"><a href="#层次分析法的一些局限性" class="headerlink" title="层次分析法的一些局限性"></a>层次分析法的一些局限性</h5><ol><li><p>评价的决策层不能太多，太多的话n会很大，判断矩阵和一致矩阵的差异也会很大。</p></li><li><p>如果决策层中指标的数据是已知的，那么我们如何利用这些来使得评价评价准确呢？</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数学建模 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IOU相关知识</title>
      <link href="/2022/03/15/YOLOv5%E6%94%AF%E7%BA%BF%E5%AD%A6%E4%B9%A0%E4%B9%8BIOU%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"/>
      <url>/2022/03/15/YOLOv5%E6%94%AF%E7%BA%BF%E5%AD%A6%E4%B9%A0%E4%B9%8BIOU%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h1 id="IOU相关知识"><a href="#IOU相关知识" class="headerlink" title="IOU相关知识"></a>IOU相关知识</h1><p>IoU 作为目标检测算法性能 mAP 计算的一个非常重要的函数。</p><h2 id="1-什么是IOU"><a href="#1-什么是IOU" class="headerlink" title="1. 什么是IOU"></a>1. 什么是IOU</h2><p>IoU 的全称为交并比（Intersection over Union），通过这个名称我们大概可以猜到 IoU 的计算方法。IoU 计算的是 “预测的边框” 和 “真实的边框” 的交集和并集的比值。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/IOU%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F.png"></p><p>一般约定，在计算机检测任务中，如果IoU≥0.5，就说检测正确。当然0.5只是约定阈值，你可以将IoU的阈值定的更高。IoU越高，边界框越精确。</p><p><strong>举例如下：</strong>绿色框是准确值，红色框是预测值。</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/1.jpg"></p><h2 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2. 代码实现"></a>2. 代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculateIoU</span>(<span class="params">candidateBound, groundTruthBound</span>):</span><br><span class="line">    cx1 = candidateBound[<span class="number">0</span>]</span><br><span class="line">    cy1 = candidateBound[<span class="number">1</span>]</span><br><span class="line">    cx2 = candidateBound[<span class="number">2</span>]</span><br><span class="line">    cy2 = candidateBound[<span class="number">3</span>]</span><br><span class="line"> </span><br><span class="line">    gx1 = groundTruthBound[<span class="number">0</span>]</span><br><span class="line">    gy1 = groundTruthBound[<span class="number">1</span>]</span><br><span class="line">    gx2 = groundTruthBound[<span class="number">2</span>]</span><br><span class="line">    gy2 = groundTruthBound[<span class="number">3</span>]</span><br><span class="line"> </span><br><span class="line">    carea = (cx2 - cx1) * (cy2 - cy1) <span class="comment">#C的面积</span></span><br><span class="line">    garea = (gx2 - gx1) * (gy2 - gy1) <span class="comment">#G的面积</span></span><br><span class="line"> </span><br><span class="line">    x1 = <span class="built_in">max</span>(cx1, gx1)</span><br><span class="line">    y1 = <span class="built_in">max</span>(cy1, gy1)</span><br><span class="line">    x2 = <span class="built_in">min</span>(cx2, gx2)</span><br><span class="line">    y2 = <span class="built_in">min</span>(cy2, gy2)</span><br><span class="line">    w = <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">abs</span>(x2 - x1))</span><br><span class="line">    h = <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">abs</span>(y2 - y1))</span><br><span class="line">    area = w * h <span class="comment">#C∩G的面积</span></span><br><span class="line"> </span><br><span class="line">    iou = area / (carea + garea - area)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure><h2 id="3-原理解析"><a href="#3-原理解析" class="headerlink" title="3. 原理解析"></a>3. 原理解析</h2><p>计算两个图片的交集，首先想到的是考虑两个图片边框的相对位置，然后按照它们的相对位置分情况讨论。</p><p>相对位置无非以下几种：</p><p><em>左上   左下   右上   右下   包含   互不相交</em></p><p>如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/2.jpg"></p><p>但在实际上这样写代码是做不到的。</p><p>换个角度思考：两个框交集的计算的实质是两个集合交集的计算，因此我们可以将两个框的交集的计算简化为：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/3.jpg"></p><p>通过简化，我们可以清晰地看到，交集计算的关键是交集上下界点（图中蓝点）的计算。</p><p>我们假设集合 A 为 [x 1 x_{1}<em>x</em>1，x 2 x_{2}<em>x</em>2]，集合 B 为 [y 1 y_{1}<em>y</em>1，y 2 y_{2}<em>y</em>2]。然后我们来求AB交集的上下界限。</p><p>交集计算的逻辑</p><ul><li>交集下界 z 1 z_{1}<em>z</em>1：max ( x 1 , y 1 ) \text{max}(x_{1}, y_{1})max(<em>x</em>1,<em>y</em>1)</li><li>交集上界 z 2 z_{2}<em>z</em>2：min ( x 2 , y 2 ) \text{min}(x_{2}, y_{2})min(<em>x</em>2,<em>y</em>2)</li><li>如果 z 2 − z 1 z_{2}-z_{1}<em>z</em>2−<em>z</em>1 小于0，则说明集合 A 和集合 B 没有交集。</li></ul><p>在YOLOv5的项目代码中，作者使用如下代码计算iou。</p><p>代码路径为：&#x2F;yolov5-master&#x2F;build&#x2F;lib.win-amd64-3.9&#x2F;utils&#x2F;metrics.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bbox_iou</span>(<span class="params">box1, box2, x1y1x2y2=<span class="literal">True</span>, GIoU=<span class="literal">False</span>, DIoU=<span class="literal">False</span>, CIoU=<span class="literal">False</span>, eps=<span class="number">1e-7</span></span>):</span><br><span class="line">    <span class="comment"># Returns the IoU of box1 to box2. box1 is 4, box2 is nx4</span></span><br><span class="line">    box2 = box2.T</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get the coordinates of bounding boxes</span></span><br><span class="line">    <span class="keyword">if</span> x1y1x2y2:  <span class="comment"># x1, y1, x2, y2 = box1</span></span><br><span class="line">        b1_x1, b1_y1, b1_x2, b1_y2 = box1[<span class="number">0</span>], box1[<span class="number">1</span>], box1[<span class="number">2</span>], box1[<span class="number">3</span>]</span><br><span class="line">        b2_x1, b2_y1, b2_x2, b2_y2 = box2[<span class="number">0</span>], box2[<span class="number">1</span>], box2[<span class="number">2</span>], box2[<span class="number">3</span>]</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># transform from xywh to xyxy</span></span><br><span class="line">        b1_x1, b1_x2 = box1[<span class="number">0</span>] - box1[<span class="number">2</span>] / <span class="number">2</span>, box1[<span class="number">0</span>] + box1[<span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">        b1_y1, b1_y2 = box1[<span class="number">1</span>] - box1[<span class="number">3</span>] / <span class="number">2</span>, box1[<span class="number">1</span>] + box1[<span class="number">3</span>] / <span class="number">2</span></span><br><span class="line">        b2_x1, b2_x2 = box2[<span class="number">0</span>] - box2[<span class="number">2</span>] / <span class="number">2</span>, box2[<span class="number">0</span>] + box2[<span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">        b2_y1, b2_y2 = box2[<span class="number">1</span>] - box2[<span class="number">3</span>] / <span class="number">2</span>, box2[<span class="number">1</span>] + box2[<span class="number">3</span>] / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Intersection area</span></span><br><span class="line">    inter = (torch.<span class="built_in">min</span>(b1_x2, b2_x2) - torch.<span class="built_in">max</span>(b1_x1, b2_x1)).clamp(<span class="number">0</span>) * \</span><br><span class="line">            (torch.<span class="built_in">min</span>(b1_y2, b2_y2) - torch.<span class="built_in">max</span>(b1_y1, b2_y1)).clamp(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Union Area</span></span><br><span class="line">    w1, h1 = b1_x2 - b1_x1, b1_y2 - b1_y1 + eps</span><br><span class="line">    w2, h2 = b2_x2 - b2_x1, b2_y2 - b2_y1 + eps</span><br><span class="line">    union = w1 * h1 + w2 * h2 - inter + eps</span><br><span class="line"></span><br><span class="line">    iou = inter / union</span><br><span class="line">    <span class="keyword">if</span> CIoU <span class="keyword">or</span> DIoU <span class="keyword">or</span> GIoU:</span><br><span class="line">        cw = torch.<span class="built_in">max</span>(b1_x2, b2_x2) - torch.<span class="built_in">min</span>(b1_x1, b2_x1)  <span class="comment"># convex (smallest enclosing box) width</span></span><br><span class="line">        ch = torch.<span class="built_in">max</span>(b1_y2, b2_y2) - torch.<span class="built_in">min</span>(b1_y1, b2_y1)  <span class="comment"># convex height</span></span><br><span class="line">        <span class="keyword">if</span> CIoU <span class="keyword">or</span> DIoU:  <span class="comment"># Distance or Complete IoU https://arxiv.org/abs/1911.08287v1</span></span><br><span class="line">            c2 = cw ** <span class="number">2</span> + ch ** <span class="number">2</span> + eps  <span class="comment"># convex diagonal squared</span></span><br><span class="line">            rho2 = ((b2_x1 + b2_x2 - b1_x1 - b1_x2) ** <span class="number">2</span> +</span><br><span class="line">                    (b2_y1 + b2_y2 - b1_y1 - b1_y2) ** <span class="number">2</span>) / <span class="number">4</span>  <span class="comment"># center distance squared</span></span><br><span class="line">            <span class="keyword">if</span> CIoU:  <span class="comment"># https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47</span></span><br><span class="line">                v = (<span class="number">4</span> / math.pi ** <span class="number">2</span>) * torch.<span class="built_in">pow</span>(torch.atan(w2 / h2) - torch.atan(w1 / h1), <span class="number">2</span>)</span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                    alpha = v / (v - iou + (<span class="number">1</span> + eps))</span><br><span class="line">                <span class="keyword">return</span> iou - (rho2 / c2 + v * alpha)  <span class="comment"># CIoU</span></span><br><span class="line">            <span class="keyword">return</span> iou - rho2 / c2  <span class="comment"># DIoU</span></span><br><span class="line">        c_area = cw * ch + eps  <span class="comment"># convex area</span></span><br><span class="line">        <span class="keyword">return</span> iou - (c_area - union) / c_area  <span class="comment"># GIoU https://arxiv.org/pdf/1902.09630.pdf</span></span><br><span class="line">    <span class="keyword">return</span> iou  <span class="comment"># IoU</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv5学习笔记1</title>
      <link href="/2022/03/15/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"/>
      <url>/2022/03/15/Yolov5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/</url>
      
        <content type="html"><![CDATA[<h1 id="Yolov5学习笔记-预测部分"><a href="#Yolov5学习笔记-预测部分" class="headerlink" title="Yolov5学习笔记-预测部分"></a>Yolov5学习笔记-预测部分</h1><h2 id="一些使用tips："><a href="#一些使用tips：" class="headerlink" title="一些使用tips："></a>一些使用tips：</h2><h3 id="detect-py运行指令——命令行方式"><a href="#detect-py运行指令——命令行方式" class="headerlink" title="detect.py运行指令——命令行方式"></a>detect.py运行指令——命令行方式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">python detect.py --source <span class="number">0</span>  <span class="comment"># webcam</span></span><br><span class="line">                          img.jpg  <span class="comment"># image</span></span><br><span class="line">                          vid.mp4  <span class="comment"># video</span></span><br><span class="line">                          path/  <span class="comment"># directory</span></span><br><span class="line">                          path/*.jpg  <span class="comment"># glob  匹配该文件夹下的所有jpg图片</span></span><br><span class="line">                          <span class="string">&#x27;https://youtu.be/Zgi9g1ksQHc&#x27;</span>  <span class="comment"># YouTube</span></span><br><span class="line">                          <span class="string">&#x27;rtsp://example.com/media.mp4&#x27;</span>  <span class="comment"># RTSP, RTMP, HTTP stream</span></span><br></pre></td></tr></table></figure><p>格式如上，“–”后面为传入的参数，通过命令行的方式往执行的.py文件中传入参数。</p><p>以detect.py为例，运行detect.py文件肯定是要有默认的输入参数的，在我所使用的YOLOv5代码下，以右键运行detect.py文件，默认检测的是目录””&#x2F;yolov5-master&#x2F;data&#x2F;images”下的两张图片。</p><p>通过上述代码的命令行指令，可以给detect.py的输入指定图片、视频或者某一个路径下的所有文件或某一个路径下的所有图片，当然还有视频或直接调用电脑或手机的摄像头实现实时检测。</p><h3 id="运行detect-py需要输入的参数"><a href="#运行detect-py需要输入的参数" class="headerlink" title="运行detect.py需要输入的参数"></a>运行detect.py需要输入的参数</h3><p>示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python detect.pu --source data/images --weights yolov5s.pt --conf <span class="number">0.25</span></span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">参数</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">source</td><td align="center">输入来源</td></tr><tr><td align="center">weights</td><td align="center">权重</td></tr><tr><td align="center">conf(confidence)</td><td align="center">失信度</td></tr></tbody></table><p>运行结果如下：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/detect%E6%96%87%E4%BB%B6%E8%BF%90%E8%A1%8C%E6%88%AA%E5%9B%BE.png"></p><h2 id="detect-py相关代码学习"><a href="#detect-py相关代码学习" class="headerlink" title="detect.py相关代码学习"></a>detect.py相关代码学习</h2><h3 id="参数-amp-解释"><a href="#参数-amp-解释" class="headerlink" title="参数&amp;解释"></a>参数&amp;解释</h3><p>接上表继续学习该代码中的参数</p><table><thead><tr><th align="center">参数</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">–imgsz&#x2F;–img&#x2F;–img-size</td><td align="center">输入的图片尺寸</td></tr><tr><td align="center">–conf-thres</td><td align="center">置信度</td></tr><tr><td align="center">–iou-thres</td><td align="center">交并比</td></tr><tr><td align="center">–view-img</td><td align="center">实时显示结果</td></tr><tr><td align="center">–save-txt</td><td align="center">保存检测结果</td></tr><tr><td align="center">–save-conf</td><td align="center">保存置信度</td></tr><tr><td align="center">–save-crop</td><td align="center">保存预测结果</td></tr><tr><td align="center">–classes</td><td align="center">可以检测的类别</td></tr><tr><td align="center">–agnostic-nms</td><td align="center">数据增强</td></tr><tr><td align="center">–augment</td><td align="center">增强检测</td></tr><tr><td align="center">–project</td><td align="center">结果保存的位置</td></tr><tr><td align="center">–name</td><td align="center">保存结果的名字</td></tr><tr><td align="center">–exist-ok</td><td align="center">依然保存在默认文件夹，而不新增文件夹</td></tr><tr><td align="center"></td><td align="center"></td></tr></tbody></table><h3 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;--imgsz&#x27;</span>, <span class="string">&#x27;--img&#x27;</span>, <span class="string">&#x27;--img-size&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=[<span class="number">640</span>], <span class="built_in">help</span>=<span class="string">&#x27;inference size h,w&#x27;</span>)</span><br></pre></td></tr></table></figure><p>虽然指定了图片尺寸，但比如输入1200*800的图片，输出依然为该尺寸，只是在检测过程中会对图片进行裁剪、分割。(代码后面会还原图片尺寸)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;--conf-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.25</span>, <span class="built_in">help</span>=<span class="string">&#x27;confidence threshold&#x27;</span>)</span><br></pre></td></tr></table></figure><p>默认值为0.25，表示只有当置信度大于0.25时，才会去标注它。值越小，检测标注的东西越多，但可信度就会降低，极容易出现误判。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;--iou-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.45</span>, <span class="built_in">help</span>=<span class="string">&#x27;NMS IoU threshold&#x27;</span>)</span><br></pre></td></tr></table></figure><p>有关IOU的知识在另一篇blog中有详细解释。<strong>default&#x3D;1表示框与框完全重合才能合并，结果中会有多个框出现。default&#x3D;0表示只要框与框有交集部分就可以合并，故结果中没有重合的框。</strong></p><p>设置默认值default&#x3D;1，表示只有当检测框与标注框完全重合时才会合并，因此运行后检测的效果会看到许多框框，这种完全重合的情况是很难满足的。在不同框下，一个物体被多次重复检测。如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/3.png"></p><p>当默认值default&#x3D;0时，检测效果如下：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/IOU=0.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;--view-img&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;show results&#x27;</span>)</span><br></pre></td></tr></table></figure><p>在运行detect.py时，若加上上行代码参数，则表示在运行此代码时会在检测的同时显示检测的效果。</p><p>一般执行时是默认没有的，若需要显示，有两种方法：一种通过命令行，输入如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate pytorch</span><br><span class="line">python detect.py --view-img</span><br></pre></td></tr></table></figure><p>我们不喜欢在命令行写指令，那么可以编辑该文件的运行配置，在[形参Parameters]位置上添加参数，如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/4.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;--save-txt&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to *.txt&#x27;</span>)</span><br></pre></td></tr></table></figure><p>保存检测的结果，内容为检测标注的值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(&#x27;--classes&#x27;, nargs=&#x27;+&#x27;, type=int, help=&#x27;filter by class: --classes 0, or --classes 0 2 3&#x27;)</span><br></pre></td></tr></table></figure><p>例如设置classes&#x3D;0并运行代码，则表示之间<strong>人</strong>这个类别。</p><h3 id="查看detect-py参数的默认值"><a href="#查看detect-py参数的默认值" class="headerlink" title="查看detect.py参数的默认值"></a>查看detect.py参数的默认值</h3><p>通过在调试可以看到所有参数的默认值</p><p><img src="https://cdn.jsdelivr.net/gh/PengJoy1106/peng_picgo/img/5.png"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 计算机视觉 </tag>
            
            <tag> yolov5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客编写发布指南</title>
      <link href="/2022/03/14/%E5%8D%9A%E5%AE%A2%E7%BC%96%E5%86%99%E5%8F%91%E5%B8%83%E6%8C%87%E5%8D%97/"/>
      <url>/2022/03/14/%E5%8D%9A%E5%AE%A2%E7%BC%96%E5%86%99%E5%8F%91%E5%B8%83%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h2 id="使用的软件"><a href="#使用的软件" class="headerlink" title="使用的软件"></a>使用的软件</h2><h3 id="WebStorm"><a href="#WebStorm" class="headerlink" title="WebStorm"></a>WebStorm</h3><p>用来管理博客相关源代码以及博客的部署和文章的提交</p><h3 id="Typora"><a href="#Typora" class="headerlink" title="Typora"></a>Typora</h3><p>用于博客写作<br>Typora常用快捷键和用法：<br>标题：Ctrl+1、2、3…对应一、二、三…级标题（光标定位到需要设置为标题的行，按快捷键）<br>加粗：Ctrl+B（选中要加粗的文本，按快捷键）<br>斜体：Ctrl+I（选中要设置斜体的文本，按快捷键）<br>下划线：Ctrl+U（选中要加下划线的文本，按快捷键）<br>删除线：Alt+Shift+5（选中要加删除线的文本，按快捷键）<br>代码片段：Ctrl+Shift+&#96;（选中要设置为代码片段的文本，按快捷键）<br>代码块：Ctrl+Shift+K（任意位置按快捷键，选择编程语言然后在代码块中输入代码）<br>切换到下一行：Ctrl+Enter（任意位置按快捷键，在代码块中可以跳出代码块另起一行）<br>链接：Ctrl+K（先复制链接，然后选中要加链接的文本，按快捷键。Ctrl+左键点击文本可跳转到对应链接）<br>取消格式：再次按相同的快捷键即可<br>有序列表：数字+点+空格<br>任务列表：加号或减号+空格<br>切换到列表下一行：Space+Enter<br>嵌套列表：按Tab键<br>退出列表：按 Shift+Tab<br>插入表格：Ctrl+T<br>引用：输入&gt;后面加空格，或者Ctrl+Shift+Q</p><h2 id="Hexo文章管理"><a href="#Hexo文章管理" class="headerlink" title="Hexo文章管理"></a>Hexo文章管理</h2><h3 id="创建的命令"><a href="#创建的命令" class="headerlink" title="创建的命令"></a>创建的命令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new &lt;title&gt;</span><br><span class="line">$ hexo new &quot;我的第一篇文章&quot;</span><br></pre></td></tr></table></figure><h3 id="布局"><a href="#布局" class="headerlink" title="布局"></a>布局</h3><p>· 创建md文件时，我们可以指定布局</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new [layout] &lt;title&gt;</span><br><span class="line">$ hexo new page &quot;我的页面&quot;</span><br></pre></td></tr></table></figure><p>· 布局有三种<br>    ①post(文章)<br>    ②draft(草稿)<br>    ③page(页面)<br>· 如果没有指定布局类型，则为默认布局post，可以在站点配置文件修改 default_layout 参数来修改默认布局。</p><h2 id="文章编写格式"><a href="#文章编写格式" class="headerlink" title="文章编写格式"></a>文章编写格式</h2><table><thead><tr><th align="center">写法</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">title</td><td align="center">【必需】文章标题</td></tr><tr><td align="center">date</td><td align="center">【必需】文章创建日期</td></tr><tr><td align="center">updated</td><td align="center">【可选】文章更新日期</td></tr><tr><td align="center">tags</td><td align="center">【可选】文章标籤</td></tr><tr><td align="center">categories</td><td align="center">【可选】文章分类</td></tr><tr><td align="center">keywords</td><td align="center">【可选】文章关键字</td></tr><tr><td align="center">description</td><td align="center">【可选】文章描述</td></tr><tr><td align="center">top_img</td><td align="center">【可选】文章顶部图片</td></tr><tr><td align="center">cover</td><td align="center">【可选】文章缩略图 (如果没有设置 top_img, 文章页顶部将显示缩略图，可设为 false &#x2F; 图片地址 &#x2F; 留空)</td></tr><tr><td align="center">comments</td><td align="center">【可选】显示文章评论模块 (默认 true)</td></tr><tr><td align="center">toc</td><td align="center">【可选】显示文章 TOC (默认为设置中 toc 的 enable 配置)</td></tr><tr><td align="center">toc_number</td><td align="center">【可选】显示 toc_number (默认为设置中 toc 的 number 配置)</td></tr><tr><td align="center">copyright</td><td align="center">【可选】显示文章版权模块 (默认为设置中 post_copyright 的 enable 配置)</td></tr><tr><td align="center">copyright_author</td><td align="center">【可选】文章版权模块的<code>文章作者</code></td></tr><tr><td align="center">copyright_author_href</td><td align="center">【可选】文章版权模块的<code>文章作者</code>链接</td></tr><tr><td align="center">copyright_url</td><td align="center">【可选】文章版权模块的<code>文章连结</code>链接</td></tr><tr><td align="center">copyright_info</td><td align="center">【可选】文章版权模块的<code>版权声明</code>文字</td></tr><tr><td align="center">mathjax</td><td align="center">【可选】显示 mathjax (当设置 mathjax 的 per_page: false 时，才需要配置，默认 false)</td></tr><tr><td align="center">katex</td><td align="center">【可选】显示 katex (当设置 katex 的 per_page: false 时，才需要配置，默认 false)</td></tr><tr><td align="center">aplayer</td><td align="center">【可选】在需要的页面加载 aplayer 的 js 和 css, 请参考文章下面的<code>音乐</code> 配置</td></tr><tr><td align="center">highlight_shrink</td><td align="center">【可选】配置代码框是否展开 (true&#x2F;false)(默认为设置中 highlight_shrink 的配置)</td></tr><tr><td align="center">aside</td><td align="center">【可选】显示侧边栏 (默认 true)</td></tr><tr><td align="center">hide</td><td align="center">【可选】隐藏文章</td></tr><tr><td align="center">sticky</td><td align="center">【可选】文章置顶，值越大越靠上</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 生产力 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
